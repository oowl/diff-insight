---
date: '2025-02-06'
permalink: https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:d46a0e8...MicrosoftDocs:ea9b000
summary: |-
  Recent updates to the Azure AI documentation have introduced new content safety features, clarified existing materials, and ensured accuracy in references and dates. A key addition is the new document on harm categories, which outlines various types of harmful content and their severity. There is also a specific note on content safety for serverless APIs, clarifying how it differs from managed compute.

  There are no reported breaking changes in this update. Other enhancements include updates to dates and links for improved accuracy, better clarity in headers related to content safety, and a consolidation of content safety tips specifically for serverless API settings. Terminology clarifications and a streamlined document structure have also been implemented to enhance readability and user navigation.

  Overall, these revisions enhance user understanding and navigability of content safety features, particularly for serverless APIs. The updates reflect a commitment to responsible AI deployment and ethical use, ensuring users can follow best practices for content moderation and compliance. The documentation enhancements indicate a user-centered approach, reinforcing the importance of AI safety, ethics, and accessibility within the Azure AI ecosystem.
title: '[en_US] Diff Insight Report - misc'

---

[View Diff on GitHub](https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:d46a0e8...MicrosoftDocs:ea9b000){target="_blank"}

# Highlights

Recent updates to Azure AI documentation introduce new content safety features, extend clarity in existing documents, and adjust references and dates for accuracy. Notably, new documentation on content safety for serverless APIs and harm categories has been added. Adjustments were made for improved guidance on content safety during model deployment, with specific focus on serverless API settings.

## New features
- Introduction of a new document on harm categories within content safety, detailing various harmful content and severity levels.
- Addition of a specific note regarding content safety availability for serverless APIs, clarifying distinctions with managed compute.

## Breaking changes
No breaking changes reported in this diff.

## Other updates
- Dates and links updated for enhanced accuracy in "Document Intelligence What's New."
- Clarification and rephrasing in headers for content safety overview documents.
- Consolidation of content safety tips across various deployment guides, focusing guidance to serverless API settings.
- Clarifications in terminologies and streamlining document structures for better readability and user orientation.

# Insights

This set of revisions within Azure AI documentation is part of a broader effort to enhance user comprehension and improve the navigability of content safety features, particularly in environments utilizing serverless APIs. An increased emphasis on content moderation and ethical AI use is evident through the introduction of new documents outlining content safety measures, such as harm categories and the specific risks associated therein. This move signals Azure AI's commitment to ensuring the responsible deployment and scaling of AI models, with precise attention to content potentially deemed harmful.

The updates also reflect an ongoing commitment to clarity and relevancy in user guidance, as seen in repetitive content being streamlined and redundant notes being removed across documents. As part of this clarity drive, document updates have improved the accuracy of references and navigational links, ensuring users can more easily follow best practices for deployment and content moderation.

Furthermore, the introduction of new entries and modifications in the table of contents reflects strategic reinforcement toward handling AI content safety. These changes not only support responsible AI usage but also serve to guide developers and stakeholders through compliance and ethical design concerns, enhancing the overall development ecosystem within Azure AI Studio.

These thoughtful document enhancements point toward a more user-centric and forward-thinking documentation approach, underscoring Azure AIâ€™s dedication to staying at the forefront of AI safety, ethics, and accessibility. The consolidation of tips related to serverless APIs represents a practical step towards making the documentation more concise while still remaining comprehensive, thus better equipping users to navigate complex deployment landscapes with confidence.

# Summary Table
|  Filename  | Type |    Title    | Status | A  | D  | M  |
|------------|------|-------------|--------|----|----|----|
| [whats-new.md](#item-1ec8d3) | minor update | Update of Date and Links in Document Intelligence What's New | modified | 3 | 3 | 6 | 
| [content-safety-overview.md](#item-2c67e3) | minor update | Modifications to Content Safety Overview Document | modified | 3 | 21 | 24 | 
| [content-filtering.md](#item-91b372) | minor update | Update to Content Filtering Documentation | modified | 1 | 1 | 2 | 
| [model-catalog-content-safety.md](#item-0d1e57) | new feature | New Documentation on Content Safety for Model Catalog | added | 49 | 0 | 49 | 
| [deploy-models-cohere-command.md](#item-3e97f4) | minor update | Update to Content Safety Tips in Deployment Instructions | modified | 8 | 8 | 16 | 
| [deploy-models-deepseek.md](#item-7c33de) | minor update | Update to Content Safety Tips in DeepSeek Deployment Instructions | modified | 8 | 8 | 16 | 
| [deploy-models-gretel-navigator.md](#item-2e9806) | minor update | Update to Content Safety Tips in Gretel Navigator Deployment Instructions | modified | 4 | 4 | 8 | 
| [deploy-models-jais.md](#item-0bd11f) | minor update | Update to Content Safety Tips in JAIS Deployment Instructions | modified | 7 | 8 | 15 | 
| [deploy-models-llama.md](#item-6274a7) | minor update | Update to Content Safety Information in Llama Deployment Instructions | modified | 4 | 16 | 20 | 
| [deploy-models-mistral-codestral.md](#item-83ba03) | minor update | Update to Content Safety Guidance in Mistral Codestral Deployment Instructions | modified | 8 | 8 | 16 | 
| [deploy-models-mistral-nemo.md](#item-e7b729) | minor update | Update to Content Safety Directions in Mistral Nemo Deployment Instructions | modified | 8 | 8 | 16 | 
| [deploy-models-mistral.md](#item-487a41) | minor update | Refinement of Content Safety Guidance in Mistral Deployment Documentation | modified | 7 | 8 | 15 | 
| [deploy-models-phi-3-5-vision.md](#item-8d6d7d) | minor update | Streamlining Content Safety Guidance in Phi 3.5 Vision Deployment Instructions | modified | 4 | 16 | 20 | 
| [deploy-models-phi-3.md](#item-47e305) | minor update | Enhancement of Content Safety Information in Phi 3 Deployment Guide | modified | 4 | 17 | 21 | 
| [deploy-models-phi-4.md](#item-c40212) | minor update | Refinement of Content Safety Information in Phi 4 Deployment Guide | modified | 4 | 16 | 20 | 
| [deploy-models-tsuzumi.md](#item-d3fd51) | minor update | Streamlining Content Safety Instructions in Tsuzumi Deployment Guide | modified | 7 | 8 | 15 | 
| [deploy-cxrreportgen.md](#item-377d15) | minor update | Removal of Feature Preview Note in CXRReportGen Deployment Guide | modified | 0 | 2 | 2 | 
| [deploy-medimageinsight.md](#item-e9ab9e) | minor update | Removal of Feature Preview Note in MedImageInsight Deployment Guide | modified | 0 | 2 | 2 | 
| [deploy-medimageparse.md](#item-611e84) | minor update | Removal of Feature Preview Note in MedImageParse Deployment Guide | modified | 0 | 2 | 2 | 
| [healthcare-ai-models.md](#item-12fcfc) | minor update | Removal of Feature Preview Note in Healthcare AI Models Guide | modified | 0 | 2 | 2 | 
| [model-catalog-overview.md](#item-278001) | minor update | Clarification in Model Catalog Overview | modified | 2 | 2 | 4 | 
| [content-safety-harm-categories.md](#item-8ef139) | new feature | Introduction of Content Safety Harm Categories | added | 29 | 0 | 29 | 
| [content-safety-serverless-apis-note.md](#item-779e7e) | new feature | Addition of Note on Content Safety for Serverless APIs | added | 13 | 0 | 13 | 
| [content-safety-serverless-models.md](#item-8fe192) | minor update | Update of References in Serverless Models Content Safety Documentation | modified | 1 | 1 | 2 | 
| [toc.yml](#item-2745cd) | minor update | Update of Table of Contents for Azure AI Studio | modified | 6 | 2 | 8 | 


# Modified Contents
## articles/ai-services/document-intelligence/whats-new.md{#item-1ec8d3}

<details>
<summary>Diff</summary>
````diff
@@ -6,7 +6,7 @@ author: laujan
 manager: nitinme
 ms.service: azure-ai-document-intelligence
 ms.topic: whats-new
-ms.date: 01/14/2025
+ms.date: 02/05/2025
 ms.author: lajanuar
 ms.custom:
   - references_regions
@@ -29,7 +29,7 @@ Document Intelligence service is updated on an ongoing basis. Bookmark this page
 
 ## December 2024
 
-**Document Intelligence v4.0 programming language SDKs are now generally available (GA)**! <br><br>The latest client libraries default to the [**2024-11-30 REST API (GA)**](/rest/api/aiservices/operation-groups?view=rest-aiservices-v4.0%20(2024-11-30&preserve-view=true) version of the service.<br><br>
+**Document Intelligence v4.0 programming language SDKs are now generally available (GA)**! <br><br>The latest client libraries default to the [**2024-11-30 REST API (GA)**](/rest/api/aiservices/operation-groups?view=rest-aiservices-v4.0%20(2024-11-30)&preserve-view=true) version of the service.<br><br>
 For more information, *see* client libraries for the following supported programming languages:
 
 * [ðŸ†• .NET (C#)](versioning/changelog-release-history.md?view=doc-intel-4.0.0&tabs=csharp&preserve-view=true)
@@ -76,7 +76,7 @@ For more information, *see* client libraries for the following supported program
 *  [ðŸ†• US Tax model](prebuilt/tax-document.md)
    *  New prebuilt tax models added for 1095A, 1095C, 1099SSA, and W4.
 
-* [Delete analyze response](https://learn.microsoft.com/rest/api/aiservices/document-models/delete-analyze-result?view=rest-aiservices-v4.0%20(2024-11-30)&tabs=HTTP)
+* [Delete analyze response](/rest/api/aiservices/document-models/delete-analyze-result?view=rest-aiservices-v4.0%20(2024-11-30)&preserve-view=true&tabs=HTTP)
   * Analyze response is stored for 24 hours from when the operation completes for retrieval. For scenarios where you want to delete the response sooner, use the delete analyze response API to delete the response.  
 
 * The v4.0 API includes cumulative updates from preview releases as listed:
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update of Date and Links in Document Intelligence What's New"
}
```

### Explanation
This code diff reflects minor updates made to the "whats-new.md" file for the Document Intelligence service. The changes include updating the date from January 14, 2025, to February 5, 2025, and correcting the links within the document. Notably, the link for the Document Intelligence v4.0 programming language SDKs has been adjusted to ensure it properly preserves the view when accessed. Additionally, a related link for the delete analyze response API was also revised for consistency. Overall, these updates enhance the accuracy and relevance of the information provided in the document.

## articles/ai-studio/ai-services/content-safety-overview.md{#item-2c67e3}

<details>
<summary>Diff</summary>
````diff
@@ -12,7 +12,7 @@ ms.author: pafarley
 author: PatrickFarley
 ---
 
-# Content Safety in Azure AI Foundry portal
+# Content safety in the Azure AI Foundry portal
 
 Azure AI Content Safety is an AI service that detects harmful user-generated and AI-generated content in applications and services. Azure AI Content Safety includes various APIs that allow you to detect and prevent the output of harmful content. The interactive Content Safety **try out** page in Azure AI Foundry portal allows you to view, explore, and try out sample code for detecting harmful content across different modalities. 
 
@@ -23,7 +23,7 @@ You can use Azure AI Content Safety for many scenarios:
 **Text content**: 
 - Moderate text content: This feature scans and moderates text content, identifying and categorizing it based on different levels of severity to ensure appropriate responses. 
 - Groundedness detection: This filter determines if the AI's responses are based on trusted, user-provided sources, ensuring that the answers are "grounded" in the intended material. Groundedness detection is helpful for improving the reliability and factual accuracy of responses. 
-- Protected material detection for text: This feature identifies protected text material, such as known song lyrics, articles, or other content, ensuring that the AI doesnâ€™t output this content without permission. 
+- Protected material detection for text: This feature identifies protected text material, such as known song lyrics, articles, or other content, ensuring that the AI doesn't output this content without permission. 
 - Protected material detection for code: Detects code segments in the model's output that match known code from public repositories, helping to prevent uncredited or unauthorized reproduction of source code. 
 - Prompt shields: This feature provides a unified API to address "Jailbreak" and "Indirect Attacks": 
     - Jailbreak Attacks: Attempts by users to manipulate the AI into bypassing its safety protocols or ethical guidelines. Examples include prompts designed to trick the AI into giving inappropriate responses or performing tasks it was programmed to avoid. 
@@ -37,25 +37,7 @@ You can use Azure AI Content Safety for many scenarios:
 - Custom categories: Allows users to define specific categories for moderating and filtering content, tailoring safety protocols to unique needs. 
 - Safety system message: Provides a method for setting up a "System Message" to instruct the AI on desired behavior and limitations, reinforcing safety boundaries and helping prevent unwanted outputs. 
 
-## Understand harm categories
-
-### Harm categories
-
-| Category  | Description         |API term |
-| --------- | ------------------- | --- |
-| Hate and Fairness      | Hate and fairness harms refer to any content that attacks or uses discriminatory language with reference to a person or identity group based on certain differentiating attributes of these groups. <br><br>This includes, but is not limited to:<ul><li>Race, ethnicity, nationality</li><li>Gender identity groups and expression</li><li>Sexual orientation</li><li>Religion</li><li>Personal appearance and body size</li><li>Disability status</li><li>Harassment and bullying</li></ul> | `Hate` |
-| Sexual  | Sexual describes language related to anatomical organs and genitals, romantic relationships and sexual acts, acts portrayed in erotic or affectionate terms, including those portrayed as an assault or a forced sexual violent act against oneâ€™s will. <br><br> This includes but is not limited to:<ul><li>Vulgar content</li><li>Prostitution</li><li>Nudity and Pornography</li><li>Abuse</li><li>Child exploitation, child abuse, child grooming</li></ul>   | `Sexual` |
-| Violence  | Violence describes language related to physical actions intended to hurt, injure, damage, or kill someone or something; describes weapons, guns, and related entities. <br><br>This includes, but isn't limited to:  <ul><li>Weapons</li><li>Bullying and intimidation</li><li>Terrorist and violent extremism</li><li>Stalking</li></ul>  | `Violence` |
-| Self-Harm  | Self-harm describes language related to physical actions intended to purposely hurt, injure, damage oneâ€™s body or kill oneself. <br><br> This includes, but isn't limited to: <ul><li>Eating Disorders</li><li>Bullying and intimidation</li></ul>  | `SelfHarm` |
-
-### Severity levels 
-
-| Level | Description |
-| --- | ---|
-|Safe |Content might be related to violence, self-harm, sexual, or hate categories but the terms are used in general, journalistic, scientific, medical, and similar professional contexts, which are appropriate for most audiences. |
-|Low |Content that expresses prejudiced, judgmental, or opinionated views, includes offensive use of language, stereotyping, use cases exploring a fictional world (for example, gaming, literature) and depictions at low intensity.| 
-|Medium |Content that uses offensive, insulting, mocking, intimidating, or demeaning language towards specific identity groups, includes depictions of seeking and executing harmful instructions, fantasies, glorification, promotion of harm at medium intensity. |
-|High |Content that displays explicit and severe harmful instructions, actions, damage, or abuse; includes endorsement, glorification, or promotion of severe harmful acts, extreme or illegal forms of harm, radicalization, or nonconsensual power exchange or abuse. |
+[!INCLUDE [content-safety-harm-categories](../includes/content-safety-harm-categories.md)]
 
 ## Limitations
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Modifications to Content Safety Overview Document"
}
```

### Explanation
This code diff showcases a minor update to the "content-safety-overview.md" file for the Azure AI Foundry portal. The changes primarily involve rephrasing the section headers for grammatical consistency, changing "Content Safety in Azure AI Foundry portal" to "Content safety in the Azure AI Foundry portal." Additionally, the updates include a significant reduction of content by removing a section on harm and severity categories, replacing it with a reference link to another documentation file for comprehensive information. This approach aims to streamline the content while directing users to a more detailed resource. The modifications enhance the document's clarity and provide a more efficient way of accessing important safety information.

## articles/ai-studio/concepts/content-filtering.md{#item-91b372}

<details>
<summary>Diff</summary>
````diff
@@ -26,7 +26,7 @@ Azure AI Foundry includes a content filtering system that works alongside core m
 
 This content filtering system is powered by [Azure AI Content Safety](../../ai-services/content-safety/overview.md), and it works by running both the prompt input and completion output through an ensemble of classification models aimed at detecting and preventing the output of harmful content. Variations in API configurations and application design might affect completions and thus filtering behavior.
 
-With Azure OpenAI model deployments, you can use the default content filter or create your own content filter (described later on). The default content filter is also available for other text models curated by Azure AI in the [model catalog](../how-to/model-catalog.md), but custom content filters aren't yet available for those models. Models available through **Models as a Service** have content filtering enabled by default and can't be configured.
+With Azure OpenAI model deployments, you can use the default content filter or create your own content filter (described later on).  Models available through **serverless APIs** have content filtering enabled by default. To learn more about the default content filter enabled for serverless APIs, see [Content safety for models curated by Azure AI in the model catalog](model-catalog-content-safety.md).
 
 ## Language support
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update to Content Filtering Documentation"
}
```

### Explanation
The code diff indicates a minor update to the "content-filtering.md" file within the Azure AI documentation. The primary modification involves the replacement of the phrase "Models available through **Models as a Service**" with "Models available through **serverless APIs**." The update clarifies the type of models that have content filtering enabled by default. Additionally, a new reference link was added to guide users to more information about the default content filter associated with serverless APIs. These changes help clarify the features of the content filtering system and offer better guidance to users regarding the models utilized. Overall, the update enhances the accuracy and usability of the documentation.

## articles/ai-studio/concepts/model-catalog-content-safety.md{#item-0d1e57}

<details>
<summary>Diff</summary>
````diff
@@ -0,0 +1,49 @@
+---
+title: Content safety for models curated by Azure AI in the model catalog
+titleSuffix: Azure AI Foundry
+description: Learn about content safety for models deployed using serverless APIs, using Azure AI Foundry.
+manager: scottpolly
+ms.service: azure-ai-foundry
+ms.topic: conceptual
+ms.date: 02/04/2025
+ms.author: mopeakande 
+author: msakande
+ms.reviewer: ositanachi
+reviewer: ositanachi
+ms.custom: 
+---
+
+# Content safety for models curated by Azure AI in the model catalog
+
+[!INCLUDE [feature-preview](../includes/feature-preview.md)]
+
+In this article, learn about content safety capabilities for models from the model catalog deployed using serverless APIs.
+
+
+## Content filter defaults
+
+Azure AI uses a default configuration of [Azure AI Content Safety](/azure/ai-services/content-safety/overview) content filters to detect harmful content across four categories including hate and fairness, self-harm, sexual, and violence for models deployed via serverless APIs. To learn more about content filtering (preview), see [Understand harm categories](#understand-harm-categories).
+
+The default content filtering configuration for text models is set to filter at the medium severity threshold, filtering any detected content at this level or higher. For image models, the default content filtering configuration is set at the low configuration threshold, filtering at this level or higher. For models deployed using the [Azure AI model inference service](../../ai-foundry/model-inference/how-to/configure-content-filters.md), you can create configurable filters by selecting the **Content filters** tab within the **Safety + security** page of the Azure AI Foundry portal.
+
+> [!TIP]
+> Content filtering (preview) isn't available for certain model types that are deployed via serverless APIs. These model types include embedding models and time series models.
+
+Content filtering (preview) occurs synchronously as the service processes prompts to generate content. You might be billed separately according to [Azure AI Content Safety pricing](https://azure.microsoft.com/pricing/details/cognitive-services/content-safety/) for such use. You can disable content filtering (preview) for individual serverless endpoints either:
+
+- When you first deploy a language model
+- Later, by selecting the content filtering toggle on the deployment details page
+
+Suppose you decide to use an API other than the [Azure AI Model Inference API](/azure/ai-studio/reference/reference-model-inference-api) to work with a model that is deployed via a serverless API. In such a situation, content filtering (preview) isn't enabled unless you implement it separately by using Azure AI Content Safety. To get started with Azure AI Content Safety, see [Quickstart: Analyze text content](/azure/ai-services/content-safety/quickstart-text). You run a higher risk of exposing users to harmful content if you don't use content filtering (preview) when working with models that are deployed via serverless APIs.
+
+[!INCLUDE [content-safety-harm-categories](../includes/content-safety-harm-categories.md)]
+
+## How charges are calculated
+
+Pricing details are viewable at [Azure AI Content Safety pricing](https://azure.microsoft.com/pricing/details/cognitive-services/content-safety/). Charges are incurred when the Azure AI Content Safety validates the prompt or completion. If Azure AI Content Safety blocks the prompt or completion, you're charged for both the evaluation of the content and the inference calls.
+
+## Related content
+
+- [How to configure content filters (preview) for models in Azure AI services](../../ai-foundry/model-inference/how-to/configure-content-filters.md)
+- [What is Azure AI Content Safety?](../../ai-services/content-safety/overview.md)
+- [Model catalog and collections in Azure AI Foundry portal](../how-to/model-catalog-overview.md)
````
</details>

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "New Documentation on Content Safety for Model Catalog"
}
```

### Explanation
This code diff introduces a new document titled "Content safety for models curated by Azure AI in the model catalog." The document outlines the content safety capabilities for models deployed via serverless APIs within Azure AI Foundry. It includes details on the default content filtering configurations, which aim to detect harmful content across various categories, including hate speech, self-harm, sexual content, and violence.

Key sections in the document explain how the content filters operate, the severity thresholds set for filtering, and tips for managing content filtering, such as disabling it during model deployment. Also mentioned are pricing considerations associated with content filtering and instructions on how to integrate Azure AI Content Safety with other APIs. The addition enhances the documentation for users, providing crucial information on content safety measures and the features available for models in Azure AI's catalog. Overall, this new document serves as a comprehensive resource for understanding and managing content safety in Azure's AI offerings.

## articles/ai-studio/how-to/deploy-models-cohere-command.md{#item-3e97f4}

<details>
<summary>Diff</summary>
````diff
@@ -490,8 +490,8 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -977,8 +977,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -1489,8 +1489,8 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -2117,8 +2117,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update to Content Safety Tips in Deployment Instructions"
}
```

### Explanation
The code diff reflects a minor update to the "deploy-models-cohere-command.md" documentation regarding the deployment of models using Azure AI. The main change consists of replacing specific tip sections that provided a link to the Azure AI content safety documentation with an inclusion of a new note about content safety related to serverless APIs.

In multiple areas of the document, the original tips that directed users to the general content safety documentation have been replaced by `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. This change likely enhances the specificity of the guidance offered, ensuring that users are more accurately directed to relevant content about content safety for serverless API deployments. Overall, this update improves the clarity and focus of the documentation regarding safety settings during model deployment.

## articles/ai-studio/how-to/deploy-models-deepseek.md{#item-7c33de}

<details>
<summary>Diff</summary>
````diff
@@ -269,8 +269,8 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -542,8 +542,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -835,8 +835,8 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -1121,8 +1121,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update to Content Safety Tips in DeepSeek Deployment Instructions"
}
```

### Explanation
This code diff shows a minor update to the documentation file "deploy-models-deepseek.md," which provides guidance on deploying models using the DeepSeek service within Azure AI. The key change involves the replacement of existing tips that directed users to the Azure AI content safety documentation with a new inclusion that provides specific notes related to content safety for serverless APIs.

In several sections throughout the document, the original tips prompting users to consult general content safety resources have been exchanged for a directive that includes a serverless APIs note. This ensures that readers are directed to content that is more relevant to their specific deployment context, thereby enhancing the usability and precision of the guidance being offered. Overall, this change aims to improve the accuracy of the documentation by tailoring the information provided to better suit users deploying models via DeepSeek.

## articles/ai-studio/how-to/deploy-models-gretel-navigator.md{#item-2e9806}

<details>
<summary>Diff</summary>
````diff
@@ -266,8 +266,8 @@ except HttpResponseError as ex:
 
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -509,8 +509,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update to Content Safety Tips in Gretel Navigator Deployment Instructions"
}
```

### Explanation
The code diff indicates a minor update in the "deploy-models-gretel-navigator.md" document, which provides instructions for deploying models using the Gretel Navigator within Azure AI. The primary change involves replacing existing tips that guide users to the general Azure AI content safety documentation with a more focused note referencing specific content safety considerations for serverless APIs. 

In the modified sections, the earlier tips suggesting readers check the broader content safety documentation have been substituted with a directive to include a note about content safety related to serverless APIs: `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. This change enhances the guidance by ensuring users receive information that is more relevant to their specific context when working with the Gretel Navigator. The overall intent of this update is to improve clarity and provide users with more accurate and useful information regarding content safety during model deployment.

## articles/ai-studio/how-to/deploy-models-jais.md{#item-0bd11f}

<details>
<summary>Diff</summary>
````diff
@@ -272,8 +272,7 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
 ::: zone-end
 
@@ -546,8 +545,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -836,8 +835,8 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -1158,8 +1157,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update to Content Safety Tips in JAIS Deployment Instructions"
}
```

### Explanation
The code diff reflects a minor update to the documentation file "deploy-models-jais.md," which outlines the procedures for deploying models using the JAIS service in Azure AI. This update consists mainly of refining existing tips that directed users to the general Azure AI content safety documentation.

In the revised document, the previous tips, which prompted users to review the broader content safety documentation, have been replaced with a more precise reference to the serverless APIs note: `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. This change ensures that users receive tailored guidance that is specifically relevant to their deployment context, thus enhancing the utility and clarity of the documentation.

Overall, the modification seeks to improve the effectiveness of the instructional content by directing readers toward specific information regarding content safety as it pertains to their implementation with JAIS, ultimately leading to a better understanding of content safety measures in their deployments.

## articles/ai-studio/how-to/deploy-models-llama.md{#item-6274a7}

<details>
<summary>Diff</summary>
````diff
@@ -357,11 +357,8 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
@@ -705,11 +702,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
@@ -1065,11 +1059,8 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
@@ -1449,11 +1440,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update to Content Safety Information in Llama Deployment Instructions"
}
```

### Explanation
The code diff represents a minor update to the "deploy-models-llama.md" document, which provides guidance on deploying models using the Llama service in Azure AI. The key changes involve streamlining the content related to Azure AI's content safety settings.

Previously, the document contained tips directing users to the general Azure AI content safety documentation, which have now been replaced with a more relevant include reference: `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. This adjustment helps ensure that users receive targeted information regarding content safety specific to serverless API endpoints.

Additionally, notes that stated "Azure AI content safety is only available for models deployed as serverless API endpoints" have been removed from each section. This revision reduces redundancy since the inclusion note already directs users toward pertinent guidelines.

Overall, these modifications improve the clarity and relevance of the documentation by ensuring that users accessing the Llama deployment instructions are directed to the most applicable information related to content safety, enhancing the user experience and understanding of the deployment process.

## articles/ai-studio/how-to/deploy-models-mistral-codestral.md{#item-83ba03}

<details>
<summary>Diff</summary>
````diff
@@ -466,8 +466,8 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -929,8 +929,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -1414,8 +1414,8 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -2025,8 +2025,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update to Content Safety Guidance in Mistral Codestral Deployment Instructions"
}
```

### Explanation
The code diff indicates a minor update to the documentation file "deploy-models-mistral-codestral.md," which guides users on deploying models using the Mistral Codestral service in Azure AI. This update primarily focuses on revising sections related to Azure AI's content safety settings.

Previously, the document contained a repetitive tip directing users to the general Azure AI content safety documentation. This has been replaced with a more streamlined reference: `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. This change enhances the clarity of the instructions by providing a direct connection to the relevant content safety information needed for serverless API deployments.

The removal of the repeated tips in each section reinforces a cleaner document structure while ensuring that users are still adequately informed about important content safety considerations associated with their deployments.

Overall, these revisions aim to improve the utility and readability of the documentation, directing users specifically to guidance that is most applicable to their deployment scenarios and fostering a better understanding of content safety practices in Azure AI deployments.

## articles/ai-studio/how-to/deploy-models-mistral-nemo.md{#item-e7b729}

<details>
<summary>Diff</summary>
````diff
@@ -461,8 +461,8 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -920,8 +920,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -1401,8 +1401,8 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -2008,8 +2008,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update to Content Safety Directions in Mistral Nemo Deployment Instructions"
}
```

### Explanation
The code diff highlights a minor update to the "deploy-models-mistral-nemo.md" document, which serves as a guide for deploying models using the Mistral Nemo service within Azure AI. The primary focus of this update is to enhance the information relating to Azure AI's content safety settings.

In the previous version, the document included repetitive tips instructing users to consult the general Azure AI content safety documentation. These tips have now been replaced with a more concise directive: `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. This change improves the documentation's clarity by directly directing users to relevant content about serverless API deployments.

The repetitive tips have been removed, which streamlines the document and maintains focus on essential information, reducing potential confusion for users who seek guidance on content safety.

Overall, these updates refine the documentâ€™s structure and usability, ensuring that users have clear access to crucial safety considerations related to deploying Mistral Nemo models, thereby fostering a better grasp of content safety practices in the Azure AI environment.

## articles/ai-studio/how-to/deploy-models-mistral.md{#item-487a41}

<details>
<summary>Diff</summary>
````diff
@@ -510,8 +510,8 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -1019,8 +1019,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -1550,8 +1550,8 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -2207,8 +2207,7 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Refinement of Content Safety Guidance in Mistral Deployment Documentation"
}
```

### Explanation
The code diff reveals a minor update to the "deploy-models-mistral.md" document, which instructs users on how to deploy models utilizing the Mistral service within Azure AI. This update primarily aims to refine the information regarding Azure AI's content safety settings.

In the previous version, the document frequently included tips inviting users to refer to general Azure AI content safety documentation. With the current change, these tips have been replaced by a single, more efficient statement: `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. This modification directs users to relevant information about content safety in a way that is more streamlined and less repetitive.

This modification not only removes redundant content from the document but also enhances its clarity and usability, allowing users to focus on the key actions they need to consider while deploying Mistral models. 

By ensuring that users have clear, concise access to critical content safety guidance without unnecessary repetition, the update improves the overall quality and readability of the documentation. This is particularly beneficial for those looking to navigate Azure AI's content safety protocols effectively during their deployment process.

## articles/ai-studio/how-to/deploy-models-phi-3-5-vision.md{#item-8d6d7d}

<details>
<summary>Diff</summary>
````diff
@@ -308,11 +308,8 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ## Use chat completions with images
 
@@ -699,11 +696,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ## Use chat completions with images
 
@@ -1108,11 +1102,8 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ## Use chat completions with images
 
@@ -1526,11 +1517,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ## Use chat completions with images
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Streamlining Content Safety Guidance in Phi 3.5 Vision Deployment Instructions"
}
```

### Explanation
The code diff shows a minor update to the "deploy-models-phi-3-5-vision.md" document, which provides instructions on deploying the Phi 3.5 Vision model within Azure AI. The update focuses on enhancing the clarity and efficiency of the content safety information provided in the document.

In the previous version, the document included multiple instances of tips advising users to consult the Azure AI content safety documentation. These have now been streamlined into a single inclusion: `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. This change reduces repetition and directs users to pertinent information on content safety more efficiently. 

Additionally, the notes about Azure AI content safety applicabilityâ€”specifying that it is available only for models deployed as serverless API endpointsâ€”were retained, ensuring users still receive critical context regarding content safety limitations.

Overall, this modification enhances the user experience by simplifying the guidance provided, helping users navigate essential content safety considerations without encountering redundant information. This streamlining is particularly beneficial for users looking to deploy models effectively while maintaining compliance with safety protocols in the Azure AI environment.

## articles/ai-studio/how-to/deploy-models-phi-3.md{#item-47e305}

<details>
<summary>Diff</summary>
````diff
@@ -342,11 +342,7 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
-
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
 ::: zone-end
 
@@ -693,11 +689,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
@@ -1056,11 +1049,8 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
@@ -1443,11 +1433,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Enhancement of Content Safety Information in Phi 3 Deployment Guide"
}
```

### Explanation
The code diff indicates a minor update to the "deploy-models-phi-3.md" document, which serves as a guide for deploying the Phi 3 model within Azure AI. The primary focus of this update is on simplifying the presentation of content safety information.

Previously, the document included repeated tips suggesting readers refer to the Azure AI content safety documentation as well as notes about the availability of content safety for models deployed as serverless API endpoints. In the revised version, this redundant information has been replaced with a single directive: `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. This approach consolidates the guidance effectively and directs readers to the necessary context without cluttering the document with repetitive statements.

By removing multiple tips and consolidating the information regarding serverless API endpoints into one inclusion, the documentation is not only made more concise but also clearer, contributing to a better user experience. Users can now access essential information about content safety more efficiently while following the deployment instructions.

Overall, this update enhances the clarity of the document and ensures that users can focus on deploying the Phi 3 model without being distracted by repetitive guidance, thereby facilitating a smoother navigation through the deployment process.

## articles/ai-studio/how-to/deploy-models-phi-4.md{#item-c40212}

<details>
<summary>Diff</summary>
````diff
@@ -312,11 +312,8 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
@@ -633,11 +630,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
@@ -966,11 +960,8 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
@@ -1323,11 +1314,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
-> [!NOTE]
-> Azure AI content safety is only available for models deployed as serverless API endpoints.
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Refinement of Content Safety Information in Phi 4 Deployment Guide"
}
```

### Explanation
The provided code diff reflects a minor update to the "deploy-models-phi-4.md" document, which guides users on deploying the Phi 4 model in Azure AI. This update primarily serves to simplify and enhance the content safety instructions within the document.

In the previous version, the document featured multiple tips instructing users to refer to the Azure AI content safety documentation alongside notes explaining that content safety is applicable only for models deployed as serverless API endpoints. The updated version replaces this repetitive information with a single inclusion directive: `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. This consolidation reduces duplication and directs users efficiently to the necessary information regarding content safety.

By streamlining the guidance, the document becomes clearer and more focused, allowing users to navigate the deployment instructions without being encumbered by redundant text. The retained context regarding the specific applicability of content safety features ensures that crucial information is preserved for the user.

Overall, this update enhances the usability and readability of the document, making it easier for users to follow along with the deployment process while ensuring they remain informed about relevant content safety considerations in the Azure AI context.

## articles/ai-studio/how-to/deploy-models-tsuzumi.md{#item-d3fd51}

<details>
<summary>Diff</summary>
````diff
@@ -266,8 +266,8 @@ except HttpResponseError as ex:
     raise
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -583,8 +583,8 @@ catch (error) {
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
@@ -917,8 +917,7 @@ catch (RequestFailedException ex)
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
 
 ::: zone-end
 
@@ -1317,8 +1316,8 @@ The following example shows how to handle events when the model detects harmful
 }
 ```
 
-> [!TIP]
-> To learn more about how you can configure and control Azure AI content safety settings, check the [Azure AI content safety documentation](https://aka.ms/azureaicontentsafety).
+[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]
+
 
 ::: zone-end
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Streamlining Content Safety Instructions in Tsuzumi Deployment Guide"
}
```

### Explanation
The code diff represents a minor update to the "deploy-models-tsuzumi.md" guide, which assists users in deploying the Tsuzumi model using Azure AI. The primary aim of this revision is to enhance the presentation and accessibility of content safety information.

In the previous version, the guide featured multiple instances where tips encouraged users to refer to the Azure AI content safety documentation. This information has now been replaced with a streamlined directive: `[!INCLUDE [content-safety-serverless-apis-note](../includes/content-safety-serverless-apis-note.md)]`. By consolidating this advice into a single inclusion command, the document reduces redundancy and makes it clearer for the reader.

Additionally, the update includes minor additions and deletions, leading to a total of 15 changes that contribute to a cleaner structure. The important context regarding the applicability of content safety settings remains intact, ensuring that users are still informed about its relevance to models deployed as serverless API endpoints.

Overall, this update improves the clarity and usability of the document, allowing users to focus more efficiently on the deployment process while still receiving essential information about content safety considerations relevant to their model. The streamlined format enhances the overall reading experience, making it easier for users to navigate the guide.

## articles/ai-studio/how-to/healthcare-ai/deploy-cxrreportgen.md{#item-377d15}

<details>
<summary>Diff</summary>
````diff
@@ -16,8 +16,6 @@ author: msakande
 
 # How to use CXRReportGen Healthcare AI model to generate grounded findings
 
-[!INCLUDE [Feature preview](~/reusable-content/ce-skilling/azure/includes/ai-studio/includes/feature-preview.md)]
-
 [!INCLUDE [health-ai-models-meddev-disclaimer](../../includes/health-ai-models-meddev-disclaimer.md)]
 
 In this article, you learn how to deploy CXRReportGen as an online endpoint for real-time inference and issue a basic call to the API. The steps you take are:
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Removal of Feature Preview Note in CXRReportGen Deployment Guide"
}
```

### Explanation
The code diff indicates a minor update to the "deploy-cxrreportgen.md" document, which instructs users on how to implement the CXRReportGen Healthcare AI model for generating medical reports. This particular modification involves the removal of two lines of content from the guide.

Specifically, the section containing the note about "Feature preview" has been removed, which likely indicates that the feature is no longer in preview status or is not relevant for users at this time. By eliminating this mention, the document is streamlined, removing unnecessary information for users who are focused on deploying the model and utilizing its capabilities.

The remaining content includes a disclaimer regarding health AI models, ensuring users are still informed about pertinent considerations when deploying healthcare-related AI solutions.

Overall, this change enhances the clarity and relevance of the guide, allowing users to engage with the material without encountering outdated or non-essential information. The update signifies a careful effort to maintain the document's focus on current deployment practices for the CXRReportGen model.

## articles/ai-studio/how-to/healthcare-ai/deploy-medimageinsight.md{#item-e9ab9e}

<details>
<summary>Diff</summary>
````diff
@@ -16,8 +16,6 @@ author: msakande
 
 # How to use MedImageInsight healthcare AI model for medical image embedding generation
 
-[!INCLUDE [Feature preview](~/reusable-content/ce-skilling/azure/includes/ai-studio/includes/feature-preview.md)]
-
 [!INCLUDE [health-ai-models-meddev-disclaimer](../../includes/health-ai-models-meddev-disclaimer.md)]
 
 In this article, you learn how to deploy MedImageInsight from the model catalog as an online endpoint for real-time inference. You also learn to issue a basic call to the API. The steps you take are:
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Removal of Feature Preview Note in MedImageInsight Deployment Guide"
}
```

### Explanation
The code diff reflects a minor update to the "deploy-medimageinsight.md" document, which guides users on deploying the MedImageInsight healthcare AI model for generating medical image embeddings. This change consists of the removal of two lines from the content of the guide.

Specifically, the note regarding the "Feature preview" has been deleted. This likely means that the feature has either transitioned out of its preview phase or is no longer applicable. Removing this line helps to declutter the document, ensuring that users are not misled by outdated references while focusing on effectively deploying the model.

The remaining content still includes an important disclaimer related to health AI models, ensuring that key compliance and safety information is preserved for the users.

Overall, this update contributes to a clearer and more relevant documentation experience by eliminating references that may no longer pertain to the user's current deployment workflow for the MedImageInsight model. This allows users to concentrate on the essential steps required for successful implementation without distraction from obsolete materials.

## articles/ai-studio/how-to/healthcare-ai/deploy-medimageparse.md{#item-611e84}

<details>
<summary>Diff</summary>
````diff
@@ -16,8 +16,6 @@ author: msakande
 
 # How to use MedImageParse healthcare AI model for segmentation of medical images
 
-[!INCLUDE [Feature preview](~/reusable-content/ce-skilling/azure/includes/ai-studio/includes/feature-preview.md)]
-
 [!INCLUDE [health-ai-models-meddev-disclaimer](../../includes/health-ai-models-meddev-disclaimer.md)]
 
 In this article, you learn how to deploy MedImageParse as an online endpoint for real-time inference and issue a basic call to the API. The steps you take are:
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Removal of Feature Preview Note in MedImageParse Deployment Guide"
}
```

### Explanation
The code diff shows a minor update to the "deploy-medimageparse.md" document, which describes how to deploy the MedImageParse healthcare AI model for segmenting medical images. This particular modification involves the removal of two lines of content from the guide.

In this change, the lines referencing the "Feature preview" have been eliminated. This suggests that the feature is now stable and no longer considered a preview or that the information is not currently relevant. This update cleans up the document, providing users with a streamlined experience that focuses on the essential steps for deploying the MedImageParse model without references to outdated or irrelevant content.

The updated document still retains a disclaimer regarding health AI models, ensuring that users are aware of important considerations and safety information as they implement the model.

Overall, this modification helps to enhance document clarity and relevance by removing unnecessary details, allowing users to concentrate on deploying the MedImageParse model effectively. The document thus remains focused on delivering valuable, current instructions to users aiming to use the MedImageParse functionality.

## articles/ai-studio/how-to/healthcare-ai/healthcare-ai-models.md{#item-12fcfc}

<details>
<summary>Diff</summary>
````diff
@@ -16,8 +16,6 @@ author: msakande
 
 # Foundation models for healthcare AI
 
-[!INCLUDE [Feature preview](~/reusable-content/ce-skilling/azure/includes/ai-studio/includes/feature-preview.md)]
-
 [!INCLUDE [health-ai-models-meddev-disclaimer](../../includes/health-ai-models-meddev-disclaimer.md)]
 
 In this article, you learn about Microsoft's catalog of multimodal healthcare foundation models. The models were developed in collaboration with Microsoft Research, strategic partners, and leading healthcare institutions for healthcare organizations. Healthcare organizations can use the models to rapidly build and deploy AI solutions tailored to their specific needs, while minimizing the extensive compute and data requirements typically associated with building multimodal models from scratch. The intention isn't for these models to serve as standalone products; rather, they're designed for developers to use as a foundation to build upon. With these healthcare AI models, professionals have the tools they need to harness the full potential of AI to enhance biomedical research, clinical workflows, and ultimately care delivery.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Removal of Feature Preview Note in Healthcare AI Models Guide"
}
```

### Explanation
The code diff indicates a minor update to the "healthcare-ai-models.md" document, which outlines Microsoft's catalog of multimodal healthcare foundation models. This update involves the removal of two lines from the article, specifically referencing the "Feature preview."

By eliminating the note about the feature preview, the document becomes more straightforward and focused on providing relevant information without any outdated references. This change suggests that the feature is now stable and no longer in a preview state, which could enhance user confidence in the content being presented.

Despite the removal of the preview note, the article retains an important disclaimer regarding health AI models. This ensures users remain informed about necessary compliance and safety considerations as they explore the use of these models.

Ultimately, this modification contributes to a cleaner and more pertinent document, allowing readers to better understand and utilize Microsoft's healthcare AI models without distractions from unnecessary details. The intent remains clear: to equip healthcare organizations and developers with robust foundational models that can be adapted to specific AI solution requirements in healthcare contexts.

## articles/ai-studio/how-to/model-catalog-overview.md{#item-278001}

<details>
<summary>Diff</summary>
````diff
@@ -27,7 +27,7 @@ The model catalog in Azure AI Foundry portal is the hub to discover and use a wi
 The model catalog organizes models into different collections:
 
 
-* **Curated by Azure AI**: The most popular non-Microsoft open-weight and proprietary models packaged and optimized to work seamlessly on the Azure AI platform. Use of these models is subject to the model providers' license terms. When you deploy these models in Azure AI Foundry portal, their availability is subject to the applicable [Azure service-level agreement (SLA)](https://www.microsoft.com/licensing/docs/view/Service-Level-Agreements-SLA-for-Online-Services), and Microsoft provides support for deployment problems.
+* **Curated by Azure AI**: The most popular partner models (open-weight and proprietary) packaged and optimized to work seamlessly on the Azure AI platform. Use of these models is subject to the model providers' license terms. When you deploy these models in Azure AI Foundry portal, their availability is subject to the applicable [Azure service-level agreement (SLA)](https://www.microsoft.com/licensing/docs/view/Service-Level-Agreements-SLA-for-Online-Services), and Microsoft provides support for deployment problems.
 
   Models from partners such as Meta, NVIDIA, and Mistral AI are examples of models available in this collection on the catalog. You can identify these models by looking for a green checkmark on the model tiles in the catalog. Or you can filter by the **Curated by Azure AI** collection.
 
@@ -97,7 +97,7 @@ Nixtla | Not available | TimeGEN-1
 AI models evolve fast, and when a new version or a new model with updated capabilities in the same model family become available, older models may be retired in the AI Foundry model catalog. To allow for a smooth transition to a newer model version, some models provide users with the option to enable automatic updates. To learn more about the model lifecycle of different models, upcoming model retirement dates, and suggested replacement models and versions, see:
 
 - [Azure OpenAI Service model deprecations and retirements](../../ai-services/openai/concepts/model-retirements.md)
-- [Severless API model deprecations and retirements](../../ai-studio/concepts/model-lifecycle-retirement.md)
+- [Serverless API model deprecations and retirements](../../ai-studio/concepts/model-lifecycle-retirement.md)
 
 ## Managed compute
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Clarification in Model Catalog Overview"
}
```

### Explanation
The code diff presents a minor update to the "model-catalog-overview.md" document, which provides an overview of the model catalog in the Azure AI Foundry portal. This change includes the clarification of terminology and minor adjustments to enhance readability.

Notably, the phrase "most popular non-Microsoft open-weight and proprietary models" has been revised to "most popular partner models (open-weight and proprietary)." This clarification indicates that the models highlighted in this section are sourced from various partners rather than being solely non-Microsoft models. This distinction helps users better understand the source of the models available in the catalog.

Additionally, the update includes a correction to the term "Severless API" which has been changed to "Serverless API." This correction is important for ensuring accurate terminology is used throughout the document, ultimately improving user comprehension.

Overall, these modifications aim to provide clearer information and establish a more precise understanding of the models within the Azure AI Foundry portal's catalog. By refining these details, the document enhances its usefulness for users looking to explore and deploy AI models effectively. The article continues to serve as a valuable resource for users navigating the various offerings curated by Azure AI.

## articles/ai-studio/includes/content-safety-harm-categories.md{#item-8ef139}

<details>
<summary>Diff</summary>
````diff
@@ -0,0 +1,29 @@
+---
+title: include file
+description: include file
+ms.author: pafarley
+ms.service: azure-ai-studio
+ms.topic: include
+ms.date: 01/28/2025
+ms.custom: include
+---
+
+## Understand harm categories
+
+### Harm categories
+
+| Category  | Description         |API term |
+| --------- | ------------------- | --- |
+| Hate and Fairness      | Hate and fairness harms refer to any content that attacks or uses discriminatory language with reference to a person or identity group based on certain differentiating attributes of these groups. <br><br>This includes, but isn't limited to:<ul><li>Race, ethnicity, nationality</li><li>Gender identity groups and expression</li><li>Sexual orientation</li><li>Religion</li><li>Personal appearance and body size</li><li>Disability status</li><li>Harassment and bullying</li></ul> | `Hate` |
+| Sexual  | Sexual describes language related to anatomical organs and genitals, romantic relationships and sexual acts, acts portrayed in erotic or affectionate terms, including those portrayed as an assault or a forced sexual violent act against one's will. <br><br> This includes but isn't limited to:<ul><li>Vulgar content</li><li>Prostitution</li><li>Nudity and Pornography</li><li>Abuse</li><li>Child exploitation, child abuse, child grooming</li></ul>   | `Sexual` |
+| Violence  | Violence describes language related to physical actions intended to hurt, injure, damage, or kill someone or something; describes weapons, guns, and related entities. <br><br>This includes, but isn't limited to:  <ul><li>Weapons</li><li>Bullying and intimidation</li><li>Terrorist and violent extremism</li><li>Stalking</li></ul>  | `Violence` |
+| Self-Harm  | Self-harm describes language related to physical actions intended to purposely hurt, injure, damage one's body or kill oneself. <br><br> This includes, but isn't limited to: <ul><li>Eating Disorders</li><li>Bullying and intimidation</li></ul>  | `SelfHarm` |
+
+### Severity levels 
+
+| Level | Description |
+| --- | ---|
+|Safe |Content might be related to violence, self-harm, sexual, or hate categories. However, the terms are used in general, journalistic, scientific, medical, and similar professional contexts, which are appropriate for most audiences. |
+|Low |Content that expresses prejudiced, judgmental, or opinionated views, includes offensive use of language, stereotyping, use-cases exploring a fictional world (for example, gaming, literature) and depictions at low intensity.| 
+|Medium |Content that uses offensive, insulting, mocking, intimidating, or demeaning language towards specific identity groups, includes depictions of seeking and executing harmful instructions, fantasies, glorification, promotion of harm at medium intensity. |
+|High |Content that displays explicit and severe harmful instructions, actions, damage, or abuse; includes endorsement, glorification, or promotion of severe harmful acts, extreme or illegal forms of harm, radicalization, or nonconsensual power exchange or abuse. |
\ No newline at end of file
````
</details>

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "Introduction of Content Safety Harm Categories"
}
```

### Explanation
This code diff introduces a new document titled "content-safety-harm-categories.md" to the Azure AI documentation. The document outlines the categories of harm related to content safety, providing a structured framework for understanding various harmful content types and their severity levels in AI systems.

The document consists of two primary sections: **Harm Categories** and **Severity Levels**. In the harm categories section, specific categories such as "Hate and Fairness," "Sexual," "Violence," and "Self-Harm" are defined. Each category includes a description and a list of examples, highlighting the types of content that fall under these classifications. This structured approach assists users in recognizing the different forms of harmful content that AI applications might encounter.

In the severity levels section, four levelsâ€”Safe, Low, Medium, and Highâ€”describe the potential impact of content on users. This classification helps in understanding how AI systems can assess and respond to content based on its harmful nature.

Overall, this addition serves to improve transparency and understanding regarding content moderation and safety within AI applications, providing critical insights that can help developers and users better navigate the complexities of AI ethics and content safety. The inclusion of such guidelines is a vital step toward responsible AI deployment and usage.

## articles/ai-studio/includes/content-safety-serverless-apis-note.md{#item-779e7e}

<details>
<summary>Diff</summary>
````diff
@@ -0,0 +1,13 @@
+---
+title: include file
+description: include file
+author: msakande
+ms.author: mopeakande
+ms.service: azure-ai-studio
+ms.topic: include
+ms.date: 02/04/2025
+ms.custom: include file
+---
+
+> [!NOTE]
+> Azure AI content safety is currently available for models deployed as serverless API endpoints, but not to models deployed via managed compute. To learn more about Azure AI content safety for models deployed as serverless APIs, see [Content safety for models curated by Azure AI in the model catalog](../concepts/model-catalog-content-safety.md).
````
</details>

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "Addition of Note on Content Safety for Serverless APIs"
}
```

### Explanation
The code diff introduces a new note in the "content-safety-serverless-apis-note.md" file, which emphasizes important information regarding Azure AI content safety features. This addition is aimed at clarifying the availability of content safety measures specifically for models deployed via serverless API endpoints.

This note indicates that while Azure AI content safety is currently supported for serverless APIs, it is not available for models that are deployed through managed compute. This distinction is crucial for users and developers as it directly affects how they implement content safety measures within their applications.

Furthermore, the note provides a reference link to additional resources, particularly to the "Content safety for models curated by Azure AI in the model catalog" document. This link serves as a pathway for users to gain deeper insights into the content safety features available for these models, ensuring they have access to the necessary information for effective deployment and management.

Overall, the addition enhances the documentation by providing key insights into the capabilities of Azure AI content safety in relation to serverless APIs, which is vital for ensuring safe and responsible use of AI technologies in various applications.

## articles/ai-studio/includes/content-safety-serverless-models.md{#item-8fe192}

<details>
<summary>Diff</summary>
````diff
@@ -13,7 +13,7 @@ ms.custom: include file
 # Also used in Azure Machine Learning documentation
 ---
 
-For language models deployed via serverless APIs, Azure AI implements a default configuration of [Azure AI Content Safety](/azure/ai-services/content-safety/overview) text moderation filters that detect harmful content such as hate, self-harm, sexual, and violent content. To learn more about content filtering (preview), see [Harm categories in Azure AI Content Safety](/azure/ai-services/content-safety/concepts/harm-categories).
+For language models deployed via serverless APIs, Azure AI implements a default configuration of [Azure AI Content Safety](../../ai-services/content-safety/overview.md) text moderation filters that detect harmful content such as hate, self-harm, sexual, and violent content. To learn more about content filtering (preview), see [Content safety for models curated by Azure AI in the model catalog](../concepts/model-catalog-content-safety.md). 
 
 > [!TIP]
 > Content filtering (preview) is not available for certain model types that are deployed via serverless APIs. These model types include embedding models and time series models.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update of References in Serverless Models Content Safety Documentation"
}
```

### Explanation
In this code diff, a minor update was made to the "content-safety-serverless-models.md" file, specifically concerning the references provided in the text pertaining to Azure AI's content safety features for serverless API deployments.

The modification involves changing the URL path for the link to the overview of Azure AI Content Safety. The original link was updated to reflect a more appropriate relative path, ensuring better navigation within the documentation. The previous link pointed to a broader overview, whereas the new link directs users to the "Content safety for models curated by Azure AI in the model catalog," offering more specific information related to the subject matter.

Additionally, the content itself remains focused on the implementation of default text moderation filters for language models deployed via serverless APIs. These filters are designed to detect various forms of harmful content, including hate speech, self-harm, sexual content, and violence. The note also emphasizes that content filtering (in preview) may not be available for certain model types such as embedding and time series models.

Overall, this modification improves the clarity and usability of the documentation, guiding users effectively to the relevant resources and ensuring that they have the most current and accurate information regarding content safety in their AI applications.

## articles/ai-studio/toc.yml{#item-2745cd}

<details>
<summary>Diff</summary>
````diff
@@ -200,6 +200,8 @@ items:
         - name: Consume serverless API models from a different project or hub
           href: how-to/deploy-models-serverless-connect.md
           displayName: maas, paygo, models-as-a-service
+        - name: Content safety for models deployed with serverless APIs
+          href: concepts/model-catalog-content-safety.md
         - name: Model and region availability for Serverless API deployments
           href: how-to/deploy-models-serverless-availability.md
       - name: Managed compute
@@ -416,8 +418,10 @@ items:
     href: responsible-use-of-ai-overview.md
   - name: What is Azure AI Content Safety?
     href: ai-services/content-safety-overview.md
-  - name: Use Azure AI Content Safety in the portal
-    href: ai-services/how-to/content-safety.md
+  - name: Content safety for models deployed with serverless APIs
+    href: concepts/model-catalog-content-safety.md
+  - name: Use Azure AI content safety in the portal
+    href: ../ai-services/content-safety/how-to/foundry.md?context=/azure/ai-studio/context/context
   - name: Content filtering
     href: concepts/content-filtering.md
   - name: Use blocklists
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update of Table of Contents for Azure AI Studio"
}
```

### Explanation
The code diff reflects a minor update to the "toc.yml" file for Azure AI Studio, which organizes the navigation structure of the documentation. This modification includes the addition of new entries as well as some adjustments to existing links for improved clarity and navigation.

Notable changes include the introduction of a new section titled "Content safety for models deployed with serverless APIs," which links to the relevant concepts document. This addition indicates a growing focus on the content safety measures applicable to serverless API deployments, providing users with direct access to knowledge regarding safe model governance.

Further adjustments were made to existing entries; specifically, the previous link for "Use Azure AI Content Safety in the portal" has been updated to redirect users to a more appropriate path that leads to the content safety resources related to Foundry within the Azure AI environment.

Overall, these changes enhance the structure of the table of contents by ensuring that users can easily navigate through the important topics related to Azure AI content safety and its applications in serverless environments, thus supporting usersâ€™ ability to locate relevant documentation efficiently.


