---
date: '2025-07-29'
permalink: https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:c91b816...MicrosoftDocs:e0fd9e5
summary: 'Summary: The recent updates to the Azure AI Search documentation involve
  minor adjustments that enhance link accuracy, improve tutorial structures, and update
  redirection configurations. New features include a section on accelerators and improved
  guidance on enrichment caching management, while there are no significant breaking
  changes. The modifications aim to improve clarity and usability, ensuring users
  have access to relevant resources and structured guidance for optimizing their use
  of Azure AI Search. Overall, the changes reflect a commitment to maintaining high
  documentation quality and user support.'
title: '[en_US] Diff Insight Report - search'

---

[View Diff on GitHub](https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:c91b816...MicrosoftDocs:e0fd9e5){target="_blank"}

# Highlights
The code diff primarily involves minor updates across various documentation files related to Azure AI Search. The changes showcase improvements in link accuracy, enhancements to tutorial structures, updates to redirection configurations, and the introduction of new resources like accelerators for better user navigation and resource management.

## New features
- A new section on accelerators enhancing productivity in Azure AI Search is added to `resource-tools.md` and `samples-python.md`.
- Improved guidance on enrichment caching configuration and management with newly renamed documents.

## Breaking changes
There are no significant breaking changes, as most updates are aimed at enhancing clarity, improving link accuracy, and refining user navigation within the documentation.

## Other updates
- Systematic updates and replacements of outdated links with new, relevant resources across multiple documents, helping to guide users more effectively.
- Clarification of roles required for accessing enrichment caching and other Azure AI Search features.
- Updated performance and resource management insights to improve user understanding.

# Insights
The updates in the diff indicate a concerted effort to maintain a high standard of documentation quality for Azure AI Search by improving link accuracy, providing clearer guidance, and introducing new helpful sections such as accelerators. These changes enhance usability and ensure that users have access to relevant, up-to-date resources. 

One of the key modifications involves updating links to point to newly consolidated and focused resources on enrichment caching, reflecting a shift to more structured and detailed guidance on this topic. Such updates are crucial for users aiming to optimize their Azure AI Search usage, particularly concerning caching configurations which are vital in managing workflow efficiency and cost.

A significant addition is the introduction of an accelerators section, which aims to boost user productivity by providing end-to-end solutions and customizable documentation for specific scenarios. This not only enhances the resources available to developers but also encourages experimentation and adaptation of Azure AI Search capabilities to meet unique project needs.

Overall, these updates show a clear drive towards making Azure AI Search documentation more comprehensive, navigable, and useful to its audience by aligning with the latest developments and best practices in AI search solutions.

# Summary Table
|  Filename  | Type |    Title    | Status | A  | D  | M  |
|------------|------|-------------|--------|----|----|----|
| [.openpublishing.redirection.search.json](#item-8b66f9) | minor update | Update Redirection Configurations for Search Articles | modified | 10 | 0 | 10 | 
| [cognitive-search-attach-cognitive-services.md](#item-68eaec) | minor update | Update Link for Incremental Enrichment Configuration | modified | 1 | 1 | 2 | 
| [cognitive-search-concept-intro.md](#item-bf9ed7) | minor update | Update Links for Enrichment Cache Configuration | modified | 3 | 3 | 6 | 
| [cognitive-search-defining-skillset.md](#item-e2d71d) | minor update | Update Link for Enrichment Caching Configuration | modified | 1 | 1 | 2 | 
| [cognitive-search-tutorial-debug-sessions.md](#item-7e10e9) | minor update | Update Link for Incremental Enrichment Caching Configuration | modified | 1 | 1 | 2 | 
| [cognitive-search-working-with-skillsets.md](#item-6091d1) | minor update | Update Link for Enrichment Caching Configuration | modified | 1 | 1 | 2 | 
| [enrichment-cache-how-to-configure.md](#item-b0ae0b) | minor update | Rename and Update Enrichment Cache Configuration Guide | renamed | 30 | 30 | 60 | 
| [enrichment-cache-how-to-manage.md](#item-a972bd) | minor update | Rename and Update Enrichment Caching Management Guide | renamed | 18 | 21 | 39 | 
| [knowledge-store-concept-intro.md](#item-7475c2) | minor update | Update Link for Enabling Caching of Enriched Documents | modified | 1 | 1 | 2 | 
| [knowledge-store-projection-example-long.md](#item-e18999) | minor update | Update Reference Link for Caching Configuration | modified | 1 | 1 | 2 | 
| [knowledge-store-projection-overview.md](#item-81aa4a) | minor update | Update Reference Link for Enrichment Caching | modified | 1 | 1 | 2 | 
| [knowledge-store-projections-examples.md](#item-9bfff5) | minor update | Update Reference Link for Enrichment Caching | modified | 1 | 1 | 2 | 
| [resource-tools.md](#item-0c6ac1) | minor update | Update and Organize Accelerators Section | modified | 10 | 9 | 19 | 
| [retrieval-augmented-generation-overview.md](#item-ec76e0) | minor update | Add References and Update See Also Section | modified | 3 | 1 | 4 | 
| [samples-dotnet.md](#item-12f3fa) | minor update | Remove Knowledge Mining Solution Accelerator Reference | modified | 0 | 1 | 1 | 
| [samples-python.md](#item-d2bf09) | new feature | Add Accelerators Section with RAG Experiment Accelerator | modified | 8 | 0 | 8 | 
| [search-api-preview.md](#item-511f5d) | minor update | Update Incremental Enrichment Cache Link in Preview Features | modified | 1 | 1 | 2 | 
| [search-features-list.md](#item-d34448) | minor update | Update Enrichment Caching Link in Search Features List | modified | 1 | 1 | 2 | 
| [search-file-storage-integration.md](#item-d20e26) | minor update | Update Link for Indexer Cache in File Storage Integration | modified | 1 | 1 | 2 | 
| [search-how-to-create-indexers.md](#item-de71fb) | minor update | Update Link for Enrichment Caching in Indexer Creation Guide | modified | 2 | 2 | 4 | 
| [search-how-to-index-onelake-files.md](#item-95f3db) | minor update | Update Link for Indexer Cache in OneLake Files Indexing Guide | modified | 1 | 1 | 2 | 
| [search-howto-index-changed-deleted-blobs.md](#item-32a688) | minor update | Clarification on Soft Delete Support for Azure Blob Storage | modified | 1 | 1 | 2 | 
| [search-howto-indexing-azure-blob-storage.md](#item-dc4668) | minor update | Update Link for Indexer Cache in Azure Blob Storage Indexing Guide | modified | 1 | 1 | 2 | 
| [search-howto-managed-identities-data-sources.md](#item-edf98d) | minor update | Link Update for Enrichment Cache in Managed Identities Data Sources Guide | modified | 2 | 2 | 4 | 
| [search-howto-managed-identities-storage.md](#item-8209c4) | minor update | Correction of Enrichment Cache Link and Access Roles in Managed Identities Storage Guide | modified | 1 | 1 | 2 | 
| [search-howto-run-reset-indexers.md](#item-fb10c8) | minor update | Update to Enrichment Cache Link in Reset Indexers Guide | modified | 2 | 2 | 4 | 
| [search-indexer-access-control-lists-and-role-based-access.md](#item-67b42f) | minor update | Update Link for Indexer Enrichment Cache in Access Control Lists Guide | modified | 1 | 1 | 2 | 
| [search-indexer-howto-access-trusted-service-exception.md](#item-e19826) | minor update | Update Link for Enrichment Caching in Trusted Service Exception Guide | modified | 1 | 1 | 2 | 
| [search-performance-analysis.md](#item-5032b3) | minor update | Correct Round-Trip Duration in Performance Analysis Guide | modified | 1 | 1 | 2 | 
| [search-relevance-overview.md](#item-cb0e09) | minor update | Clarify Relevance Tuning Criteria in Overview | modified | 1 | 1 | 2 | 
| [search-reliability.md](#item-3e9b1a) | minor update | Update Resource Links for Clarity | modified | 1 | 1 | 2 | 
| [search-security-overview.md](#item-6b3f1e) | minor update | Update Links for Enrichment Cache Guidelines | modified | 2 | 2 | 4 | 
| [search-sku-manage-costs.md](#item-6e0122) | minor update | Update Links for Enrichment Caching Resource | modified | 2 | 2 | 4 | 
| [toc.yml](#item-c4768f) | minor update | Update Table of Contents for Azure AI Search | modified | 6 | 6 | 12 | 
| [tutorial-rag-build-solution-minimize-storage.md](#item-088ad8) | minor update | Update Next Steps in RAG Build Solution Tutorial | modified | 2 | 2 | 4 | 
| [tutorial-skillset.md](#item-8e61e7) | minor update | Update Title and References in Skillset Tutorial | modified | 3 | 3 | 6 | 


# Modified Contents
## articles/search/.openpublishing.redirection.search.json{#item-8b66f9}

<details>
<summary>Diff</summary>
````diff
@@ -1,5 +1,15 @@
 {
     "redirections": [
+        {
+            "source_path_from_root": "/articles/search/cognitive-search-incremental-indexing-conceptual.md",
+            "redirect_url": "/azure/search/enrichment-cache-how-to-manage",
+            "redirect_document_id": true
+        },
+                {
+            "source_path_from_root": "/articles/search/search-howto-incremental-index.md",
+            "redirect_url": "/azure/search/enrichment-cache-how-to-configure",
+            "redirect_document_id": true
+        },
         {
             "source_path_from_root": "/articles/search/search-security-network-security-perimiter.md",
             "redirect_url": "/azure/search/search-security-network-security-perimeter",
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Redirection Configurations for Search Articles"
}
```

### Explanation
The recent modification involves updates to the `.openpublishing.redirection.search.json` file, specifically for the Azure AI documentation. A total of 10 lines were added, enhancing the redirection features for specific search articles. This update includes two new redirection entries that link previously defined source paths to new target URLs, enabling users to be redirected to relevant content within the Azure documentation. 

The new entries specify that requests for the articles related to "cognitive search incremental indexing" and "search how-to incremental index" will now redirect to more appropriate pages that cover managing and configuring the enrichment cache. This minor update aims to improve user navigation and ensure that the documentation is kept up to date with the relevant information freely accessible to users exploring Azure AI services.

## articles/search/cognitive-search-attach-cognitive-services.md{#item-68eaec}

<details>
<summary>Diff</summary>
````diff
@@ -321,7 +321,7 @@ A [query-time vectorizer](vector-search-how-to-configure-vectorizer.md) backed b
 Image extraction is an Azure AI Search operation that occurs when documents are cracked prior to enrichment. Image extraction is billable on all tiers, except for 20 free daily extractions on the free tier. Image extraction costs apply to image files inside blobs, embedded images in other files (PDF and other app files), and for images extracted using [Document Extraction](cognitive-search-skill-document-extraction.md). For image extraction pricing, see the [Azure AI Search pricing page](https://azure.microsoft.com/pricing/details/search/).
 
 > [!TIP]
-> To lower the cost of skillset processing, enable [incremental enrichment](cognitive-search-incremental-indexing-conceptual.md) to cache and reuse any enrichments that are unaffected by changes made to a skillset. Caching requires Azure Storage (see [pricing](https://azure.microsoft.com/pricing/details/storage/blobs/) but the cumulative cost of skillset execution is lower if existing enrichments can be reused, especially for skillsets that use image extraction and analysis.
+> To lower the cost of skillset processing, enable [incremental enrichment](enrichment-cache-how-to-configure.md) to cache and reuse any enrichments that are unaffected by changes made to a skillset. Caching requires Azure Storage (see [pricing](https://azure.microsoft.com/pricing/details/storage/blobs/) but the cumulative cost of skillset execution is lower if existing enrichments can be reused, especially for skillsets that use image extraction and analysis.
 
 ## Example: Estimate costs
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Incremental Enrichment Configuration"
}
```

### Explanation
This modification makes a minor update to the `cognitive-search-attach-cognitive-services.md` file, specifically correcting a hyperlink related to incremental enrichment in the Azure AI documentation. In this change, the link pointing to the configuration for enabling incremental enrichment has been updated from a previously defined URL to a new one.

The update consists of one line being added and one line being deleted, resulting in a clearer and more accurate reference for users looking to reduce the costs associated with skillset processing by caching and reusing enrichments. This ensures that users have access to the most relevant and correct instructional material on configuring incremental enrichment, which is an important optimization in Azure AI Search service usage. The overall goal of this modification is to enhance the usability and reliability of documentation for readers utilizing cognitive services.

## articles/search/cognitive-search-concept-intro.md{#item-bf9ed7}

<details>
<summary>Diff</summary>
````diff
@@ -43,7 +43,7 @@ The following diagram shows the progression of AI enrichment:
 
 + Enrichment starts when the indexer ["cracks documents"](search-indexer-overview.md#document-cracking) and extracts images and text. The kind of processing that occurs next depends on your data and which skills you've added to a skillset. If you have images, they can be forwarded to skills that perform image processing. Text content is queued for text and natural language processing. Internally, skills create an ["enriched document"](cognitive-search-working-with-skillsets.md#enrichment-tree) that collects the transformations as they occur.
 
-+ Enriched content is generated during skillset execution, and is temporary unless you save it. You can enable an [enrichment cache](cognitive-search-incremental-indexing-conceptual.md) to persist cracked documents and skill outputs for subsequent reuse during future skillset executions.
++ Enriched content is generated during skillset execution, and is temporary unless you save it. You can enable an [enrichment cache](enrichment-cache-how-to-configure.md) to persist cracked documents and skill outputs for subsequent reuse during future skillset executions.
 
 + To get content into a search index, the indexer must have mapping information for sending enriched content to target field. [Field mappings](search-indexer-field-mappings.md) (explicit or implicit) set the data path from source data to a search index. [Output field mappings](cognitive-search-output-field-mapping.md) set the data path from enriched documents to an index.
 
@@ -84,7 +84,7 @@ In Azure AI Search, an indexer saves the output it creates. A single indexer run
 |------------|----------|----------|-------------|
 | [**searchable index**](search-what-is-an-index.md) | Required | Search service | Used for full text search and other query forms. Specifying an index is an indexer requirement. Index content is populated from skill outputs, plus any source fields that are mapped directly to fields in the index. |
 | [**knowledge store**](knowledge-store-concept-intro.md) | Optional | Azure Storage | Used for downstream apps like knowledge mining or data science. A knowledge store is defined within a skillset. Its definition determines whether your enriched documents are projected as tables or objects (files or blobs) in Azure Storage. |
-| [**enrichment cache**](cognitive-search-incremental-indexing-conceptual.md) | Optional | Azure Storage | Used for caching enrichments for reuse in subsequent skillset executions. The cache stores imported, unprocessed content (cracked documents). It also stores the enriched documents created during skillset execution. Caching is helpful if you're using image analysis or OCR, and you want to avoid the time and expense of reprocessing image files. |
+| [**enrichment cache**](enrichment-cache-how-to-configure.md) | Optional | Azure Storage | Used for caching enrichments for reuse in subsequent skillset executions. The cache stores imported, unprocessed content (cracked documents). It also stores the enriched documents created during skillset execution. Caching is helpful if you're using image analysis or OCR, and you want to avoid the time and expense of reprocessing image files. |
 
 Indexes and knowledge stores are fully independent of each other. While you must attach an index to satisfy indexer requirements, if your sole objective is a knowledge store, you can ignore the index after it's populated.
 
@@ -126,7 +126,7 @@ Start with a subset of data in a [supported data source](search-indexer-overview
 
    An indexer is also where you specify field mappings and output field mappings that set up the data path to a search index.
 
-   Optionally, [enable enrichment caching](cognitive-search-incremental-indexing-conceptual.md) in the indexer configuration. This step allows you to reuse existing enrichments later on.
+   Optionally, [enable enrichment caching](enrichment-cache-how-to-configure.md) in the indexer configuration. This step allows you to reuse existing enrichments later on.
 
 1. [Run queries](search-query-create.md) to evaluate results or [start a debug session](cognitive-search-how-to-debug-skillset.md) to work through any skillset issues.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Links for Enrichment Cache Configuration"
}
```

### Explanation
This modification introduces minor changes to the `cognitive-search-concept-intro.md` file, primarily focusing on updating the links related to the enrichment cache configuration within Azure AI Search documentation. The update involves substituting the previous link with a more appropriate one, enhancing the accuracy and usability of the referenced content.

Three lines were added while three lines were deleted, resulting in a total of six changes. The corrections ensure that users are directed to the correct documentation page for configuring the enrichment cache, which is essential for persisting enriched content during skillset execution. This update aims to improve the clarity and effectiveness of the information provided to users, ensuring that they can navigate easily to the necessary resources regarding configuration options for the enrichment cache. Overall, the changes enhance the educational value of the document while maintaining its core content on cognitive search concepts in Azure.

## articles/search/cognitive-search-defining-skillset.md{#item-e2d71d}

<details>
<summary>Diff</summary>
````diff
@@ -30,7 +30,7 @@ Rules for skillset definition include:
 Indexers drive skillset execution. You need an [indexer](search-howto-create-indexers.md), [data source](search-data-sources-gallery.md), and [index](search-what-is-an-index.md) before you can test your skillset.
 
 > [!TIP]
-> Enable [enrichment caching](cognitive-search-incremental-indexing-conceptual.md) to reuse the content you've already processed and lower the cost of development.
+> Enable [enrichment caching](enrichment-cache-how-to-configure.md) to reuse the content you've already processed and lower the cost of development.
 
 ## Add a skillset definition
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Enrichment Caching Configuration"
}
```

### Explanation
This code diff represents a minor update to the `cognitive-search-defining-skillset.md` file, specifically modifying the link related to enabling enrichment caching within Azure AI Search documentation. The change entails replacing the old link with a new one that points to the appropriate resource for configuring enrichment caching.

In total, one line was added, and one line was deleted, marking a change in hyperlinked content. This update enhances the accuracy of the documentation by guiding users to the correct page where they can learn how to enable enrichment caching. This feature is important as it helps in reusing previously processed content, thereby reducing development costs. Overall, this modification aims to improve the clarity and practicality of the guidance provided for defining skillsets in cognitive search workflows.

## articles/search/cognitive-search-tutorial-debug-sessions.md{#item-7e10e9}

<details>
<summary>Diff</summary>
````diff
@@ -270,4 +270,4 @@ This tutorial touched on various aspects of skillset definition and processing.
 
 + [Skillsets in Azure AI Search](cognitive-search-working-with-skillsets.md)
 
-+ [How to configure caching for incremental enrichment](cognitive-search-incremental-indexing-conceptual.md)
++ [How to configure caching for incremental enrichment](enrichment-cache-how-to-configure.md)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Incremental Enrichment Caching Configuration"
}
```

### Explanation
This modification entails a minor update to the `cognitive-search-tutorial-debug-sessions.md` file, focusing on correcting the link that provides information on configuring caching for incremental enrichment in Azure AI Search. The change consists of replacing the previous link with a new and more relevant one that directs users to the correct documentation for configuration.

In the diff, one line was added, and one line was deleted, leading to a total of two changes. This update ensures that users are accurately guided to the appropriate resource where they can learn how to configure caching mechanisms effectively. Improving the documentation in this way enhances its usability, providing clearer and more accurate instructions for users looking to optimize their skillset processing in Azure AI Search. Thus, this change contributes to a better user experience in understanding how to work with skillsets and caching in debug sessions.

## articles/search/cognitive-search-working-with-skillsets.md{#item-6091d1}

<details>
<summary>Diff</summary>
````diff
@@ -126,7 +126,7 @@ Notice how the output of the first skill ("pages") is used in sentiment analysis
 
 An enriched document is a temporary, tree-like data structure created during skillset execution that collects all of the changes introduced through skills. Collectively, enrichments are represented as a hierarchy of addressable nodes. Nodes also include any unenriched fields that are passed in verbatim from the external data source. The best approach for examining the structure and content of an enrichment tree is through a [debug session](cognitive-search-debug-session.md) in the Azure portal.
 
-An enriched document exists for the duration of skillset execution, but can be [cached](cognitive-search-incremental-indexing-conceptual.md) or sent to a [knowledge store](knowledge-store-concept-intro.md). 
+An enriched document exists for the duration of skillset execution, but can be [cached](enrichment-cache-how-to-configure.md) or sent to a [knowledge store](knowledge-store-concept-intro.md). 
 
 Initially, an enriched document is simply the content extracted from a data source during [*document cracking*](search-indexer-overview.md#document-cracking), where text and images are extracted from the source and made available for language or image analysis. 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Enrichment Caching Configuration"
}
```

### Explanation
This code diff involves a minor update to the `cognitive-search-working-with-skillsets.md` file, specifically altering the hyperlink associated with caching enriched documents during skillset execution in Azure AI Search documentation. The previous link, which pointed to an older resource, has been replaced with a new link that directs users to the updated guide on how to configure caching.

The modification includes one addition and one deletion, resulting in a total of two changes. By correcting the link, the documentation ensures that users can access current information regarding caching processes, which can enhance performance and efficiency in handling enriched documents. This enhances user understanding and experience when navigating the process of working with skillsets in Azure AI Search by providing more accurate and relevant resources. Overall, the update reflects a commitment to maintaining high-quality documentation that evolves with the platform's development.

## articles/search/enrichment-cache-how-to-configure.md{#item-b0ae0b}

<details>
<summary>Diff</summary>
````diff
@@ -1,23 +1,23 @@
 ---
-title: Enable caching for incremental enrichment (preview)
+title: Configure enrichment caching (preview)
 titleSuffix: Azure AI Search
-description: Enable caching of enriched content for potential reuse when modifying downstream skills and projections in an AI enrichment pipeline.
+description: Cache enriched content for potential reuse when modifying downstream skills and projections in an AI enrichment pipeline.
 author: HeidiSteen
 ms.author: heidist
 ms.service: azure-ai-search
 ms.topic: how-to
-ms.date: 02/24/2025
+ms.date: 07/28/2025
 ms.custom:
   - ignite-2023
   - sfi-ropc-nochange
 ---
 
-# Enable caching for incremental enrichment in Azure AI Search
+# Configure an enrichment cache
 
 > [!IMPORTANT] 
 > This feature is in public preview under [supplemental terms of use](https://azure.microsoft.com/support/legal/preview-supplemental-terms/). [Preview REST APIs](/rest/api/searchservice/index-preview) support this feature.
 
-This article explains how to add caching to an enrichment pipeline so that you can modify downstream enrichment steps without having to rebuild in full every time. By default, a skillset is stateless, and changing any part of its composition requires a full rerun of the indexer. With an [**enrichment cache**](cognitive-search-incremental-indexing-conceptual.md), the indexer can determine which parts of the document tree must be refreshed based on changes detected in the skillset or indexer definitions. Existing processed output is preserved and reused wherever possible. 
+This article explains how to add caching to an enrichment pipeline so that you can modify downstream enrichment steps without having to rebuild in full every time. By default, a skillset is stateless, and changing any part of its composition requires a full rerun of the indexer. With an *enrichment cache*, the indexer can determine which parts of the document tree must be refreshed based on changes detected in the skillset or indexer definitions. Existing processed output is preserved and reused wherever possible. 
 
 Cached content is placed in Azure Storage using account information that you provide. The container, named `ms-az-search-indexercache-<alpha-numerc-string>`, is created when you run the indexer. It should be considered an internal component managed by your search service and must not be modified.
 
@@ -27,18 +27,20 @@ Cached content is placed in Azure Storage using account information that you pro
 
 + [For blob indexing only](search-howto-indexing-azure-blob-storage.md), if you need synchronized document removal from both the cache and index when blobs are deleted from your data source, enable a [deletion policy](search-howto-index-changed-deleted-blobs.md) in the indexer. Without this policy, document deletion from the cache isn't supported.
 
-You should be familiar with setting up indexers. Start with [indexer overview](search-indexer-overview.md) and then continue on to [skillsets](cognitive-search-working-with-skillsets.md) to learn about enrichment pipelines. For more background on key concepts, see [incremental enrichment](cognitive-search-incremental-indexing-conceptual.md).
+You should be familiar with setting up indexers and skillsets. Start with [indexer overview](search-indexer-overview.md) and then continue on to [skillsets](cognitive-search-working-with-skillsets.md) to learn about enrichment pipelines. 
+
+## Limitations
 
 > [!CAUTION]
-> Avoid enrichment caching for data originating from the [SharePoint Online indexer (Preview)](search-howto-index-sharepoint-online.md). Under certain circumstances, the cache becomes invalid, requiring a [full indexer reset and run](search-howto-run-reset-indexers.md), should you choose to reload it.
+> If you're using the [SharePoint Online indexer (Preview)](search-howto-index-sharepoint-online.md), you should avoid incremental enrichment. Under certain circumstances, the cache becomes invalid, requiring an [indexer reset and full rebuild](search-howto-run-reset-indexers.md), should you choose to reload it.
 
 ## Permissions
 
-Azure AI Search needs write-access to Azure Storage. If you're using a managed identity for your search service, make sure it's assigned to the **Storage Blob Data Contributor** and **Storage Table Data Reader** roles. For more information, see [Connect to Azure Storage using a managed identity (Azure AI Search)](search-howto-managed-identities-storage.md).
+Azure AI Search needs write-access to Azure Storage. If you're using a managed identity for your search service, make sure it's assigned to the **Storage Blob Data Contributor** and **Storage Table Data Contributor** roles. For more information, see [Connect to Azure Storage using a managed identity (Azure AI Search)](search-howto-managed-identities-storage.md).
 
 ## Enable on new indexers
 
-You can use the Azure portal, preview APIs, or beta Azure SDKs are required to enable an enrichment cache on an indexer.
+You can use the Azure portal, preview APIs, or preview Azure SDK packages to enable an enrichment cache on an indexer.
 
 ### [**Azure portal**](#tab/portal)
 
@@ -50,18 +52,18 @@ You can use the Azure portal, preview APIs, or beta Azure SDKs are required to e
 
 ### [**REST**](#tab/rest)
 
-On new indexers, add the "cache" property in the indexer definition payload when calling Create or Update Indexer. 
+On new indexers, add the `cache` property in the indexer definition payload when calling Create or Update Indexer. 
 
-You can use preview API versions 2021-04-30-preview and later. We recommend the latest preview for [Create or Update Indexer (2024-05-01-preview)](/rest/api/searchservice/indexers/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true).
+We recommend the latest preview for [Create or Update Indexer (2025-05-01-preview)](/rest/api/searchservice/indexers/create-or-update?view=rest-searchservice-2025-05-01-preview&preserve-view=true).
 
 ```https
-POST https://[service name].search.windows.net/indexers?api-version=2024-05-01-preview
+POST https://[service name].search.windows.net/indexers?api-version=2025-05-01-preview
     {
         "name": "<YOUR-INDEXER-NAME>",
         "targetIndexName": "<YOUR-INDEX-NAME>",
         "dataSourceName": "<YOUR-DATASOURCE-NAME>",
         "skillsetName": "<YOUR-SKILLSET-NAME>",
-        "cache" : {
+        `cache` : {
             "storageConnectionString" : "<YOUR-STORAGE-ACCOUNT-CONNECTION-STRING>",
             "enableReprocessing": true
         },
@@ -79,29 +81,29 @@ For existing indexers that already have a skillset, use the following steps to a
 
 ### Step 1: Get the indexer definition
 
-Start with a valid, work indexer that has these components: data source, skillset, index. Using an API client, send a [GET Indexer](/rest/api/searchservice/indexers/get?view=rest-searchservice-2024-05-01-preview&preserve-view=true) request to retrieve the indexer. When you use the preview API version to the GET the indexer, a "cache" property set to null is added to the definition automatically.
+Start with a valid, work indexer that has these components: data source, skillset, index. Using an API client, send a [GET Indexer](/rest/api/searchservice/indexers/get?view=rest-searchservice-2025-05-01-preview&preserve-view=true) request to retrieve the indexer. When you use the preview API version to the GET the indexer, a `cache` property set to null is added to the definition automatically.
 
 ```http
-GET https://[YOUR-SEARCH-SERVICE].search.windows.net/indexers/[YOUR-INDEXER-NAME]?api-version=2024-05-01-preview
+GET https://[YOUR-SEARCH-SERVICE].search.windows.net/indexers/[YOUR-INDEXER-NAME]?api-version=2025-05-01-preview
     Content-Type: application/json
     api-key: [YOUR-ADMIN-KEY]
 ```
 
 ### Step 2: Set the cache property
 
-In the index definition, modify "cache" to include the following required and optional properties:
+In the index definition, modify `cache` to include the following required and optional properties:
 
 + (Required) `storageConnectionString` must be set to an Azure Storage connection string.
 + (Optional) `enableReprocessing` boolean property (`true` by default), indicates that incremental enrichment is enabled. Set to `false` if you want to suspend incremental processing while other resource-intensive operations, such as indexing new documents, are underway and then switch back to `true` later.
 
 ```http
-POST https://[service name].search.windows.net/indexers?api-version=2024-05-01-preview
+POST https://[service name].search.windows.net/indexers?api-version=2025-05-01-preview
     {
         "name": "<YOUR-INDEXER-NAME>",
         "targetIndexName": "<YOUR-INDEX-NAME>",
         "dataSourceName": "<YOUR-DATASOURCE-NAME>",
         "skillsetName": "<YOUR-SKILLSET-NAME>",
-        "cache" : {
+        `cache` : {
             "storageConnectionString" : "<YOUR-STORAGE-ACCOUNT-CONNECTION-STRING>",
             "enableReprocessing": true
         },
@@ -116,23 +118,23 @@ POST https://[service name].search.windows.net/indexers?api-version=2024-05-01-p
 [Reset Indexer](/rest/api/searchservice/indexers/reset) is required when setting up incremental enrichment for existing indexers to ensure all documents are in a consistent state. You can use the Azure portal or an API client for this task.
 
 ```https
-POST https://[YOUR-SEARCH-SERVICE].search.windows.net/indexers/[YOUR-INDEXER-NAME]/reset?api-version=2024-05-01-preview
+POST https://[YOUR-SEARCH-SERVICE].search.windows.net/indexers/[YOUR-INDEXER-NAME]/reset?api-version=2025-05-01-preview
     Content-Type: application/json
     api-key: [YOUR-ADMIN-KEY]
 ```
 
 ### Step 4: Save the indexer
 
-[Update Indexer](/rest/api/searchservice/indexers/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true) with a PUT request, where the body of the request includes "cache".
+[Update Indexer](/rest/api/searchservice/indexers/create-or-update?view=rest-searchservice-2025-05-01-preview&preserve-view=true) with a PUT request, where the body of the request includes `cache`.
 
 ```http
-PUT https://[YOUR-SEARCH-SERVICE].search.windows.net/indexers/[YOUR-INDEXER-NAME]?api-version=2024-05-01-preview
+PUT https://[YOUR-SEARCH-SERVICE].search.windows.net/indexers/[YOUR-INDEXER-NAME]?api-version=2025-05-01-preview
     Content-Type: application/json
     api-key: [YOUR-ADMIN-KEY]
     {
         "name" : "<YOUR-INDEXER-NAME>",
         ...
-        "cache": {
+        `cache`: {
             "storageConnectionString": "<YOUR-STORAGE-ACCOUNT-CONNECTION-STRING>",
             "enableReprocessing": true
         }
@@ -142,7 +144,7 @@ PUT https://[YOUR-SEARCH-SERVICE].search.windows.net/indexers/[YOUR-INDEXER-NAME
 If you now issue another GET request on the indexer, the response from the service includes an `ID` property in the cache object. The string is appended to the name of the container containing all the cached results and intermediate state of each document processed by this indexer. The ID is used to uniquely name the cache in Blob storage.
 
 ```http
-    "cache": {
+    `cache`: {
         "ID": "<ALPHA-NUMERIC STRING>",
         "enableReprocessing": true,
         "storageConnectionString": "DefaultEndpointsProtocol=https;AccountName=<YOUR-STORAGE-ACCOUNT>;AccountKey=<YOUR-STORAGE-KEY>;EndpointSuffix=core.windows.net"
@@ -156,7 +158,7 @@ To run indexer, you can use the Azure portal or the API. In the Azure portal, fr
 Alternatively, you can use REST to [run the indexer](/rest/api/searchservice/indexers/run):
 
 ```http
-POST https://[YOUR-SEARCH-SERVICE].search.windows.net/indexers/[YOUR-INDEXER-NAME]/run?api-version=2024-05-01-preview
+POST https://[YOUR-SEARCH-SERVICE].search.windows.net/indexers/[YOUR-INDEXER-NAME]/run?api-version=2025-05-01-preview
 Content-Type: application/json
 api-key: [YOUR-ADMIN-KEY]
 ```
@@ -185,11 +187,9 @@ The following error occurs if you forget to specify a preview API version on the
 
 A 400 Bad Request error will also occur if you're missing an indexer requirement. The error message specifies any missing dependencies.
 
-## Next steps
+## Next step
 
-Incremental enrichment is applicable on indexers that contain skillsets, providing reusable content for both indexes and knowledge stores. The following links provide more information about caching and skillsets.
+Incremental enrichment is applicable on indexers that contain skillsets, providing reusable content for both indexes and knowledge stores. The following link provides more information about cache management.
 
-+ [Incremental enrichment (lifecycle and management)](cognitive-search-incremental-indexing-conceptual.md)
-+ [Skillset concepts and composition](cognitive-search-working-with-skillsets.md)
-+ [Create a skillset](cognitive-search-defining-skillset.md)
-+ [Tutorial: Use REST and AI to generate searchable content from Azure blobs](tutorial-skillset.md)
+> [!div class="checklist"]
+> + [Manage an enrichment cache](enrichment-cache-how-to-manage.md)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Rename and Update Enrichment Cache Configuration Guide"
}
```

### Explanation
The code diff reflects a significant modification in the form of a renaming and content update to the document previously titled `search-howto-incremental-index.md`, now renamed to `enrichment-cache-how-to-configure.md`. This change has resulted in a complete overhaul of the file, which includes both additions and deletions totaling up to 60 modifications.

The updates enhance the clarity and relevance of the article, shifting the focus to configuring enrichment caching in Azure AI Search. The title and descriptions have been revised to better express the article's purpose, while the content has been expanded to provide more detailed instructions on configuring caching for enriched content within an AI enrichment pipeline.

In addition to changing titles and descriptions, the document now includes new sections, limitations, and updated API version references, ensuring that users have access to the latest information. The restructured content guides users on the importance of caching, how to implement it, and what considerations to keep in mind, particularly regarding permissions and configuration properties.

Overall, the modifications aim to improve the usability and accessibility of the guide, enabling users to implement caching effectively while working with Azure AI Search's data enrichment capabilities. This is part of ongoing efforts to maintain accurate, user-friendly documentation that supports developers and users in leveraging Azure services effectively.

## articles/search/enrichment-cache-how-to-manage.md{#item-a972bd}

<details>
<summary>Diff</summary>
````diff
@@ -1,44 +1,48 @@
 ---
-title: Incremental enrichment concepts (preview)
+title: Manage enrichment caching
 titleSuffix: Azure AI Search
 description: Cache intermediate content and incremental changes from AI enrichment pipeline in Azure Storage to preserve investments in existing processed documents. This feature is currently in public preview.
 author: HeidiSteen
 ms.author: heidist
 ms.service: azure-ai-search
-ms.topic: conceptual
-ms.date: 07/11/2025
+ms.topic: how-to
+ms.date: 07/28/2025
 ms.custom:
   - ignite-2023
   - sfi-ropc-nochange
 ---
 
-# Incremental enrichment and caching in Azure AI Search
+# Manage an enrichment cache
 
 > [!IMPORTANT] 
 > This feature is in public preview under [supplemental terms of use](https://azure.microsoft.com/support/legal/preview-supplemental-terms/). The [preview REST API](/rest/api/searchservice/search-service-api-versions#preview-versions) supports this feature.
 
-*Incremental enrichment* refers to the use of cached enrichments during [skillset execution](cognitive-search-working-with-skillsets.md) so that only new and changed skills and documents incur standard processing charges for API calls to Azure AI services. The cache contains the output from [document cracking](search-indexer-overview.md#document-cracking), plus the outputs of each skill for every document. Although caching is billable (it uses Azure Storage), the overall cost of enrichment is reduced because the costs of storage are less than image extraction and AI processing.
+An *enrichment cache* is an optional feature that stores reusable enriched content created during [skillset execution](cognitive-search-working-with-skillsets.md) so that only new and changed skills and documents incur standard processing charges during future indexer and skillset processing. 
 
-To ensure synchronization between your data source data and your index, it's important to understand your unique [data source](search-data-sources-gallery.md) change and deletion tracking prerequisites. This guide specifically addresses how to manage incremental modifications in terms of your skills processing and how to utilize cache for this purpose.
+The cache contains the output from [document cracking](search-indexer-overview.md#document-cracking), plus the outputs of each skill for every document. Although caching is billable (it uses Azure Storage), the overall cost of enrichment is reduced because the costs of storage are less than image extraction and AI processing.
 
-When you enable caching, the indexer evaluates your updates to determine whether existing enrichments can be pulled from the cache. Image and text content from the document cracking phase, plus skill outputs that are upstream or orthogonal to your edits, are likely to be reusable.
+If you have configured an enrichment cache, this article explains how to manage skill and data source updates so that you get maximum utility from cached enrichments.
 
-After skillset processing is finished, the refreshed results are written back to the cache, and also to the search index or knowledge store.
+## Prerequisites
+
++ An [indexer](search-indexer-overview.md) and [skillset](cognitive-search-working-with-skillsets.md)
+
++ An [enrichment cache](enrichment-cache-how-to-configure.md)
 
 ## Limitations
 
 > [!CAUTION]
-> If you're using the [SharePoint Online indexer (Preview)](search-howto-index-sharepoint-online.md), you should avoid incremental enrichment. Under certain circumstances, the cache becomes invalid, requiring an [indexer reset and run](search-howto-run-reset-indexers.md), should you choose to reload it.
+> If you're using the [SharePoint Online indexer (Preview)](search-howto-index-sharepoint-online.md), you should avoid incremental enrichment. Under certain circumstances, the cache becomes invalid, requiring an [indexer reset and full rebuild](search-howto-run-reset-indexers.md), should you choose to reload it.
 
 ## Cache configuration
 
-Physically, the cache is stored in a blob container in your Azure Storage account, one per indexer. Each indexer is assigned a unique and immutable cache identifier that corresponds to the container it's using.
+Physically, the cache is stored in a blob container or table in your Azure Storage account, one per indexer. Each indexer is assigned a unique and immutable cache identifier that corresponds to the container it's using.
 
 The cache is created when you specify the "cache" property and run the indexer. Only enriched content can be cached. If your indexer doesn't have an attached skillset, then caching doesn't apply. 
 
-The following example illustrates an indexer with caching enabled. See [Enable enrichment caching](search-howto-incremental-index.md) for full instructions. 
+The following example illustrates an indexer with caching enabled. See [Configure enrichment caching](enrichment-cache-how-to-configure.md) for full instructions. 
 
-To use the cache property, you can use 2020-06-30-preview or later when you [create or update an indexer](/rest/api/searchservice/indexers/create-or-update?view=rest-searchservice-2025-05-01-preview&preserve-view=true). We recommend the latest preview API.
+To set the cache property, use a preview REST API [Create or Update Indexer](/rest/api/searchservice/indexers/create-or-update?view=rest-searchservice-2025-05-01-preview&preserve-view=true) or a preview Azure SDK package that provides the feature. You can also enable enrichment caching in the Import data wizard in the Azure portal.
 
 ```json
 POST https://[YOUR-SEARCH-SERVICE-NAME].search.windows.net/indexers?api-version=2025-05-01-preview
@@ -180,9 +184,9 @@ Incremental processing evaluates your skillset definition and determines which s
 
 ## APIs used for caching
 
-REST API version `2020-06-30-Preview` or later provides incremental enrichment through extra properties on indexers. We recommend the latest preview API.
+Preview APIs provide extra properties on indexers. We recommend the latest preview API.
 
-Skillsets and data sources can use the generally available version. In addition to the reference documentation, see  [Configure caching for incremental enrichment](search-howto-incremental-index.md) for details about order of operations.
+Skillsets and data sources can use the generally available version. In addition to the reference documentation, see  [Configure caching for incremental enrichment](enrichment-cache-how-to-configure.md) for details about order of operations.
 
 + [Create or Update Indexer (api-version=2025-05-01-preview)](/rest/api/searchservice/indexers/create-or-update?view=rest-searchservice-2025-05-01-preview&preserve-view=true) 
 
@@ -191,10 +195,3 @@ Skillsets and data sources can use the generally available version. In addition
 + [Create or Update Skillset (api-version=2025-05-01-preview)](/rest/api/searchservice/skillsets/create-or-update?view=rest-searchservice-2025-05-01-preview&preserve-view=true) (New URI parameter on the request)
 
 + [Create or Update Data Source (api-version=2025-05-01-preview)](/rest/api/searchservice/data-sources/create-or-update?view=rest-searchservice-2025-05-01-preview&preserve-view=true), when called with a preview API version, provides a new parameter named "ignoreResetRequirement", which should be set to true when your update action shouldn't invalidate the cache. Use "ignoreResetRequirement" sparingly as it could lead to unintended inconsistency in your data that won't be detected easily.
-
-## Next steps
-
-Incremental enrichment is a powerful feature that extends change tracking to skillsets and AI enrichment. Incremental enrichment enables reuse of existing processed content as you iterate over skillset design. As a next step, enable caching on your indexers.
-
-> [!div class="nextstepaction"]
-> [Enable caching for incremental enrichment](search-howto-incremental-index.md)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Rename and Update Enrichment Caching Management Guide"
}
```

### Explanation
The code diff indicates a renaming and enhancement of the document previously titled `cognitive-search-incremental-indexing-conceptual.md`, which is now called `enrichment-cache-how-to-manage.md`. This change involves a total of 39 modifications, including adding 18 lines and deleting 21 lines, thereby updating the content to focus more specifically on managing enrichment caching in Azure AI Search.

The document now features a revised title and description that clearly convey its purpose: to guide users on how to manage the caching of enriched content when using skills in their AI enrichment pipelines. The content explains how an enrichment cache is an optional feature that allows for greater efficiency by preserving the outputs from previous skillset executions, ultimately reducing costs associated with processing new and changed documents.

Additionally, the article includes new sections on prerequisites and configuration, improving clarity for users. Important links have been updated to direct users to relevant documentation pages for further guidance. The document enhances user experience by consolidating essential information related to managing caching, thus facilitating a smoother integration of enrichment features in existing workflows.

Overall, these modifications aim to ensure that users of Azure AI Search have concise and accurate resources to effectively manage enrichment caching as they develop their applications, supporting ongoing enhancements to the Azure platform's documentation.

## articles/search/knowledge-store-concept-intro.md{#item-7475c2}

<details>
<summary>Diff</summary>
````diff
@@ -138,7 +138,7 @@ For data sources that support change tracking, an indexer will process new and c
 
 ### Changes to a skillset
 
-If you're making changes to a skillset, you should [enable caching of enriched documents](cognitive-search-incremental-indexing-conceptual.md) to reuse existing enrichments where possible.
+If you're making changes to a skillset, you should [enable caching of enriched documents](enrichment-cache-how-to-configure.md) to reuse existing enrichments where possible.
 
 Without incremental caching, the indexer will always process documents in order of the high water mark, without going backwards. For blobs, the indexer would process blobs sorted by `lastModified`, regardless of any changes to indexer settings or the skillset. If you change a skillset, previously processed documents aren't updated to reflect the new skillset. Documents processed after the skillset change will use the new skillset, resulting in index documents being a mix of old and new skillsets.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Enabling Caching of Enriched Documents"
}
```

### Explanation
The code diff shows a minor update to the document titled `knowledge-store-concept-intro.md`. The change involves modifying a single line within the section discussing skillset changes, where the link for enabling caching of enriched documents has been updated from `cognitive-search-incremental-indexing-conceptual.md` to `enrichment-cache-how-to-configure.md`. 

This modification reflects an effort to improve accuracy and direct users to the correct documentation for configuring enrichment caching. By providing the updated link, the documentation ensures that users can easily access the most relevant information and guidance as they manage skillsets and utilize caching in Azure's knowledge store.

Overall, this change enhances user experience by maintaining up-to-date reference links, thereby supporting effective integration of the Azure AI Search features.

## articles/search/knowledge-store-projection-example-long.md{#item-e18999}

<details>
<summary>Diff</summary>
````diff
@@ -657,4 +657,4 @@ When building projections of different types, file and object projections are ge
 The example in this article demonstrates common patterns on how to create projections. Now that you have a good understanding of the concepts, you're better equipped to build projections for your specific scenario.
 
 > [!div class="nextstepaction"]
-> [Configure caching for incremental enrichment](search-howto-incremental-index.md)
+> [Configure caching for incremental enrichment](enrichment-cache-how-to-configure.md)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Reference Link for Caching Configuration"
}
```

### Explanation
The code diff indicates a minor update to the document `knowledge-store-projection-example-long.md`. Specifically, the change involves updating a reference link in the "next steps" section. The link previously directed users to `search-howto-incremental-index.md` and has been modified to point to `enrichment-cache-how-to-configure.md`.

This update ensures that users are guided to the correct resource for configuring caching for incremental enrichment in the context of knowledge store projections. By providing an accurate and relevant link, the documentation enhances clarity and usability for readers who are looking to implement caching in their projections.

Overall, this change contributes to a smoother user experience by maintaining up-to-date guidance within the documentation, thereby supporting effective application of Azure AI Search features in building projections.

## articles/search/knowledge-store-projection-overview.md{#item-81aa4a}

<details>
<summary>Diff</summary>
````diff
@@ -157,7 +157,7 @@ Recall that projections are exclusive to knowledge stores, and aren't used to st
 
 1. While in Azure Storage, familiarize yourself with existing content in containers and tables so that you choose nonconflicting names for the projections. A knowledge store is a loose collection of tables and containers. Consider adopting a naming convention to keep track of related objects.
 
-1. In Azure AI Search, [enable enrichment caching (preview)](search-howto-incremental-index.md) in the indexer and then [run the indexer](search-howto-run-reset-indexers.md) to execute the skillset and populate the cache. This is a preview feature, so be sure to use the preview REST API  on the indexer request. Once the cache is populated, you can modify projection definitions in a knowledge store free of charge (as long as the skills themselves aren't modified).
+1. In Azure AI Search, [enable enrichment caching (preview)](enrichment-cache-how-to-configure.md) in the indexer and then [run the indexer](search-howto-run-reset-indexers.md) to execute the skillset and populate the cache. This is a preview feature, so be sure to use the preview REST API  on the indexer request. Once the cache is populated, you can modify projection definitions in a knowledge store free of charge (as long as the skills themselves aren't modified).
 
 1. In your code, all projections are defined solely in a skillset. There are no indexer properties (such as field mappings or output field mappings) that apply to projections. Within a skillset definition, you'll focus on two areas: knowledgeStore property and skills array.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Reference Link for Enrichment Caching"
}
```

### Explanation
The code diff reflects a minor update to the document `knowledge-store-projection-overview.md`. The change specifically involves modifying a line that instructs users on enabling enrichment caching in Azure AI Search. The previous link to `search-howto-incremental-index.md` has been updated to point to `enrichment-cache-how-to-configure.md`.

This alteration is made to direct users to the appropriate resource for configuring enrichment caching within the context of Azure AI Search. Providing an accurate and relevant link helps ensure that users can find the right guidance and documentation needed to enable this preview feature effectively.

The overall impact of this change reinforces the clarity and usability of the documentation, enabling users to successfully navigate and utilize the features associated with knowledge store projections in Azure AI Search.

## articles/search/knowledge-store-projections-examples.md{#item-9bfff5}

<details>
<summary>Diff</summary>
````diff
@@ -42,7 +42,7 @@ Recall that projections are defined under the `knowledgeStore` property of a ski
 If you need more background before getting started, review [this check list](knowledge-store-projection-overview.md#checklist-for-getting-started) for tips and workflow.
 
 > [!TIP]
-> When developing projections, [enable enrichment caching (preview)](search-howto-incremental-index.md) so that you can reuse existing enrichments while editing projection definitions. Enrichment caching is a preview feature, so be sure to use the preview REST API on the indexer request. Without caching, simple edits to a projection will result in a full reprocess of enriched content. By caching the enrichments, you can iterate over projections without incurring any skillset processing charges.
+> When developing projections, [enable enrichment caching (preview)](enrichment-cache-how-to-configure.md) so that you can reuse existing enrichments while editing projection definitions. Enrichment caching is a preview feature, so be sure to use the preview REST API on the indexer request. Without caching, simple edits to a projection will result in a full reprocess of enriched content. By caching the enrichments, you can iterate over projections without incurring any skillset processing charges.
 
 ## Requirements
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Reference Link for Enrichment Caching"
}
```

### Explanation
The code diff indicates a minor update to the document `knowledge-store-projections-examples.md`. The primary change features a modification of a link related to enabling enrichment caching in Azure AI Search. The original link directing users to `search-howto-incremental-index.md` has been updated to point to `enrichment-cache-how-to-configure.md`.

This update is essential as it ensures users receive accurate and relevant information on configuring enrichment caching while developing projections. By linking to the appropriate documentation, users can effectively enable this preview feature, allowing them to reuse existing enrichments during the editing of projection definitions.

Overall, this change improves the quality and usability of the documentation, facilitating a better experience for users working with projections in Azure AI Search, while also helping them avoid unnecessary processing costs when making edits to their projections.

## articles/search/resource-tools.md{#item-0c6ac1}

<details>
<summary>Diff</summary>
````diff
@@ -7,13 +7,22 @@ author: haileytap
 ms.author: haileytapia
 ms.service: azure-ai-search
 ms.topic: conceptual
-ms.date: 06/02/2025
+ms.date: 07/28/2025
 ---
 
 # Productivity tools and accelerators for Azure AI Search
 
 Microsoft engineers build productivity tools that aren't part of the Azure AI Search service and aren't covered by service-level agreements (SLAs). You can download, modify, and build these tools to create an app that helps you develop or maintain a search solution.
 
+## Accelerators
+
+| Accelerator | Description |
+|--|--|
+| [RAG Experiment Accelerator](https://github.com/microsoft/rag-experiment-accelerator) | Conduct experiments and evaluations using Azure AI Search and the RAG pattern. This accelerator has code for loading multiple data sources, using a variety of models, and creating a variety of search indexes and queries. |
+| [Build your own copilot solution accelerator](https://github.com/microsoft/Build-your-own-copilot-Solution-Accelerator) | Code and docs to build a copilot for specific use cases. |
+| [Chat with your data solution accelerator](https://github.com/Azure-Samples/chat-with-your-data-solution-accelerator/blob/main/README.md) | Code and docs to create interactive search solution in production environments. |
+| [Document knowledge mining solution accelerator](https://github.com/microsoft/Document-Knowledge-Mining-Solution-Accelerator/blob/main/README.md) | Code and docs built on Azure OpenAI in Azure AI Foundry Models and Azure AI Document Intelligence. It processes and extracts summaries, entities, and metadata from unstructured, multimodal documents to enable searching and chatting over this data. |
+
 ## Tools
 
 | Tool name | Description |
@@ -24,11 +33,3 @@ Microsoft engineers build productivity tools that aren't part of the Azure AI Se
 | [Performance testing solution](https://github.com/Azure-Samples/azure-search-performance-testing/blob/main/README.md) | This solution helps you load test Azure AI Search. It uses Apache JMeter as an open source load and performance testing tool and Terraform to dynamically provision and destroy the required infrastructure on Azure. |
 | [Visual Studio Code extension](https://github.com/microsoft/vscode-azurecognitivesearch) | Although the extension is no longer available on the Visual Studio Code Marketplace, the code is open source. You can clone and modify the tool for your own use. |
 
-## Accelerators
-
-| Accelerator | Description |
-|--|--|
-| [Build your own copilot solution accelerator](https://github.com/microsoft/Build-your-own-copilot-Solution-Accelerator) | Code and docs to build a copilot for specific use cases. |
-| [Chat with your data solution accelerator](https://github.com/Azure-Samples/chat-with-your-data-solution-accelerator/blob/main/README.md) | Code and docs to create interactive search solution in production environments. |
-| [Document knowledge mining solution accelerator](https://github.com/microsoft/Document-Knowledge-Mining-Solution-Accelerator/blob/main/README.md) | Code and docs built on Azure OpenAI in Azure AI Foundry Models and Azure AI Document Intelligence. It processes and extracts summaries, entities, and metadata from unstructured, multimodal documents to enable searching and chatting over this data. |
-| [Knowledge mining accelerator](https://github.com/Azure-Samples/azure-search-knowledge-mining/blob/main/README.md) | Code and docs to jump start a knowledge store using your data. |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update and Organize Accelerators Section"
}
```

### Explanation
The code diff reflects a minor update to the document `resource-tools.md`. Key modifications include the addition of a new section titled "Accelerators," which introduces several specific accelerators designed to enhance user productivity when working with Azure AI Search. This section includes detailed descriptions and links to various accelerators, such as the RAG Experiment Accelerator and the Chat with Your Data Solution Accelerator.

Additionally, the previously existing "Accelerators" section has been removed from its prior location, indicating an organizational enhancement in how tools and accelerators are presented. The document now provides a more structured overview, separating tools and accelerators into distinct sections, which improves readability and makes it easier for users to find relevant resources.

Moreover, the date associated with the document has been updated from June 2, 2025, to July 28, 2025, signaling that the content is fresh and current. Overall, these changes aim to improve accessibility and usability, allowing users to better leverage the resources available for developing and maintaining their search solutions on Azure AI Search.

## articles/search/retrieval-augmented-generation-overview.md{#item-ec76e0}

<details>
<summary>Diff</summary>
````diff
@@ -276,6 +276,8 @@ Check out the following GitHub repositories for code, documentation, and video d
 
 ## See also
 
++ [RAG Experiment Accelerator](https://github.com/microsoft/rag-experiment-accelerator)
+
 + [Retrieval Augmented Generation: Streamlining the creation of intelligent natural language processing models](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/)
-+ [Retrieval Augmented Generation using Azure Machine Learning prompt flow](/azure/machine-learning/concept-retrieval-augmented-generation)
+
 + [Azure Cognitive Search and LangChain: A Seamless Integration for Enhanced Vector Search Capabilities](https://techcommunity.microsoft.com/t5/azure-ai-services-blog/azure-cognitive-search-and-langchain-a-seamless-integration-for/ba-p/3901448)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add References and Update See Also Section"
}
```

### Explanation
The code diff shows a minor update to the document `retrieval-augmented-generation-overview.md`. The main changes involve the enhancement of the "See also" section, where additional resources have been incorporated to provide more valuable references for readers interested in Retrieval Augmented Generation (RAG).

Newly added items in this section include:
1. A link to the **RAG Experiment Accelerator**, which is likely a valuable tool for users who want to experiment with using retrieval augmented generation in their projects.
2. A link to a blog post titled **"Retrieval Augmented Generation: Streamlining the creation of intelligent natural language processing models"**, designed to offer a deeper understanding and insights into RAG and its benefits.
3. An additional reference to a blog post on **Azure Cognitive Search and LangChain**, which focuses on integrating these technologies to enhance vector search capabilities.

These updates not only improve the context and resources available for users exploring RAG but also aid in better understanding its application within the Azure ecosystem. Overall, these modifications enhance the comprehensiveness of the document, making it a more useful resource for readers interested in this area of artificial intelligence.

## articles/search/samples-dotnet.md{#item-12f3fa}

<details>
<summary>Diff</summary>
````diff
@@ -72,7 +72,6 @@ An accelerator is an end-to-end solution that includes code and documentation th
 | Samples | Repository | Description |
 |---------|------------|-------------|
 | Search + QnA Maker Accelerator | [search-qna-maker-accelerator](https://github.com/Azure-Samples/search-qna-maker-accelerator)| A [solution](https://techcommunity.microsoft.com/t5/azure-ai/qna-with-azure-cognitive-search/ba-p/2081381) combining the power of Search and QnA Maker. See the live [demo site](https://aka.ms/qnaWithAzureSearchDemo). |
-| [Knowledge Mining Solution Accelerator](/shows/ai-show/knowledge-mining-with-azure-search) | [azure-search-knowledge-mining](https://github.com/azure-samples/azure-search-knowledge-mining/tree/main/) | Includes templates, support files, and analytical reports to help you prototype an end-to-end knowledge mining solution.  |
 
 ## Demos
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Remove Knowledge Mining Solution Accelerator Reference"
}
```

### Explanation
The code diff indicates a minor update to the document `samples-dotnet.md`. The primary change involves the deletion of a reference to the **Knowledge Mining Solution Accelerator** from the table that lists available accelerators and their descriptions.

Previously, the document included information about the Knowledge Mining Solution Accelerator, which provided templates, support files, and analytical reports designed to assist users in prototyping an end-to-end knowledge mining solution. The removal of this reference suggests a decision to streamline the information or possibly to align the content with the latest updates in available solutions or resources.

With this deletion, the document now highlights only the existing remaining accelerator example, specifically the **Search + QnA Maker Accelerator**, retaining clarity while ensuring that the document stays focused on currently relevant and supported tools. Overall, this change reflects ongoing maintenance efforts to keep the documentation precise and up-to-date.

## articles/search/samples-python.md{#item-d2bf09}

<details>
<summary>Diff</summary>
````diff
@@ -54,6 +54,14 @@ Code samples from the Azure AI Search team demonstrate features and workflows. M
 
 [**aisearch-openai-rag-audio**](https://github.com/Azure-Samples/aisearch-openai-rag-audio) is "voice to RAG". This sample demonstrates a simple architecture for voice-based generative AI applications that enables Azure AI Search RAG on top of the real-time audio API with full-duplex audio streaming from client devices, while securely handling access to both the model and retrieval system. Backend code is written in Python, while frontend code is written in JavaScript. For an introduction, watch this [video](https://www.youtube.com/watch?v=vXJka8xZ9Ko).
 
+## Accelerators
+
+An accelerator is an end-to-end solution that includes code and documentation that you can adapt for your own implementation of a specific scenario.
+
+| Repository | Description |
+|------------|-------------|
+| [RAG Experiment Accelerator](https://github.com/microsoft/rag-experiment-accelerator) | Conduct experiments and evaluations using Azure AI Search and the RAG pattern. This accelerator has code for loading multiple data sources, using a variety of models, and creating a variety of search indexes and queries. |
+
 ## Other samples
 
 The following samples are also published by the Azure AI Search team but aren't referenced in documentation. Associated readme files provide usage instructions.
````
</details>

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "Add Accelerators Section with RAG Experiment Accelerator"
}
```

### Explanation
The code diff reveals a significant addition to the document `samples-python.md`, specifically the introduction of a new section titled "Accelerators." In this update, eight lines of content have been added, which enhance the document by providing information about an additional resource for users interested in leveraging Azure AI Search capabilities.

The newly added section defines what an accelerator is, labeling it as an end-to-end solution that includes code and documentation customizable for specific scenarios. It features a table listing the **RAG Experiment Accelerator**, along with a description of its functionalities. This accelerator allows users to conduct experiments and evaluations using Azure AI Search in conjunction with the Retrieval Augmented Generation (RAG) pattern. Key benefits mentioned include support for loading various data sources, utilizing different models, and creating diverse search indexes and queries.

The inclusion of this section not only informs users about additional tools available for enhancing their AI search implementations but also encourages experimentation and adaptation of the provided code for personalized projects. Overall, this update improves the document's utility by broadening the resources available to developers in the Azure AI Search ecosystem.

## articles/search/search-api-preview.md{#item-511f5d}

<details>
<summary>Diff</summary>
````diff
@@ -48,7 +48,7 @@ Preview features are removed from this list if they're retired or transition to
 | [**Text Split skill (token chunking)**](cognitive-search-skill-textsplit.md) | Applied AI (skills) | This skill has new parameters that improve data chunking for embedding models. A new `unit` parameter lets you specify token chunking. You can now chunk by token length, setting the length to a value that makes sense for your embedding model. You can also specify the tokenizer and any tokens that shouldn't be split during data chunking. | [Create or Update Skillset (preview)](/rest/api/searchservice/skillsets/create-or-update?view=rest-searchservice-2024-09-01-preview&preserve-view=true). |
 | [**Azure AI Vision multimodal embedding skill**](cognitive-search-skill-vision-vectorize.md) | Applied AI (skills) | A new skill type that calls Azure AI Vision multimodal API to generate embeddings for text or images during indexing. | [Create or Update Skillset (preview)](/rest/api/searchservice/skillsets/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true). |
 | [**Azure Machine Learning (AML) skill**](cognitive-search-aml-skill.md) | Applied AI (skills) | AML skill integrates an inferencing endpoint from Azure Machine Learning. In previous preview APIs, it supports connections to deployed custom models in an AML workspace. Starting in the 2024-05-01-preview, you can use this skill in workflows that connect to embedding models in the Azure AI Foundry model catalog. It's also available in the Azure portal, in skillset design, assuming Azure AI Search and Azure Machine Learning services are deployed in the same subscription. | [Create or Update Skillset (preview)](/rest/api/searchservice/skillsets/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true). |
-| [**Incremental enrichment cache**](cognitive-search-incremental-indexing-conceptual.md) | Applied AI (skills) | Adds caching to an enrichment pipeline, allowing you to reuse existing output if a targeted modification, such as an update to a skillset or another object, doesn't change the content. Caching applies only to enriched documents produced by a skillset.| [Create or Update Indexer (preview)](/rest/api/searchservice/indexers/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true). |
+| [**Incremental enrichment cache**](enrichment-cache-how-to-configure.md) | Applied AI (skills) | Adds caching to an enrichment pipeline, allowing you to reuse existing output if a targeted modification, such as an update to a skillset or another object, doesn't change the content. Caching applies only to enriched documents produced by a skillset.| [Create or Update Indexer (preview)](/rest/api/searchservice/indexers/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true). |
 |  [**OneLake files indexer**](search-how-to-index-onelake-files.md) | Indexer data source | New data source for extracting searchable data and metadata data from a [lakehouse](/fabric/onelake/create-lakehouse-onelake) on top of [OneLake](/fabric/onelake/onelake-overview) | [Create or Update Data Source (preview)](/rest/api/searchservice/data-sources/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true). |
 |  [**Azure Files indexer**](search-file-storage-integration.md) | Indexer data source | New data source for indexer-based indexing from [Azure Files](https://azure.microsoft.com/services/storage/files/) | [Create or Update Data Source (preview)](/rest/api/searchservice/data-sources/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true). |
 | [**SharePoint Online indexer**](search-howto-index-sharepoint-online.md) | Indexer data source | New data source for indexer-based indexing of SharePoint content. | [Sign up](https://aka.ms/azure-cognitive-search/indexer-preview) to enable the feature. [Create or Update Data Source (preview)](/rest/api/searchservice/data-sources/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true) or the Azure portal. |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Incremental Enrichment Cache Link in Preview Features"
}
```

### Explanation
The code diff shows a minor update to the `search-api-preview.md` document, where one line of text has been deleted and one line added, resulting in an overall change of two lines. The update involves the modification of the hyperlink associated with the **Incremental enrichment cache** feature.

Previously, the link directed users to a different resource (`cognitive-search-incremental-indexing-conceptual.md`) for information related to incremental enrichment caching in the Azure AI Search context. The updated link now directs users to a new resource titled `enrichment-cache-how-to-configure.md`. 

This change likely reflects a reorganization of documentation or an improvement in clarity regarding how to configure caching in enrichment pipelines. By guiding users to a more relevant or updated resource, the modification aims to enhance the overall usability and accuracy of the documentation, ensuring users have direct access to the most pertinent instructions for implementing the incremental enrichment cache feature.

## articles/search/search-features-list.md{#item-d34448}

<details>
<summary>Diff</summary>
````diff
@@ -49,7 +49,7 @@ The following table summarizes features by category. There's feature parity in a
 |-------------------|----------|
 |AI processing during indexing | [**AI enrichment**](cognitive-search-concept-intro.md) refers to embedded image and natural language processing in an indexer pipeline that extracts text and information from content that can't otherwise be indexed for full text search. AI processing is achieved by adding and combining skills in a skillset, which is then attached to an indexer. AI can be either [built-in skills](cognitive-search-predefined-skills.md) from Microsoft, such as text translation or Optical Character Recognition (OCR), or [custom skills](cognitive-search-create-custom-skill-example.md) that you provide. |
 | Storing enriched content for analysis and consumption in non-search scenarios | [**Knowledge store**](knowledge-store-concept-intro.md) is persistent storage of enriched content, intended for non-search scenarios like knowledge mining and data science processing. A knowledge store is defined in a skillset, but created in Azure Storage as objects or tabular rowsets.|
-| Cached enrichments | [**Enrichment caching (preview)**](cognitive-search-incremental-indexing-conceptual.md) refers to cached enrichments that can be reused during skillset execution. Caching is particularly valuable in skillsets that include OCR and image analysis, which are expensive to process. |
+| Cached enrichments | [**Enrichment caching (preview)**](enrichment-cache-how-to-configure.md) refers to cached enrichments that can be reused during skillset execution. Caching is particularly valuable in skillsets that include OCR and image analysis, which are expensive to process. |
 
 ## Full text and other query forms
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Enrichment Caching Link in Search Features List"
}
```

### Explanation
The code diff presents a minor update to the `search-features-list.md` document, involving one line addition and one line deletion, resulting in a net change of two lines. This update specifically addresses the hyperlink associated with the **Enrichment caching (preview)** feature.

Previously, the link led users to `cognitive-search-incremental-indexing-conceptual.md` for information related to enrichment caching. The modification changes this link to direct users to a new document titled `enrichment-cache-how-to-configure.md`. 

The update indicates an effort to improve the documentation by ensuring that users access the most relevant and current resource regarding how to configure enrichment caching. This adjustment is likely to enhance the clarity and usability of the feature information for developers and users looking to implement caching within their skillsets, particularly for resource-intensive processes like Optical Character Recognition (OCR) and image analysis.

## articles/search/search-file-storage-integration.md{#item-d20e26}

<details>
<summary>Diff</summary>
````diff
@@ -48,7 +48,7 @@ You can use this indexer for the following tasks:
 + **Deletion detection:** The indexer can [detect deletions through custom metadata](search-howto-index-changed-deleted-blobs.md).
 + **Applied AI through skillsets:** [Skillsets](cognitive-search-concept-intro.md) are fully supported by the indexer. This includes key features like [integrated vectorization](vector-search-integrated-vectorization.md) that adds data chunking and embedding steps.
 + **Parsing modes:** The indexer supports [JSON parsing modes](search-howto-index-json-blobs.md) if you want to parse JSON arrays or lines into individual search documents. It also supports [Markdown parsing mode](search-how-to-index-markdown-blobs.md).
-+ **Compatibility with other features:** The indexer is designed to work seamlessly with other indexer features, such as [debug sessions](cognitive-search-debug-session.md), [indexer cache for incremental enrichments](search-howto-incremental-index.md), and [knowledge store](knowledge-store-concept-intro.md).
++ **Compatibility with other features:** The indexer is designed to work seamlessly with other indexer features, such as [debug sessions](cognitive-search-debug-session.md), [indexer cache for incremental enrichments](enrichment-cache-how-to-configure.md), and [knowledge store](knowledge-store-concept-intro.md).
 
 ## Supported document formats
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Indexer Cache in File Storage Integration"
}
```

### Explanation
The code diff illustrates a minor update to the `search-file-storage-integration.md` document, where one line of text was deleted and another was added, leading to a total of two line modifications. This update specifically pertains to the link associated with the indexer cache for incremental enrichments feature.

In the previous version, a hyperlink directed users to `search-howto-incremental-index.md` for more information on the indexer cache associated with incremental enrichments. The updated link now points to `enrichment-cache-how-to-configure.md`, which likely offers more relevant or updated guidance on configuring caching in enrichment processes.

This change reflects an ongoing effort to ensure that users have access to the most accurate and useful documentation concerning the integration of various indexer features, enhancing their understanding and implementation of the indexer in Azure's file storage context. By providing a correct and direct resource, the update aims to improve clarity and usability for developers utilizing AI features in their applications.

## articles/search/search-how-to-create-indexers.md{#item-de71fb}

<details>
<summary>Diff</summary>
````diff
@@ -107,7 +107,7 @@ Skills-based indexing uses [AI enrichment](cognitive-search-concept-intro.md) to
 }
 ```
 
-AI enrichment is its own subject area and is out of scope for this article. For more information, start with [AI enrichment](cognitive-search-concept-intro.md), [Skillsets in Azure AI Search](cognitive-search-working-with-skillsets.md), [Create a skillset](cognitive-search-defining-skillset.md), [Map enriched output fields](cognitive-search-output-field-mapping.md), and [Enable caching for AI enrichment](search-howto-incremental-index.md).
+AI enrichment is its own subject area and is out of scope for this article. For more information, start with [AI enrichment](cognitive-search-concept-intro.md), [Skillsets in Azure AI Search](cognitive-search-working-with-skillsets.md), [Create a skillset](cognitive-search-defining-skillset.md), [Map enriched output fields](cognitive-search-output-field-mapping.md), and [Enable caching for AI enrichment](enrichment-cache-how-to-configure.md).
 
 ## Prepare external data
 
@@ -255,7 +255,7 @@ Change detection logic is built into the data platforms. How an indexer supports
 
 Indexers keep track of the last document it processed from the data source through an internal *high water mark*. The marker is never exposed in the API, but internally the indexer keeps track of where it stopped. When indexing resumes, either through a scheduled run or an on-demand invocation, the indexer references the high water mark so that it can pick up where it left off.
 
-If you need to clear the high water mark to reindex in full, you can use [Reset Indexer](/rest/api/searchservice/indexers/reset). For more selective reindexing, use [Reset Skills](/rest/api/searchservice/skillsets/reset-skills?view=rest-searchservice-2024-05-01-preview&preserve-view=true) or [Reset Documents](/rest/api/searchservice/indexers/reset-docs?view=rest-searchservice-2024-05-01-preview&preserve-view=true). Through the reset APIs, you can clear internal state, and also flush the cache if you enabled [incremental enrichment](search-howto-incremental-index.md). For more background and comparison of each reset option, see [Run or reset indexers, skills, and documents](search-howto-run-reset-indexers.md).
+If you need to clear the high water mark to reindex in full, you can use [Reset Indexer](/rest/api/searchservice/indexers/reset). For more selective reindexing, use [Reset Skills](/rest/api/searchservice/skillsets/reset-skills?view=rest-searchservice-2024-05-01-preview&preserve-view=true) or [Reset Documents](/rest/api/searchservice/indexers/reset-docs?view=rest-searchservice-2024-05-01-preview&preserve-view=true). Through the reset APIs, you can clear internal state, and also flush the cache if you enabled [incremental enrichment](enrichment-cache-how-to-configure.md). For more background and comparison of each reset option, see [Run or reset indexers, skills, and documents](search-howto-run-reset-indexers.md).
 
 ## Related content
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Enrichment Caching in Indexer Creation Guide"
}
```

### Explanation
The code diff shows a minor update made to the `search-how-to-create-indexers.md` document, with a total of four changes comprising two additions and two deletions. The primary focus of this update is the modification of links related to caching for AI enrichment.

In the original text, the link leading to instructions on enabling caching for AI enrichment directed users to `search-howto-incremental-index.md`. The updated version replaces this link with a new one pointing to `enrichment-cache-how-to-configure.md`, which likely provides more specific or updated guidance on configuring the caching feature.

Additionally, a similar change was made in a second occurrence within the document’s section on reindexing, where the previous link to `search-howto-incremental-index.md` was replaced with the same new link. 

These updates are intended to enhance the clarity and accuracy of the documentation, ensuring that users are directed to the most relevant resources for configuring and utilizing caching in their indexing processes effectively. This careful attention to link accuracy aids developers in implementing AI enrichment efficiently in their Azure search solutions.

## articles/search/search-how-to-index-onelake-files.md{#item-95f3db}

<details>
<summary>Diff</summary>
````diff
@@ -56,7 +56,7 @@ You can use this indexer for the following tasks:
 + **Deletion detection:** The indexer can [detect deletions via custom metadata](#detect-deletions-via-custom-metadata) for most files and shortcuts. This requires adding metadata to files to signify that they have been "soft deleted", enabling their removal from the search index. Currently, it's not possible to detect deletions in Google Cloud Storage or Amazon S3 shortcut files because custom metadata isn't supported for those data sources.
 + **Applied AI through skillsets:** [Skillsets](cognitive-search-concept-intro.md) are fully supported by the OneLake files indexer. This includes key features like [integrated vectorization](vector-search-integrated-vectorization.md) that adds data chunking and embedding steps.
 + **Parsing modes:** The indexer supports [JSON parsing modes](search-howto-index-json-blobs.md) if you want to parse JSON arrays or lines into individual search documents. It also supports [Markdown parsing mode](search-how-to-index-markdown-blobs.md).
-+ **Compatibility with other features:** The OneLake indexer is designed to work seamlessly with other indexer features, such as [debug sessions](cognitive-search-debug-session.md), [indexer cache for incremental enrichments](search-howto-incremental-index.md), and [knowledge store](knowledge-store-concept-intro.md).
++ **Compatibility with other features:** The OneLake indexer is designed to work seamlessly with other indexer features, such as [debug sessions](cognitive-search-debug-session.md), [indexer cache for incremental enrichments](enrichment-cache-how-to-configure.md), and [knowledge store](knowledge-store-concept-intro.md).
 
 <a name="SupportedFormats"></a>
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Indexer Cache in OneLake Files Indexing Guide"
}
```

### Explanation
The code diff indicates a minor update to the `search-how-to-index-onelake-files.md` document, featuring a total of two changes consisting of one addition and one deletion. The primary purpose of this update is to modify the hyperlink pertaining to the indexer cache for incremental enrichments.

In the previous version, the link associated with the indexer cache directed users to `search-howto-incremental-index.md`. In the current update, this link has been changed to point to `enrichment-cache-how-to-configure.md`, which likely provides more refined or comprehensive guidance regarding caching configurations in the context of enrichment processes.

Through this modification, the document aims to improve the accuracy and relevance of the resources it provides, allowing users to access the most appropriate and up-to-date information for effectively utilizing AI capabilities with the OneLake files indexer in Azure. This focus on clarity and correctness enhances user experience, aiding developers in implementing efficient indexing solutions.

## articles/search/search-howto-index-changed-deleted-blobs.md{#item-32a688}

<details>
<summary>Diff</summary>
````diff
@@ -43,7 +43,7 @@ For this deletion detection approach, Azure AI Search depends on the [native blo
 
 ### Requirements for native soft delete
 
-+ Blobs must be in an Azure Blob Storage container. The Azure AI Search native blob soft delete policy isn't supported for blobs in ADLS Gen2 or Azure Files.
++ Blobs must be in an Azure Blob Storage container, including ADLS Gen2 Blob container. The Azure AI Search native blob soft delete policy isn't supported for Azure Files.
 
 + [Enable soft delete for blobs](/azure/storage/blobs/soft-delete-blob-enable).
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Clarification on Soft Delete Support for Azure Blob Storage"
}
```

### Explanation
The code diff reveals a minor update to the `search-howto-index-changed-deleted-blobs.md` document, featuring a total of two changes which include one addition and one deletion. The key focus of this update is to clarify the types of Azure Blob Storage that are supported for the native soft delete feature.

In the original text, it was stated that blobs must be in an Azure Blob Storage container, but it implied that ADLS Gen2 was not included in the list of supported options. The updated version explicitly states that blobs must be in an Azure Blob Storage container while also clarifying that ADLS Gen2 Blob containers are indeed supported. However, the Azure AI Search native blob soft delete policy remains unsupported for Azure Files.

This modification enhances the document's clarity regarding the requirements for enabling soft delete in Azure, ensuring users fully understand where they can apply this functionality. Additionally, a link to a guide on enabling soft delete for blobs is also included, further directing users to relevant resources. This update contributes to an improved understanding of the soft delete capabilities within the Azure Blob Storage context, thereby assisting users in correctly implementing these features.

## articles/search/search-howto-indexing-azure-blob-storage.md{#item-dc4668}

<details>
<summary>Diff</summary>
````diff
@@ -53,7 +53,7 @@ You can use this indexer for the following tasks:
 + **Deletion detection:** The indexer can [detect deletions through native soft delete or through custom metadata](search-howto-index-changed-deleted-blobs.md).
 + **Applied AI through skillsets:** [Skillsets](cognitive-search-concept-intro.md) are fully supported by the indexer. This includes key features like [integrated vectorization](vector-search-integrated-vectorization.md) that adds data chunking and embedding steps.
 + **Parsing modes:** The indexer supports [JSON parsing modes](search-howto-index-json-blobs.md) if you want to parse JSON arrays or lines into individual search documents. It also supports [Markdown parsing mode](search-how-to-index-markdown-blobs.md).
-+ **Compatibility with other features:** The indexer is designed to work seamlessly with other indexer features, such as [debug sessions](cognitive-search-debug-session.md), [indexer cache for incremental enrichments](search-howto-incremental-index.md), and [knowledge store](knowledge-store-concept-intro.md).
++ **Compatibility with other features:** The indexer is designed to work seamlessly with other indexer features, such as [debug sessions](cognitive-search-debug-session.md), [indexer cache for incremental enrichments](enrichment-cache-how-to-configure.md), and [knowledge store](knowledge-store-concept-intro.md).
 
 <a name="SupportedFormats"></a>
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Indexer Cache in Azure Blob Storage Indexing Guide"
}
```

### Explanation
The code diff indicates a minor update to the `search-howto-indexing-azure-blob-storage.md` document, involving two changes that include one addition and one deletion. The primary objective of this update is to revise the hyperlink associated with the indexer cache for incremental enrichments.

In the earlier version of the document, the link regarding the indexer cache pointed users to `search-howto-incremental-index.md`. The updated version changes this link to direct users to `enrichment-cache-how-to-configure.md`, which likely provides more comprehensive or specific guidance on configuring cache settings for indexer processing.

This modification serves to enhance the overall quality and accuracy of the information provided to users, ensuring that those utilizing the Azure Blob Storage indexer have access to the most pertinent instructions. By refining the documentation in this way, it better aids developers in effectively implementing the indexing functionalities and maximizing the capabilities of Azure AI Search, particularly regarding handling deleted blobs and leveraging incremental enrichment features.

## articles/search/search-howto-managed-identities-data-sources.md{#item-edf98d}

<details>
<summary>Diff</summary>
````diff
@@ -47,7 +47,7 @@ A search service uses Azure Storage as an indexer data source and as a data sink
 | [Indexer connections to supported Azure data sources](search-indexer-overview.md) <sup>1</sup>| Yes | Yes |
 | [Azure Key Vault for customer-managed keys](search-security-manage-encryption-keys.md) | Yes | Yes |
 | [Debug sessions (hosted in Azure Storage)](cognitive-search-debug-session.md)	<sup>1</sup> | Yes | No |
-| [Enrichment cache (hosted in Azure Storage)](search-howto-incremental-index.md) <sup>1,</sup> <sup>2</sup> | Yes | Yes |
+| [Enrichment cache (hosted in Azure Storage)](enrichment-cache-how-to-configure.md) <sup>1,</sup> <sup>2</sup> | Yes | Yes |
 | [Knowledge Store (hosted in Azure Storage)](knowledge-store-create-rest.md) <sup>1</sup>| Yes | Yes |
 | Connections to Azure OpenAI, Azure AI Foundry and Azure Functions via skills/vectorizers <sup>3</sup> | Yes | Yes |
 
@@ -274,7 +274,7 @@ A knowledge store definition includes a connection string to Azure Storage. The
 }
 ```
 
-[**Enrichment cache:**](search-howto-incremental-index.md)
+[**Enrichment cache:**](enrichment-cache-how-to-configure.md)
 
 An indexer creates, uses, and remembers the container used for the cached enrichments. It's not necessary to include the container in the cache connection string. You can find the object ID on the **Identity** page of your search service in the Azure portal.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Link Update for Enrichment Cache in Managed Identities Data Sources Guide"
}
```

### Explanation
The code diff shows a minor update to the `search-howto-managed-identities-data-sources.md` document, consisting of four changes that include two additions and two deletions. The main objective of this modification is to improve the accuracy of the links related to the enrichment cache feature in the context of Azure AI Search.

Previously, the document directed users to `search-howto-incremental-index.md` for information about the enrichment cache hosted in Azure Storage. This update replaces that link with `enrichment-cache-how-to-configure.md`, which presumably offers more precise instructions on configuring the enrichment cache settings for indexers.

This change is reflected not only in a table listing supported data sources and their features but also in a corresponding section explaining the enrichment cache. By updating the links, the documentation ensures that users have access to the most relevant and current resources available, enhancing their ability to implement managed identities and manage data sources effectively in Azure AI Search. Overall, this update improves the user experience and supports better comprehension of the functionalities related to enrichment caching within Azure's indexing framework.

## articles/search/search-howto-managed-identities-storage.md{#item-8209c4}

<details>
<summary>Diff</summary>
````diff
@@ -45,7 +45,7 @@ You can use a system-assigned managed identity or a user-assigned managed identi
    | Table indexing using an indexer | Add **Storage Table Data Reader** |
    | File indexing using an indexer | Add **Reader and Data Access** |
    | Write to a [knowledge store](knowledge-store-concept-intro.md) | Add **Storage Blob Data Contributor** for object and file projections, and **Reader and Data Access** for table projections. |
-   | Write to an [enrichment cache](cognitive-search-incremental-indexing-conceptual.md) | Add **Storage Blob Data Contributor** and **Storage Table Data Reader** |
+   | Write to an [enrichment cache](enrichment-cache-how-to-configure.md) | Add **Storage Blob Data Contributor** and **Storage Table Data Contributor** |
    | Save [debug session state](cognitive-search-debug-session.md) | Add **Storage Blob Data Contributor**  |
 
 1. Select **Next**.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Correction of Enrichment Cache Link and Access Roles in Managed Identities Storage Guide"
}
```

### Explanation
The code diff details a minor update made to the `search-howto-managed-identities-storage.md` document, which includes two changes consisting of one addition and one deletion. The primary purpose of this modification is to update the link associated with writing to an enrichment cache and clarify the necessary roles required for access.

In the previous version, the document referenced the link `cognitive-search-incremental-indexing-conceptual.md` for writing to an enrichment cache. This has been changed to point to `enrichment-cache-how-to-configure.md`, which is likely intended to provide more relevant instructions for configuration settings specific to the enrichment cache.

Additionally, the access role requirements have been updated. The previous version specified the use of **Storage Blob Data Contributor** and **Storage Table Data Reader** roles. Now, it updates the requirements to include the **Storage Blob Data Contributor** and replaces the previous table role specification with **Storage Table Data Contributor**. This refined specification helps ensure users have the correct permissions when working with Azure's managed identities in relation to enrichment caching.

Overall, the changes enhance the clarity and accuracy of the documentation, ultimately aiding users in correctly setting up their configurations and permissions for effective data management within Azure AI Search.

## articles/search/search-howto-run-reset-indexers.md{#item-fb10c8}

<details>
<summary>Diff</summary>
````diff
@@ -102,7 +102,7 @@ After reset, follow with a Run command to reprocess new and existing documents.
 
 ## How to reset and run indexers
 
-Reset clears the high-water mark. All documents in the search index are flagged for full overwrite, without inline updates or merging into existing content. For indexers with a skillset and [enrichment caching](cognitive-search-incremental-indexing-conceptual.md), resetting the index also implicitly resets the skillset. 
+Reset clears the high-water mark. All documents in the search index are flagged for full overwrite, without inline updates or merging into existing content. For indexers with a skillset and [enrichment caching](enrichment-cache-how-to-configure.md), resetting the index also implicitly resets the skillset. 
 
 The actual work occurs when you follow a reset with a Run command:
 
@@ -182,7 +182,7 @@ catch (RequestFailedException ex) when (ex.Status == 429)
 
 ## How to reset skills (preview)
 
-For indexers that have skillsets, you can reset individual skills to force processing of just that skill and any downstream skills that depend on its output. The [enrichment cache](search-howto-incremental-index.md), if you enabled it, is also refreshed. 
+For indexers that have skillsets, you can reset individual skills to force processing of just that skill and any downstream skills that depend on its output. The [enrichment cache](enrichment-cache-how-to-configure.md), if you enabled it, is also refreshed. 
 
 [Reset Skills](/rest/api/searchservice/skillsets/reset-skills?view=rest-searchservice-2024-05-01-preview&preserve-view=true) is currently REST-only, available through 2020-06-30-preview or later. We recommend the latest preview API.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update to Enrichment Cache Link in Reset Indexers Guide"
}
```

### Explanation
The code diff reflects a minor update to the `search-howto-run-reset-indexers.md` document, revealing four total changes comprising two additions and two deletions. This modification primarily focuses on updating the link associated with the enrichment caching feature.

In the earlier version of the document, the link referencing enrichment caching was directed to `cognitive-search-incremental-indexing-conceptual.md`. With this update, the documentation now points to `enrichment-cache-how-to-configure.md`, which is expected to provide more pertinent instructions on configuring enrichment caching in the context of running and resetting indexers.

The modifications take place within sections that discuss the implications of resetting indexers, particularly around how it affects the skillsets and documents in the search index. By ensuring that links direct users to the most relevant resources, the update enhances the document's clarity and provides essential information on operational impacts when managing indexers.

Furthermore, in a section about resetting skills for indexers with skillsets, the link to enrichment caching was also updated, maintaining consistency throughout the document. This change contributes to a better understanding of the processes involved in managing enrichment caching and skills within Azure's indexing framework. Overall, the update helps streamline user access to correct and useful documentation, ultimately improving the experience of working with Azure AI Search's indexers.

## articles/search/search-indexer-access-control-lists-and-role-based-access.md{#item-67b42f}

<details>
<summary>Diff</summary>
````diff
@@ -50,7 +50,7 @@ This article supplements [**Index data from ADLS  Gen2**](search-howto-index-azu
   + [Custom Web API skill](cognitive-search-custom-skill-web-api.md)
   + [GenAI Prompt skill](cognitive-search-skill-genai-prompt.md)
   + [Knowledge store](knowledge-store-concept-intro.md)
-  + [Indexer enrichment cache](search-howto-incremental-index.md)
+  + [Indexer enrichment cache](enrichment-cache-how-to-configure.md)
   + [Debug sessions](cognitive-search-debug-session.md)
 
 ## Support for the permission model
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Indexer Enrichment Cache in Access Control Lists Guide"
}
```

### Explanation
The code diff indicates a minor update made to the `search-indexer-access-control-lists-and-role-based-access.md` document, featuring a total of two changes: one addition and one deletion. The primary focus of this modification is to update the reference link related to the indexer enrichment cache.

Previously, the document linked to `search-howto-incremental-index.md` for details about the indexer enrichment cache. This link has now been changed to direct users to `enrichment-cache-how-to-configure.md`, which is expected to provide more accurate and relevant instructions regarding the configuration of the indexer enrichment cache.

This update is part of a section that highlights other related topics and resources, ensuring that users have access to the most pertinent information. By correcting the link, the modification improves the clarity and utility of the document, aiding users in effectively configuring and managing access controls for indexers within Azure AI Search. Overall, this small but significant change enhances user experience by streamlining access to appropriate resources.

## articles/search/search-indexer-howto-access-trusted-service-exception.md{#item-e19826}

<details>
<summary>Diff</summary>
````diff
@@ -66,7 +66,7 @@ A system managed identity is a Microsoft Entra service principal. The assignment
 
 1. Add **Storage Blob Data Contributor** if write access is required.
 
-   Features that require write access include [enrichment caching](cognitive-search-incremental-indexing-conceptual.md), [debug sessions](cognitive-search-debug-session.md), and [knowledge store](knowledge-store-concept-intro.md).
+   Features that require write access include [enrichment caching](enrichment-cache-how-to-configure.md), [debug sessions](cognitive-search-debug-session.md), and [knowledge store](knowledge-store-concept-intro.md).
 
 ## Set up and test the connection
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Link for Enrichment Caching in Trusted Service Exception Guide"
}
```

### Explanation
The code diff showcases a minor update made to the `search-indexer-howto-access-trusted-service-exception.md` document, which consists of two changes: one addition and one deletion. This update is specifically aimed at correcting the reference link to the enrichment caching topic.

In the previous version of the document, the link pointing to enrichment caching was directed to `cognitive-search-incremental-indexing-conceptual.md`. The modification replaces this link with a more relevant one pointing to `enrichment-cache-how-to-configure.md`. This change ensures that users seeking information on features requiring write access, such as enrichment caching, are directed to the most appropriate and detailed resource.

The section in which this change occurred addresses the permissions needed for various features when using a Microsoft Entra service principal for system managed identities. By updating the link, the document improves its clarity and ensures that users have access to the correct guidance for enabling and configuring necessary features in Azure AI Search.

Overall, this minor update aids in enhancing the documentation's effectiveness, enabling users to better navigate the requirements for managing access and configuration of trusted services.

## articles/search/search-performance-analysis.md{#item-5032b3}

<details>
<summary>Diff</summary>
````diff
@@ -75,7 +75,7 @@ AzureDiagnostics
 
 In some cases, it can be useful to test individual queries to see how they're performing. To do this, it's important to be able to see how long the search service takes to complete the work, as well as how long it takes to make the round-trip request from the client and back to the client. The diagnostics logs could be used to look up individual operations, but it might be easier to do this all from a REST client.
 
-In the example below, a REST-based search query was executed. Azure AI Search includes in every response the number of milliseconds it takes to complete the query, visible in the Headers tab, in "elapsed-time". Next to Status at the top of the response, you'll find the round-trip duration, in this case, 418 milliseconds (ms). In the results section, the “Headers” tab was chosen. Using these two values, highlighted with a red box in the image below, we see the search service took 21 ms to complete the search query and the entire client round-trip request took 125 ms. By subtracting these two numbers we can determine that it took 104-ms additional time to transmit the search query to the search service and to transfer the search results back to the client.
+In the example below, a REST-based search query was executed. Azure AI Search includes in every response the number of milliseconds it takes to complete the query, visible in the Headers tab, in "elapsed-time". Next to Status at the top of the response, you'll find the round-trip duration, in this case, 125 milliseconds (ms). In the results section, the “Headers” tab was chosen. Using these two values, highlighted with a red box in the image below, we see the search service took 21 ms to complete the search query and the entire client round-trip request took 125 ms. By subtracting these two numbers we can determine that it took 104-ms additional time to transmit the search query to the search service and to transfer the search results back to the client.
 
 This technique helps you isolate network latencies from other factors impacting query performance.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Correct Round-Trip Duration in Performance Analysis Guide"
}
```

### Explanation
The code diff highlights a minor update in the `search-performance-analysis.md` document, consisting of two changes: one addition and one deletion. This update primarily focuses on correcting the value presented for the round-trip duration of a REST-based search query.

Earlier, the text conveyed that the round-trip duration was 418 milliseconds (ms), which was incorrect. The modification rectifies this figure to accurately reflect that the actual round-trip duration is 125 milliseconds. This clarification is crucial because it directly impacts the understanding of how long the complete request took between the client and the Azure AI Search service.

The description surrounding this measurement explains the diagnostic process for analyzing query performance using response headers, specifically how long it takes for the service to process the request and for the total round-trip. By providing the correct data, the update ensures that users can accurately evaluate search performance and identify network latencies that may affect their query outcomes.

This small yet significant change enhances the reliability and usability of the documentation, ultimately helping users make informed decisions based on accurate performance metrics.

## articles/search/search-relevance-overview.md{#item-cb0e09}

<details>
<summary>Diff</summary>
````diff
@@ -17,7 +17,7 @@ In a query operation, the relevance of any given result is determined by a ranki
 
 Ranking occurs whenever the query request includes full text or vector queries. It doesn't occur if the query invokes strict pattern matching, such as a filter-only query or a specialized query form like autocomplete, suggestions, geospatial search, fuzzy search, or regular expression search. A uniform search score of 1.0 indicates the absence of a ranking algorithm.
 
-You can enhance the quality of ranked results through ***relevance tuning*** that boosts search scores based on extra criteria or analysis. In Azure AI Search, relevance tuning is primarily directed at textual and numeric (nonvector) content when you apply a [scoring profile](#custom-boosting-logic-using-scoring-profiles) or invoke the [semantic ranker](semantic-search-overview.md). 
+***Relevance tuning*** can be used to boost search scores based on extra criteria such as freshness or proximity. In Azure AI Search, relevance tuning is primarily directed at textual and numeric (nonvector) content when you apply a [scoring profile](#custom-boosting-logic-using-scoring-profiles) or invoke the [semantic ranker](semantic-search-overview.md). 
 
 > [!NOTE]
 > In Azure AI Search, there's no explicit relevance tuning capabilities for vector content, but you can experiment between Hierarchical Navigable Small World (HNSW) and exhaustive K-nearest neighbors (KNN) to see if one algorithm outperforms the other for your scenario. HNSW graphing with an exhaustive KNN override at query time is the most flexible approach for comparison testing. You can also experiment with various embedding models to see which ones produce higher quality results.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Clarify Relevance Tuning Criteria in Overview"
}
```

### Explanation
The code diff showcases a minor update to the `search-relevance-overview.md` document, involving two changes: one addition and one deletion. This update refines the description of relevance tuning in Azure AI Search by clarifying the types of criteria that can be used to enhance search scores.

The previous text stated that relevance tuning boosts search scores based on “extra criteria or analysis." This has been updated to specify that relevance tuning can enhance scores based on criteria such as "freshness or proximity." This change provides clearer guidance on the specific aspects that can influence the ranking of search results, making it more informative for users looking to improve the relevance of their search queries.

Additionally, the context surrounding relevance tuning remains the same, explaining its application primarily to textual and numeric (nonvector) content through scoring profiles or the semantic ranker. This modification enhances the comprehensibility of the document, ensuring users have a better understanding of how to leverage relevance tuning effectively in their applications.

Overall, this minor update enhances the documentation's clarity and usability, helping users implement more effective strategies for improving search relevance.

## articles/search/search-reliability.md{#item-3e9b1a}

<details>
<summary>Diff</summary>
````diff
@@ -174,7 +174,7 @@ Traffic Manager doesn't provide an endpoint for a direct connection to Azure AI
 
 When you deploy multiple search services in various geographic regions, your content is stored in the region you chose for each search service.
 
-Azure AI Search doesn't store data outside of your specified region without your authorization. Authorization is implicit when you use features that write to an Azure Storage resource: [enrichment cache](cognitive-search-incremental-indexing-conceptual.md), [debug session](cognitive-search-debug-session.md), [knowledge store](knowledge-store-concept-intro.md). In all cases, the storage account is one that you provide, in the region of your choice. 
+Azure AI Search doesn't store data outside of your specified region without your authorization. Authorization is implicit when you use features that write to an Azure Storage resource: [enrichment cache](enrichment-cache-how-to-configure.md), [debug session](cognitive-search-debug-session.md), [knowledge store](knowledge-store-concept-intro.md). In all cases, the storage account is one that you provide, in the region of your choice. 
 
 > [!NOTE]
 > If both the storage account and the search service are in the same region, network traffic between search and storage uses a private IP address and occurs over the Microsoft backbone network. Because private IP addresses are used, you can't configure IP firewalls or a private endpoint for network security. Instead, use the [trusted service exception](search-indexer-howto-access-trusted-service-exception.md) as an alternative when both services are in the same region. 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Resource Links for Clarity"
}
```

### Explanation
The code diff reflects a minor update in the `search-reliability.md` document involving two changes: one addition and one deletion. The main focus of this modification is to update the link associated with the "enrichment cache" feature to ensure accuracy and clarity.

Originally, the document mentioned that Azure AI Search does not store data outside the specified region without user authorization, illustrated by a list of features that trigger this implicit authorization. One of these features was linked to a possibly outdated resource about the enrichment cache. The update corrects this link to direct users to the proper documentation page titled "enrichment cache: how to configure," improving the quality and accuracy of the information presented.

This change enhances the reliability of the documentation, ensuring that users have correct and up-to-date resources to consult when configuring and utilizing Azure AI Search features. It contributes to the overall clarity and utility of the document, aiding users in understanding how their data is handled in relation to geographic region and storage authorization, especially when it comes to features that write to Azure Storage resources.

## articles/search/search-security-overview.md{#item-6b3f1e}

<details>
<summary>Diff</summary>
````diff
@@ -65,7 +65,7 @@ The following list is a full enumeration of the outbound requests for which you
 | Operation | Scenario |
 | ----------| -------- |
 | Indexers | Connect to external data sources to retrieve data. For more information, see [Indexer access to content protected by Azure network security](search-indexer-securing-resources.md). |
-| Indexers | Connect to Azure Storage to persist [knowledge stores](knowledge-store-concept-intro.md), [cached enrichments](cognitive-search-incremental-indexing-conceptual.md), [debug sessions](cognitive-search-debug-session.md). |
+| Indexers | Connect to Azure Storage to persist [knowledge stores](knowledge-store-concept-intro.md), [cached enrichments](enrichment-cache-how-to-configure.md), [debug sessions](cognitive-search-debug-session.md). |
 | Custom skills | Connect to Azure functions, Azure web apps, or other apps running external code that's hosted off-service. The request for external processing is sent during skillset execution. |
 | Indexers and [integrated vectorization](vector-search-integrated-vectorization.md) | Connect to Azure OpenAI and a deployed embedding model, or it goes through a custom skill to connect to an embedding model that you provide. The search service sends text to embedding models for vectorization during indexing. |
 | Vectorizers | Connect to Azure OpenAI or other embedding models at query time to [convert user text strings to vectors](vector-search-how-to-configure-vectorizer.md) for vector search. |
@@ -167,7 +167,7 @@ When you set up a search service, you choose a region that determines where cust
 
 Currently, the only external resource that a search service writes to is Azure Storage. The storage account is one that you provide, and it could be in any region. A search service writes to Azure Storage if you use any of the following features:
 
-+ [enrichment cache](cognitive-search-incremental-indexing-conceptual.md)
++ [enrichment cache](enrichment-cache-how-to-configure.md)
 + [debug session](cognitive-search-debug-session.md)
 + [knowledge store](knowledge-store-concept-intro.md)
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Links for Enrichment Cache Guidelines"
}
```

### Explanation
The code diff indicates a minor update to the `search-security-overview.md` document with four changes: two additions and two deletions. This modification primarily focuses on updating links to ensure users have accurate and relevant information regarding the Azure AI Search features.

The key modification involves correcting the documentation link related to the "enrichment cache." The previous link directed users to an outdated resource titled "cognitive-search-incremental-indexing-conceptual.md." The update revises this link to point to the more accurate and current resource "enrichment-cache-how-to-configure.md." This change is crucial as it ensures that users receive the latest guidance on configuring the enrichment cache, which is essential for maintaining the security and efficiency of their Azure AI Search implementations.

Additionally, the table summarizing operations was updated to reflect this new link appropriately. Overall, these changes enhance the clarity and accuracy of the documentation, helping users effectively utilize Azure AI Search while ensuring they have access to updated resources for better security practices and resource management.

## articles/search/search-sku-manage-costs.md{#item-6e0122}

<details>
<summary>Diff</summary>
````diff
@@ -59,7 +59,7 @@ Depending on your configuration and usage, the following charges might apply:
 
 + Data traffic might incur networking costs. See the [bandwidth pricing](https://azure.microsoft.com/pricing/details/bandwidth/).
 
-+ Several premium features, such as [knowledge stores](knowledge-store-concept-intro.md), [debug sessions](cognitive-search-debug-session.md), and [enrichment caches](cognitive-search-incremental-indexing-conceptual.md), depend on Azure Storage and incur storage costs. Charges for these features appear on your Azure Storage bill.
++ Several premium features, such as [knowledge stores](knowledge-store-concept-intro.md), [debug sessions](cognitive-search-debug-session.md), and [enrichment caches](enrichment-cache-how-to-configure.md), depend on Azure Storage and incur storage costs. Charges for these features appear on your Azure Storage bill.
 
 + [Customer-managed keys](search-security-manage-encryption-keys.md), which provide double encryption of sensitive content, require a billable [Azure Key Vault](https://azure.microsoft.com/pricing/details/key-vault/).
 
@@ -114,7 +114,7 @@ To minimize the costs of your Azure AI Search solution, use the following strate
 
 + Use [incremental indexing](search-howto-reindex.md) to process only new or changed data.
 
-+ Use [enrichment caching](cognitive-search-incremental-indexing-conceptual.md) and a [knowledge store](knowledge-store-concept-intro.md) to reuse previously enriched content. Although caching incurs a storage charge, it lowers the cumulative cost of [AI enrichment](cognitive-search-concept-intro.md).
++ Use [enrichment caching](enrichment-cache-how-to-configure.md) and a [knowledge store](knowledge-store-concept-intro.md) to reuse previously enriched content. Although caching incurs a storage charge, it lowers the cumulative cost of [AI enrichment](cognitive-search-concept-intro.md).
 
 + Keep vector payloads compact. For vector search, see the [vector  compression best practices](https://techcommunity.microsoft.com/blog/azure-ai-services-blog/azure-ai-search-cut-vector-costs-up-to-92-5-with-new-compression-techniques/4404866).
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Links for Enrichment Caching Resource"
}
```

### Explanation
The code diff illustrates a minor update made to the `search-sku-manage-costs.md` document, consisting of four changes that involve two additions and two deletions. The primary aim of this modification is to ensure that users have access to accurate and relevant documentation regarding Azure AI Search features that impact costs.

One significant change is the update of the link for "enrichment caches." Previously, the link directed to the document "cognitive-search-incremental-indexing-conceptual.md," which may have contained outdated information. The update replaces this link with a more relevant resource titled "enrichment-cache-how-to-configure.md." This adjustment is crucial for users looking for clear and effective guidance on managing costs associated with enrichment caching.

Additionally, the document now highlights networking costs that might arise from data traffic and emphasizes the relevance of "customer-managed keys" requiring a billable Azure Key Vault, providing more comprehensive information about potential costs associated with various features.

These updates enhance the clarity of the documentation, ensuring users are well-informed about the financial implications of using Azure AI Search services and encouraging best practices for cost management. Overall, this contributes to a better user experience and helps organizations make informed decisions regarding their Azure costs.

## articles/search/toc.yml{#item-c4768f}

<details>
<summary>Diff</summary>
````diff
@@ -348,6 +348,8 @@ items:
         href: cognitive-search-working-with-skillsets.md
       - name: Create a skillset
         href: cognitive-search-defining-skillset.md
+      - name: Design tips
+        href: cognitive-search-concept-troubleshooting.md
       - name: Attach an Azure AI resource
         href: cognitive-search-attach-cognitive-services.md
       - name: Define an index projection
@@ -362,12 +364,10 @@ items:
         href: cognitive-search-output-field-mapping.md
       - name: Process image files
         href: cognitive-search-concept-image-scenarios.md
-      - name: Enrichment cache
-        href: cognitive-search-incremental-indexing-conceptual.md
-      - name: Cache (incremental) enrichment
-        href: search-howto-incremental-index.md
-      - name: Design tips
-        href: cognitive-search-concept-troubleshooting.md
+      - name: Configure an enrichment cache
+        href: enrichment-cache-how-to-configure.md
+      - name: Manage an enrichment cache
+        href: enrichment-cache-how-to-manage.md
       - name: Best practices - GenAI Prompt skill
         href: responsible-ai-best-practices-genai-prompt-skill.md
       - name: GenAI Prompt Skill - Example Usage Guide
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Table of Contents for Azure AI Search"
}
```

### Explanation
The code diff demonstrates a minor update to the `toc.yml` (Table of Contents) file for the Azure AI Search documentation. This update consists of twelve changes, including six additions and six deletions, aimed at refining the structure and accessibility of the documentation.

Key modifications include the introduction of new items such as "Design tips," linking to the document "cognitive-search-concept-troubleshooting.md," thereby enhancing the troubleshooting resources available to users. Additionally, sections pertaining to the "enrichment cache" have been updated: the outdated links have been removed and replaced with new, relevant resources—such as "Configure an enrichment cache" and "Manage an enrichment cache," linking to "enrichment-cache-how-to-configure.md" and "enrichment-cache-how-to-manage.md," respectively. 

These changes ensure that the Table of Contents accurately reflects the current resources available for users, making it easier for them to navigate through the documentation and find important information related to skillsets, enrichment caching, and best practices in Azure AI Search. Overall, it improves the user experience by streamlining access to critical content, thus supporting users in effectively utilizing Azure AI features.

## articles/search/tutorial-rag-build-solution-minimize-storage.md{#item-088ad8}

<details>
<summary>Diff</summary>
````diff
@@ -334,7 +334,7 @@ Consider revisiting the [queries from the previous tutorial](tutorial-rag-build-
 
 ## Next step
 
-There are code samples in all of the Azure SDKs that provide Azure AI Search programmability. You can also review vector sample code for specific use cases and technology combinations.
+We recommend this accelerator for you next step:
 
 > [!div class="nextstepaction"]
-> [azure-search-vector-samples](https://github.com/Azure/azure-search-vector-samples)
\ No newline at end of file
+> [RAG Experiment Accelerator](https://github.com/microsoft/rag-experiment-accelerator)
\ No newline at end of file
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Next Steps in RAG Build Solution Tutorial"
}
```

### Explanation
The code diff presents a minor update to the tutorial document titled `tutorial-rag-build-solution-minimize-storage.md`. This update features four changes consisting of two additions and two deletions, with the intent of refining the guidance provided for users following the tutorial.

One significant alteration is the enhancement of the "Next step" section. The original text was modified to recommend a specific accelerator for users, enhancing clarity on what to pursue after completing the tutorial. The previous statement about Azure SDK code samples was removed to make way for this recommendation, streamlining the user's next steps.

The tutorial now directly points users to the "RAG Experiment Accelerator" with a link to its GitHub repository, replacing the general reference to vector sample code. This change focuses the user's attention on a relevant resource that is likely more beneficial for their ongoing work with the RAG (Retrieval-Augmented Generation) solution.

Overall, this update helps users navigate their next steps more effectively by directing them to targeted resources, thereby improving the tutorial's usefulness and supporting a more efficient learning process.

## articles/search/tutorial-skillset.md{#item-8e61e7}

<details>
<summary>Diff</summary>
````diff
@@ -10,16 +10,16 @@ ms.date: 7/11/2025
 zone_pivot_groups: tutorial-create-skillset
 ---
 
-# Quickstart: Skillsets in Azure AI Search
+# Tutorial: Skillsets in Azure AI Search
 
 ::: zone pivot="csharp"
 
-[!INCLUDE [C# quickstart](includes/tutorials/skillset-csharp.md)]
+[!INCLUDE [C# tutorial](includes/tutorials/skillset-csharp.md)]
 
 ::: zone-end
 
 ::: zone pivot="rest"
 
-[!INCLUDE [REST quickstart](includes/tutorials/skillset-rest.md)]
+[!INCLUDE [REST tutorial](includes/tutorials/skillset-rest.md)]
 
 ::: zone-end
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Title and References in Skillset Tutorial"
}
```

### Explanation
The code diff reveals a minor update to the tutorial document titled `tutorial-skillset.md` regarding skillsets in Azure AI Search. This update includes a total of six changes, featuring three additions and three deletions, aimed at improving the clarity and accuracy of the content.

One of the primary changes is the modification of the document title from "Quickstart: Skillsets in Azure AI Search" to "Tutorial: Skillsets in Azure AI Search." This change aligns the document's title with its content, making it clear that the document is not just a quickstart but a comprehensive tutorial.

Additionally, the references to included content for both C# and REST have been updated from "C# quickstart" and "REST quickstart" to "C# tutorial" and "REST tutorial," respectively. This adjustment reinforces the tutorial nature of the included materials, emphasizing their role in guiding users through the processes rather than merely providing quickstart guidance.

Overall, these updates enhance user understanding and provide a more coherent framework for navigating the skillset tutorial, improving the overall instructional quality of the document.


