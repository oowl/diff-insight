---
date: '2025-07-23'
permalink: https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:8cabf74...MicrosoftDocs:e9c44be
summary: 本次修改主要集中在文档的更新和新增元素上，特别是关于混合搜索查询、概述及排名技术的改进。新增了图像示例并进行了链接和结构优化，旨在增强用户体验和提高内容的可读性。更新的亮点包括混合搜索的细节和工具说明，提高了用户的理解效果，并且通过直观的图像展示了向量化和文本提取的流程。同时，文档的结构和风格也进行了改善，以反映最新的API版本和功能更新。整体而言，这次更新提升了文档的可用性和清晰度，为用户提供了更流畅的导航体验。
title: '[zh_CN] Diff Insight Report - search'

---

[View Diff on GitHub](https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:8cabf74...MicrosoftDocs:e9c44be){target="_blank"}

## Highlights

本次修改涵盖了多个文档的更新和新增元素，主要集中在混合搜索查询、概述及排名技术的文档更新，新增了一些图像示例，并进行了链接和结构上的优化。主要亮点包括：
- 新增关于混合搜索的细节和工具说明以增强用户体验。
- 增加了多个图像文件以直观展示向量化和文本提取的操作流程。
- 更新文档链接和表达以反映最新的API版本和功能。
- 改进文档的结构和风格以提高可读性和清晰度。

## 新功能

- 新增了图像文件如“extract-text-images.png”、“vectorize-text-ai-vision.png”和“vectorize-text-catalog.png”，为用户提供更直观的视觉指南。

## 破坏性更改

- 本次更新没有破坏性更改，但涉及到文档的结构和内容调整以反映最新的功能和版本信息。

## 其他更新

- 更新了混合搜索、语义查询和向量查询相关文档，主要涉及说明的精简和链接的修正以提升用户导航体验。
- 修改了API版本信息和增加新特性说明以协助用户理解最新功能。
- 完善文档中的示例和参数设置提示，优化用户的学习曲线。

## Insights

本次修改不仅涉及到文档内容的更新，也包含了许多视觉元素的增加，这对于用户理解和操作Azure AI服务有着显著帮助。通过调整混合搜索和向量查询的文档说明，用户可以更清楚地识别新的参数和其影响。而新增的图像文件，则是为了增强文档的视觉传达能力，使复杂的操作和概念能够更易于掌握。通过对API版本和新功能的跟进，确保了文档及时反映技术进展和实际应用场景，从而帮助开发者更好地利用Azure AI搜索平台。而链接的修正，则是为了提升用户在文档中的导航体验，使其更容易找到所需信息。总的而言，本次更新有助于形成一个更加完整、易用的文档体系，进一步支持用户的开发和使用需求。

# Summary Table
|  Filename  | Type |    Title    | Status | A  | D  | M  |
|------------|------|-------------|--------|----|----|----|
| [hybrid-search-how-to-query.md](#item-345ce6) | minor update | 更新混合搜索查询文档 | modified | 144 | 116 | 260 | 
| [hybrid-search-overview.md](#item-6987b4) | minor update | 更新混合搜索概述文档 | modified | 5 | 5 | 10 | 
| [hybrid-search-ranking.md](#item-dad887) | minor update | 更新混合搜索排名文档 | modified | 7 | 7 | 14 | 
| [extract-text-images.png](#item-8a1d9b) | new feature | 添加提取图像文本的示例图 | added | 0 | 0 | 0 | 
| [vectorize-images.png](#item-7fbb9f) | minor update | 更新图像: 向量化图像 | modified | 0 | 0 | 0 | 
| [vectorize-text-ai-vision.png](#item-d49e5f) | new feature | 添加图像: AI视觉向量化文本 | added | 0 | 0 | 0 | 
| [vectorize-text-aoai.png](#item-11d419) | minor update | 重命名图像: 向量化文本至AI视觉 | renamed | 0 | 0 | 0 | 
| [vectorize-text-catalog.png](#item-51c81e) | new feature | 添加图像: 向量化目录 | added | 0 | 0 | 0 | 
| [retrieval-augmented-generation-overview.md](#item-ec76e0) | minor update | 修改查询参数说明 | modified | 1 | 1 | 2 | 
| [search-api-preview.md](#item-511f5d) | minor update | 更新混合搜索过滤器示例链接 | modified | 1 | 1 | 2 | 
| [search-get-started-portal-image-search.md](#item-438b9b) | minor update | 更新图像搜索快速入门文档 | modified | 13 | 8 | 21 | 
| [search-get-started-portal-import-vectors.md](#item-7dae77) | minor update | 更新导入向量的快速入门文档 | modified | 94 | 87 | 181 | 
| [search-region-support.md](#item-25b0f1) | minor update | 更新区域支持文档 | modified | 3 | 4 | 7 | 
| [search-what-is-azure-search.md](#item-93853a) | minor update | 更新Azure搜索介绍文档 | modified | 5 | 5 | 10 | 
| [semantic-how-to-query-request.md](#item-85530d) | minor update | 更新语义查询请求文档 | modified | 1 | 1 | 2 | 
| [semantic-how-to-query-rewrite.md](#item-3e168f) | minor update | 更新语义查询重写文档 | modified | 1 | 1 | 2 | 
| [vector-search-how-to-query.md](#item-9bb93c) | minor update | 更新向量查询文档 | modified | 1 | 11 | 12 | 
| [whats-new.md](#item-fa71b4) | minor update | 更新新增功能文档 | modified | 1 | 1 | 2 | 


# Modified Contents
## articles/search/hybrid-search-how-to-query.md{#item-345ce6}

<details>
<summary>Diff</summary>
````diff
@@ -9,22 +9,19 @@ ms.service: azure-ai-search
 ms.custom:
   - ignite-2023
 ms.topic: how-to
-ms.date: 05/08/2025
+ms.date: 07/21/2025
 ---
 
 # Create a hybrid query in Azure AI Search
 
-[Hybrid search](hybrid-search-overview.md) combines text (keyword) and vector queries in a single search request. All subqueries in the request execute in parallel. The results are merged and reordered by new search scores, using [Reciprocal Rank Fusion (RRF)](hybrid-search-ranking.md) to return a unified result set. In many cases, [per benchmark tests](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-search-outperforming-vector-search-with-hybrid/ba-p/3929167), hybrid queries with semantic ranking return the most relevant results.
+[Hybrid search](hybrid-search-overview.md) combines text (keyword) and vector queries in a single search request. Both queries execute in parallel. The results are merged and reordered by new search scores, using [Reciprocal Rank Fusion (RRF)](hybrid-search-ranking.md) to return a unified result set. In many cases, [per benchmark tests](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/azure-ai-search-outperforming-vector-search-with-hybrid/ba-p/3929167), hybrid queries with semantic ranking return the most relevant results.
 
 In this article, learn how to:
 
-+ Set up a basic request
++ Set up a basic hybrid request
 + Add parameters and filters
 + Improve relevance using semantic ranking or vector weights
-+ Optimize query behaviors by controlling text and vector inputs
-
-> [!NOTE]
-> New in [**2024-09-01-preview**](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true) is the ability to target filters to just the vector subqueries in a hybrid request. This gives you more precision over how filters are applied. For more information, see [targeting filters to vector subqueries](#hybrid-search-with-filters-targeting-vector-subqueries-preview) in this article.
++ Optimize query behaviors by controlling inputs (`maxTextRecallSize`)
 
 ## Prerequisites
 
@@ -38,30 +35,33 @@ In this article, learn how to:
 
 + Search Explorer in the Azure portal (supports both stable and preview API search syntax) has a JSON view that lets you paste in a hybrid request.
 
-+ [**2024-07-01**](/rest/api/searchservice/documents/search-post) stable version or a recent preview API version if you're using preview features like [maxTextRecallSize and countAndFacetMode(preview)](#set-maxtextrecallsize-and-countandfacetmode).
++ Newer stable or preview packages of the Azure SDKs (see change logs for SDK feature support).
+
++ [Stable REST APIs](/rest/api/searchservice/documents/search-post) or a recent preview API version if you're using preview features like [maxTextRecallSize and countAndFacetMode(preview)](#set-maxtextrecallsize-and-countandfacetmode).
 
-  For readability, we use REST examples to explain how the APIs work. You can use a REST client like Visual Studio Code with the REST extension to build hybrid queries. For more information, see [Quickstart: Vector search using REST APIs](search-get-started-vector.md).
+  For readability, we use REST examples to explain how the APIs work. You can use a REST client like Visual Studio Code with the REST extension to build hybrid queries. You can also use the Azure SDKs. For more information, see [Quickstart: Vector search](search-get-started-vector.md).
 
-+ Newer stable or beta packages of the Azure SDKs (see change logs for SDK feature support).
+## Set up a hybrid query
+
+This section explains the basic structure of a hybrid query and how to set one up in either Search Explorer or for execution in a REST client.
+
+Results are returned in plain text, including vectors in fields marked as `retrievable`. Because numeric vectors aren't useful in search results, choose other fields in the index as a proxy for the vector match. For example, if an index has "descriptionVector" and "descriptionText" fields, the query can match on "descriptionVector" but the search result can show "descriptionText". Use the `select` parameter to specify only human-readable fields in the results.
 
-## Set up a hybrid query in Search Explorer
+### [**Azure portal**](#tab/portal)
 
-1. In [Search Explorer](search-explorer.md), make sure the API version is **2024-07-01** or a newer preview API version.
+1. Sign in to the [Azure portal](https://portal.azure.com) and find your search service.
 
-1. Under **View**, select **JSON view** so that you can paste in a vector query. 
+1. Under **Search management** > **Indexes**, select an index that has vectors and non-vector content. [Search Explorer](search-explorer.md) is the first tab.
 
-1. Replace the default query template with a hybrid query, such as the "Run a hybrid query" example starting on line 539 in the [vector quickstart](https://raw.githubusercontent.com/Azure-Samples/azure-search-rest-samples/refs/heads/main/Quickstart-vectors/az-search-quickstart-vectors.rest). For brevity, the vector is truncated in this article. 
+1. Under **View**, switch to **JSON view** so that you can paste in a vector query. 
 
-   A hybrid query has a text query specified in `search`, and a vector query specified under `vectorQueries.vector`.
+1. Replace the default query template with a hybrid query. A basic hybrid query has a text query specified in `search`, and a vector query specified under `vectorQueries.vector`. The text query and vector query can be equivalent or divergent, but it's common for them to share the same intent.
 
-   The text query and vector query can be equivalent or divergent, but it's common for them to share the same intent.
+   This example is from the [vector quickstart](https://raw.githubusercontent.com/Azure-Samples/azure-search-rest-samples/refs/heads/main/Quickstart-vectors/az-search-quickstart-vectors.rest) that has vector and nonvector content, and several query examples. For brevity, the vector is truncated in this article. 
 
     ```json
     {
-        "count": true,
         "search": "historic hotel walk to restaurants and shopping",
-        "select": "HotelId, HotelName, Category, Tags, Description",
-        "top": 7,
         "vectorQueries": [
             {
                 "vector": [0.01944167, 0.0040178085, -0.007816401 ... <remaining values omitted> ], 
@@ -76,16 +76,34 @@ In this article, learn how to:
 
 1. Select **Search**.
 
-> [!TIP]
-> Search results are easier to read if you hide the vectors. In **Query Options**, turn on **Hide vector values in search results**.
+   > [!TIP]
+   > Search results are easier to read if you hide the vectors. In **Query Options**, turn on **Hide vector values in search results**.
+
+1. Here's another version of the query. This one adds a `count` for the number of matches found, a `select` parameter for choosing specific fields, and a `top` parameter to return the top seven results.
 
-## Hybrid query request (REST API)
+   ```json
+    {
+        "count": true,
+        "search": "historic hotel walk to restaurants and shopping",
+        "select": "HotelId, HotelName, Category, Tags, Description",
+        "top": 7,
+        "vectorQueries": [
+            {
+                "vector": [0.01944167, 0.0040178085, -0.007816401 ... <remaining values omitted> ], 
+                "k": 7,
+                "fields": "DescriptionVector",
+                "kind": "vector",
+                "exhaustive": true
+            }
+        ]
+    }
+    ```
 
-A hybrid query combines text search and vector search, where the `search` parameter takes a query string and `vectorQueries.vector` takes the vector query. The search engine runs full text and vector queries in parallel. The union of all matches is evaluated for relevance using Reciprocal Rank Fusion (RRF) and a single result set is returned in the response.
+### [**REST**](#tab/hybrid-rest)
 
-Results are returned in plain text, including vectors in fields marked as `retrievable`. Because numeric vectors aren't useful in search results, choose other fields in the index as a proxy for the vector match. For example, if an index has "descriptionVector" and "descriptionText" fields, the query can match on "descriptionVector" but the search result can show "descriptionText". Use the `select` parameter to specify only human-readable fields in the results.
+The following example shows a hybrid query request using the REST API.
 
-The following example shows a hybrid query configuration.
+This example is from the [vector quickstart](https://raw.githubusercontent.com/Azure-Samples/azure-search-rest-samples/refs/heads/main/Quickstart-vectors/az-search-quickstart-vectors.rest) that has vector and nonvector content, and several query examples. For brevity, the vector is truncated in this article. 
 
 ```http
 POST https://{{search-service-name}}.search.windows.net/indexes/{{index-name}}/docs/search?api-version=2024-07-01
@@ -136,7 +154,89 @@ api-key: {{admin-api-key}}
 
 + `top` determines how many matches are returned in the response all-up. In this example, the response includes 10 results, assuming there are at least 10 matches in the merged results.
 
-## Hybrid search with filter
+---
+
+## Set maxTextRecallSize and countAndFacetMode
+
+[!INCLUDE [Feature preview](./includes/previews/preview-generic.md)]
+
+A hybrid query can be tuned to control how much of each subquery contributes to the combined results. Setting `maxTextRecallSize` specifies how many BM25-ranked results are passed to the hybrid ranking model.
+
+If you use `maxTextRecallSize`, you might also want to set `CountAndFacetMode`. This parameter determines whether the `count` and `facets` should include all documents that matched the search query, or only those documents retrieved within the `maxTextRecallSize` window. The default value is "countAllResults".
+
+We recommend the latest preview REST API version [2025-05-01-preview](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2025-05-01-preview&preserve-view=true) for setting these options.
+
+> [!TIP]
+> Another approach for hybrid query tuning is [vector weighting](vector-search-how-to-query.md#vector-weighting), used to increase the importance of vector queries in the request.
+
+1. Use [Search - POST (preview)](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2025-05-01-preview&preserve-view=true) or [Search - GET (preview)](/rest/api/searchservice/documents/search-get?view=rest-searchservice-2025-05-01-preview&preserve-view=true) to specify preview parameters.
+
+1. Add a `hybridSearch` query parameter object to set the maximum number of documents recalled through the BM25-ranked results of a hybrid query. It has two properties:
+
+   + `maxTextRecallSize` specifies the number of BM25-ranked results to provide to the Reciprocal Rank Fusion (RRF) ranker used in hybrid queries. The default is 1,000. The maximum is 10,000.
+
+   + `countAndFacetMode` reports the counts for the BM25-ranked results (and for facets if you're using them). The default is all documents that match the query. Optionally, you can scope "count" to the `maxTextRecallSize`.
+
+1. Set `maxTextRecallSize`:
+
+   + Decrease `maxTextRecallSize` if vector similarity search is generally outperforming the text-side of the hybrid query.
+
+   + Increase `maxTextRecallSize` if you have a large index, and the default isn't capturing a sufficient number of results. With a larger BM25-ranked result set, you can also set `top`, `skip`, and `next` to retrieve portions of those results.
+
+The following REST examples show two use-cases for setting `maxTextRecallSize`. 
+
+The first example reduces `maxTextRecallSize` to 100, limiting the text side of the hybrid query to just 100 document. It also sets `countAndFacetMode` to include only those results from `maxTextRecallSize`.
+
+```http
+POST https://[service-name].search.windows.net/indexes/[index-name]/docs/search?api-version=2024-05-01-Preview 
+
+    { 
+      "vectorQueries": [ 
+        { 
+          "kind": "vector", 
+          "vector": [1.0, 2.0, 3.0], 
+          "fields": "my_vector_field", 
+          "k": 10 
+        } 
+      ], 
+      "search": "hello world", 
+      "hybridSearch": { 
+        "maxTextRecallSize": 100, 
+        "countAndFacetMode": "countRetrievableResults" 
+      } 
+    } 
+```
+
+The second example raises `maxTextRecallSize` to 5,000. It also uses top, skip, and next to pull results from large result sets. In this case, the request pulls in BM25-ranked results starting at position 1,500 through 2,000 as the text query contribution to the RRF composite result set.
+
+```http
+POST https://[service-name].search.windows.net/indexes/[index-name]/docs/search?api-version=2024-05-01-Preview 
+
+    { 
+      "vectorQueries": [ 
+        { 
+          "kind": "vector", 
+          "vector": [1.0, 2.0, 3.0], 
+          "fields": "my_vector_field", 
+          "k": 10 
+        } 
+      ], 
+      "search": "hello world",
+      "top": 500,
+      "skip": 1500,
+      "next": 500,
+      "hybridSearch": { 
+        "maxTextRecallSize": 5000, 
+        "countAndFacetMode": "countRetrievableResults" 
+      } 
+    } 
+```
+
+## Examples of hybrid queries
+
+This section has multiple query examples that illustrate hybrid query patterns.
+
+### Example: Hybrid search with filter
 
 This example adds a filter, which is applied to the `filterable` nonvector fields of the search index.
 
@@ -174,24 +274,24 @@ api-key: {{admin-api-key}}
 
 + When you postfilter query results, the number of results might be less than top-n.
 
-## Hybrid search with filters targeting vector subqueries (preview)
+### Example: Hybrid search with filters targeting vector subqueries (preview)
 
-Using [**2024-09-01-preview**](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true), you can override a global filter on the search request by applying a secondary filter that targets just the vector subqueries in a hybrid request.
+Using a [preview API](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2025-05-01-preview&preserve-view=true), you can override a global filter on the search request by applying a secondary filter that targets just the vector subqueries in a hybrid request.
 
 This feature provides fine-grained control by ensuring that filters only influence the vector search results, leaving keyword-based search results unaffected. 
 
 The targeted filter fully overrides the global filter, including any filters used for [security trimming](search-security-trimming-for-azure-search.md) or geospatial search.  In cases where global filters are required, such as security trimming, you must explicitly include these filters in both the top-level filter and in each vector-level filter to ensure security and other constraints are consistently enforced.
 
 To apply targeted vector filters:
 
-+ Use the [latest preview Search Documents REST API](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true#request-body) or an Azure SDK beta package that provides the feature.
++ Use the [latest preview Search Documents REST API](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2025-05-01-preview&preserve-view=true#request-body) or an Azure SDK beta package that provides the feature.
 
 + Modify a query request, adding a new `vectorQueries.filterOverride` parameter set to an [OData filter expression](search-query-odata-filter.md).
 
-Here's an example of hybrid query that adds a filter override. The global filter "Rating gt 3" is replaced at run time by the filterOvrride.
+Here's an example of hybrid query that adds a filter override. The global filter "Rating gt 3" is replaced at run time by the `filterOverride`.
 
 ```http
-POST https://{{search-service-name}}.search.windows.net/indexes/{{index-name}}/docs/search?api-version=2024-09-01=preview
+POST https://{{search-service-name}}.search.windows.net/indexes/{{index-name}}/docs/search?api-version=2025-05-01=preview
 
 {
     "vectorQueries": [
@@ -218,7 +318,7 @@ POST https://{{search-service-name}}.search.windows.net/indexes/{{index-name}}/d
 }
 ```
 
-## Semantic hybrid search
+### Example: Semantic hybrid search
 
 Assuming that you [have semantic ranker](semantic-how-to-enable-disable.md) and your index definition includes a [semantic configuration](semantic-how-to-query-request.md), you can formulate a query that includes vector search and keyword search, with semantic ranking over the merged result set. Optionally, you can add captions and answers. 
 
@@ -261,7 +361,7 @@ api-key: {{admin-api-key}}
 
 + "captions" and "answers" are optional. Values are extracted from verbatim text in the results. An answer is only returned if the results include content having the characteristics of an answer to the query.
 
-## Semantic hybrid search with filter
+### Example: Semantic hybrid search with filter
 
 Here's the last query in the collection. It's the same semantic hybrid query as the previous example, but with a filter.
 
@@ -304,90 +404,18 @@ api-key: {{admin-api-key}}
 
 + Postfilter is applied after query execution. If k=50 returns 50 matches on the vector query side, followed by a post-filter applied to the 50 matches, your results are reduced by the number of documents that meet filter criteria. This leaves you with fewer than 50 documents to pass to semantic ranker. Keep this in mind if you're using semantic ranking. The semantic ranker works best if it has 50 documents as input.
 
-## Set maxTextRecallSize and countAndFacetMode
-
-[!INCLUDE [Feature preview](./includes/previews/preview-generic.md)]
-
-This section explains how to adjust the inputs to a hybrid query by controlling the amount BM25-ranked results that flow to the hybrid ranking model. Controlling over the BM25-ranked input gives you more options for relevance tuning in hybrid scenarios.
-
-We recommend preview REST API version [2024-05-01-preview](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-05-01-preview&preserve-view=true).
-
-> [!TIP]
-> Another option to consider is a supplemental or replacement technique, is [vector weighting](vector-search-how-to-query.md#vector-weighting), which increases the importance of vector queries in the request.
-
-1. Use [Search - POST](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-05-01-preview&preserve-view=true) or [Search - GET](/rest/api/searchservice/documents/search-get?view=rest-searchservice-2024-05-01-preview&preserve-view=true) in 2024-05-01-preview to specify these parameters.
-
-1. Add a `hybridSearch` query parameter object to set the maximum number of documents recalled through the BM25-ranked results of a hybrid query. It has two properties:
-
-   + `maxTextRecallSize` specifies the number of BM25-ranked results to provide to the Reciprocal Rank Fusion (RRF) ranker used in hybrid queries. The default is 1,000. The maximum is 10,000.
-
-   + `countAndFacetMode` reports the counts for the BM25-ranked results (and for facets if you're using them). The default is all documents that match the query. Optionally, you can scope "count" to the `maxTextRecallSize`.
-
-1. Reduce `maxTextRecallSize` if vector similarity search is generally outperforming the text-side of the hybrid query.
-
-1. Raise `maxTextRecallSize` if you have a large index, and the default isn't capturing a sufficient number of results. With a larger BM25-ranked result set, you can also set `top`, `skip`, and `next` to retrieve portions of those results.
-
-The following REST examples show two use-cases for setting `maxTextRecallSize`. 
-
-The first example reduces `maxTextRecallSize` to 100, limiting the text side of the hybrid query to just 100 document. It also sets `countAndFacetMode` to include only those results from `maxTextRecallSize`.
-
-```http
-POST https://[service-name].search.windows.net/indexes/[index-name]/docs/search?api-version=2024-05-01-Preview 
-
-    { 
-      "vectorQueries": [ 
-        { 
-          "kind": "vector", 
-          "vector": [1.0, 2.0, 3.0], 
-          "fields": "my_vector_field", 
-          "k": 10 
-        } 
-      ], 
-      "search": "hello world", 
-      "hybridSearch": { 
-        "maxTextRecallSize": 100, 
-        "countAndFacetMode": "countRetrievableResults" 
-      } 
-    } 
-```
-
-The second example raises `maxTextRecallSize` to 5,000. It also uses top, skip, and next to pull results from large result sets. In this case, the request pulls in BM25-ranked results starting at position 1,500 through 2,000 as the text query contribution to the RRF composite result set.
-
-```http
-POST https://[service-name].search.windows.net/indexes/[index-name]/docs/search?api-version=2024-05-01-Preview 
-
-    { 
-      "vectorQueries": [ 
-        { 
-          "kind": "vector", 
-          "vector": [1.0, 2.0, 3.0], 
-          "fields": "my_vector_field", 
-          "k": 10 
-        } 
-      ], 
-      "search": "hello world",
-      "top": 500,
-      "skip": 1500,
-      "next": 500,
-      "hybridSearch": { 
-        "maxTextRecallSize": 5000, 
-        "countAndFacetMode": "countRetrievableResults" 
-      } 
-    } 
-```
-
 ## Configure a query response
 
-When you're setting up the hybrid query, think about the response structure. The response is a flattened rowset. Parameters on the query determine which fields are in each row and how many rows are in the response. The search engine ranks the matching documents and returns the most relevant results.
+When you're setting up the hybrid query, think about the response structure. The search engine ranks the matching documents and returns the most relevant results. The response is a flattened rowset. Parameters on the query determine which fields are in each row and how many rows are in the response. 
 
 ### Fields in a response
 
 Search results are composed of `retrievable` fields from your search index. A result is either:
 
 + All `retrievable` fields (a REST API default).
-+ Fields explicitly listed in a "select" parameter on the query. 
++ Fields explicitly listed in a `select` parameter on the query. 
 
-The examples in this article used a "select" statement to specify text (nonvector) fields in the response.
+The examples in this article used a `select` statement to specify text (nonvector) fields in the response.
 
 > [!NOTE]
 > Vectors aren't reverse engineered into human readable text, so avoid returning them in the response. Instead, choose nonvector fields that are representative of the search document. For example, if the query targets a "DescriptionVector" field, return an equivalent text field if you have one ("Description") in the response.
@@ -400,22 +428,22 @@ A query might match to any number of documents, as many as all of them if the se
 + `"k": n` results for vector-only queries
 + `"top": n` results for hybrid queries (with or without semantic) that include a "search" parameter
 
-Both "k" and "top" are optional. Unspecified, the default number of results in a response is 50. You can set "top" and "skip" to [page through more results](search-pagination-page-layout.md#paging-results) or change the default.
+Both `k` and `top` are optional. Unspecified, the default number of results in a response is 50. You can set `top` and `skip` to [page through more results](search-pagination-page-layout.md#paging-results) or change the default.
 
 > [!NOTE]
-> If you're using hybrid search in 2024-05-01-preview API, you can control the number of results from the keyword query using [maxTextRecallSize](#set-maxtextrecallsize-and-countandfacetmode). Combine this with a setting for "k" to control the representation from each search subsystem (keyword and vector).
+> If you're using hybrid search in 2024-05-01-preview API, you can control the number of results from the keyword query using [maxTextRecallSize](#set-maxtextrecallsize-and-countandfacetmode). Combine this with a setting for `k` to control the representation from each search subsystem (keyword and vector).
 
-#### Semantic ranker results
+### Semantic ranker results
 
 > [!NOTE]
 > The semantic ranker can take up to 50 results. 
 
-If you're using semantic ranker in 2024-05-01-preview API, it's a best practice to set "k" and "maxTextRecallSize" to sum to at least 50 total.  You can then restrict the results returned to the user with the "top" parameter. 
+If you're using semantic ranker in 2024-05-01-preview or later, it's a best practice to set `k` and `maxTextRecallSize` to sum to at least 50 total.  You can then restrict the results returned to the user with the `top` parameter. 
 
 If you're using semantic ranker in previous APIs do the following:
 
-+ if doing keyword-only search (no vector) set "top" to 50
-+ if doing hybrid search set "k" to 50, to ensure that the semantic ranker gets at least 50 results. 
++ For keyword-only search (no vectors) set `top` to 50
++ For hybrid search set `k` to 50, to ensure that the semantic ranker gets at least 50 results. 
 
 ### Ranking
 
@@ -453,6 +481,6 @@ In this section, compare the responses between single vector search and simple h
 }
 ```
 
-## Next steps
+## Next step
 
-As a next step, we recommend reviewing the demo code for [Python](https://github.com/Azure/azure-search-vector-samples/tree/main/demo-python), [C#](https://github.com/Azure/azure-search-vector-samples/tree/main/demo-dotnet) or [JavaScript](https://github.com/Azure/azure-search-vector-samples/tree/main/demo-javascript).
+We recommend reviewing vector demo code for [Python](https://github.com/Azure/azure-search-vector-samples/tree/main/demo-python), [C#](https://github.com/Azure/azure-search-vector-samples/tree/main/demo-dotnet) or [JavaScript](https://github.com/Azure/azure-search-vector-samples/tree/main/demo-javascript).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新混合搜索查询文档"
}
```

### Explanation
此修改对文档《如何进行混合搜索查询》进行了多个小幅更新，主要旨在提高内容的准确性和可读性。新增和删除的内容反映了关于混合搜索的最新功能和使用方法，包括对一些参数的更正和更新。此外，还调整了一些API的版本说明，为用户提供更明确的指引。

具体来说，文件增加了关于混合検索配置的详细指导，并强化了对新特性的介绍，如如何设置 `maxTextRecallSize` 和 `countAndFacetMode` 参数。此外，更新还包含了一些示例查询，演示了如何有效使用REST API进行混合查询。这些更改旨在帮助用户更好地理解和利用最新的混合搜索功能，从而提升他们的搜索效率和准确性。

## articles/search/hybrid-search-overview.md{#item-6987b4}

<details>
<summary>Diff</summary>
````diff
@@ -9,22 +9,22 @@ ms.service: azure-ai-search
 ms.custom:
   - ignite-2023
 ms.topic: conceptual
-ms.date: 05/27/2025
+ms.date: 07/21/2025
 ---
 
 # Hybrid search using vectors and full text in Azure AI Search
 
-Hybrid search is a single query request, configured for full text and vector search, that executes against a search index containing both searchable plain text content and generated embeddings. For query purposes, hybrid search is:
+Hybrid search is a single query request, configured for full text and vector queries, that executes against a search index containing both searchable plain text content and generated embeddings. For query purposes, hybrid search is:
 
 + A single query request that includes both `search` and `vectors` query parameters
 + Executing in parallel
-+ With merged results in the query response, scored using [Reciprocal Rank Fusion (RRF)](hybrid-search-ranking.md)
++ Merging results from each query using [Reciprocal Rank Fusion (RRF)](hybrid-search-ranking.md)
 
-This article explains the concepts, benefits, and limitations of hybrid search. Links at the end provide instructions and next steps. You can also watch this [embedded video](#why-choose-hybrid-search) for an explanation of how hybrid retrieval contributes to high quality RAG apps.
+This article explains the concepts, benefits, and limitations of hybrid search. Links at the end provide instructions and next steps. You can also watch this [embedded video](#why-choose-hybrid-search) for an explanation of how hybrid retrieval contributes to high quality generative search applications.
 
 ## How does hybrid search work?
 
-In Azure AI Search, vector fields containing embeddings can live alongside textual and numerical fields, allowing you to formulate hybrid queries that execute in parallel. Hybrid queries can take advantage of existing text-based functionality like filtering, faceting, sorting, scoring profiles, and [semantic ranking](semantic-search-overview.md) on your text fields, while executing a similarity search against vectors, all in a single search request.
+In a search index, vector fields containing embeddings coexist with textual and numerical fields, allowing you to formulate hybrid queries that execute in parallel. Hybrid queries can take advantage of existing text-based functionality like filtering, faceting, sorting, scoring profiles, and [semantic ranking](semantic-search-overview.md) on your text fields, while executing a similarity search against vectors, all in a single search request.
 
 Hybrid search combines results from both full text and vector queries, which use different ranking functions such as BM25 for text, and Hierarchical Navigable Small World (HNSW) and exhaustive K Nearest Neighbors (eKNN) for vectors. A [Reciprocal Rank Fusion (RRF)](hybrid-search-ranking.md) algorithm merges the results. The query response provides just one result set, using RRF to rank the unified results.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新混合搜索概述文档"
}
```

### Explanation
此修改对文档《混合搜索概述》进行了小幅更新，主要内容包括更改日期和对混合搜索的描述。更新后的文档对混合搜索的定义进行了精简，并明确指出在Azure AI搜索中，混合查询同时支持文本和向量搜索。

具体来说，修改调整了“混合搜索”这一术语的描述，将其表达得更加简洁明了。同时，文中也将“生成检索应用”更新为“高质量生成搜索应用”的相关内容。这些修改意在提高文档的清晰度和可读性，使用户更好地理解混合搜索的功能及其在实际应用中的价值。

## articles/search/hybrid-search-ranking.md{#item-dad887}

<details>
<summary>Diff</summary>
````diff
@@ -9,17 +9,17 @@ ms.service: azure-ai-search
 ms.custom:
   - ignite-2023
 ms.topic: conceptual
-ms.date: 03/11/2025
+ms.date: 07/21/2025
 ---
 
 # Relevance scoring in hybrid search using Reciprocal Rank Fusion (RRF)
 
-Reciprocal Rank Fusion (RRF) is an algorithm that evaluates the search scores from multiple, previously ranked results to produce a unified result set. In Azure AI Search, RRF is used whenever there are two or more queries that execute in parallel. Each query produces a ranked result set, and RRF merges and homogenizes the rankings into a single result set for the query response. Examples of scenarios where RRF is always used include [*hybrid search*](hybrid-search-overview.md) and multiple vector queries executing concurrently. 
+Reciprocal Rank Fusion (RRF) is an algorithm that evaluates the search scores from multiple, previously ranked results to produce a unified result set. In Azure AI Search, RRF is used when two or more queries execute in parallel. Namely, for [hybrid queries](hybrid-search-overview.md) and for [multiple vector queries](vector-search-overview.md). Each individual query produces a ranked result set, and RRF merges and homogenizes the rankings into a single result set for the query response. 
 
 RRF is based on the concept of *reciprocal rank*, which is the inverse of the rank of the first relevant document in a list of search results. The goal of the technique is to take into account the position of the items in the original rankings, and give higher importance to items that are ranked higher in multiple lists. This can help improve the overall quality and reliability of the final ranking, making it more useful for the task of fusing multiple ordered search results.
 
 > [!NOTE]
-> New in [**2024-09-01-preview**](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true) is the ability to deconstruct an RRF-ranked search score into its component subscores. This gives you transparency into all-up score composition. For more information, see [unpack search scores (preview)](#unpack-a-search-score-into-subscores-preview) in this article.
+> [Preview APIs](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2025-05-01-preview&preserve-view=true) can deconstruct an RRF-ranked search score into its component subscores. This gives you transparency into all-up score composition. For more information, see [unpack search scores (preview)](#unpack-a-search-score-into-subscores-preview) in this article.
 
 ## How RRF ranking works
 
@@ -62,20 +62,20 @@ Semantic ranking occurs after RRF merging of results. Its score (`@search.rerank
 
 ## Unpack a search score into subscores (preview)
 
-Using [**2024-09-01-preview**](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true), you can deconstruct a search score to view its subscores.
+Using the [latest preview API version](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2025-05-01-preview&preserve-view=true), you can deconstruct a search score to view its subscores.
 
 For vector queries, this information can help you determine an appropriate value for [vector weighting](vector-search-how-to-query.md#vector-weighting) or [setting minimum thresholds](vector-search-how-to-query.md#set-thresholds-to-exclude-low-scoring-results-preview).
 
 To get subscores:
 
-+ Use the [latest preview Search Documents REST API](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true#request-body) or an Azure SDK beta package that provides the feature.
++ Use the [latest preview Search Documents REST API](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2025-05-01-preview&preserve-view=true#request-body) or an Azure SDK beta package that provides the feature.
 
 + Modify a query request, adding a new `debug` parameter set to either `vector`, `semantic` if using semantic ranker, or `all`.
 
 Here's an example of hybrid query that returns subscores in debug mode:
 
 ```http
-POST https://{{search-service-name}}.search.windows.net/indexes/{{index-name}}/docs/search?api-version=2024-09-01=preview
+POST https://{{search-service-name}}.search.windows.net/indexes/{{index-name}}/docs/search?api-version=2025-05-01=preview
 
 {
     "vectorQueries": [
@@ -115,7 +115,7 @@ POST https://{{search-service-name}}.search.windows.net/indexes/{{index-name}}/d
 
 ## Weighted scores
 
-Using [**2024-07-01**](/rest/api/searchservice/documents/search-post) and newer preview API versions, you can [weight vector queries](vector-search-how-to-query.md#vector-weighting) to increase or decrease their importance in a hybrid query.
+Using the [stable REST API version](/rest/api/searchservice/documents/search-post) and newer preview API versions, you can [weight vector queries](vector-search-how-to-query.md#vector-weighting) to increase or decrease their importance in a hybrid query.
 
 Recall that when computing RRF for a certain document, the search engine looks at the rank of that document for each result set where it shows up. Assume a document shows up in three separate search results, where the results are from two vector queries and one text BM25-ranked query. The position of the document varies in each result.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新混合搜索排名文档"
}
```

### Explanation
此修改对文档《混合搜索中的相关性评分使用互惠排名融合（RRF）》进行了小幅更新，主要更新了文档的日期以及对互惠排名融合算法的描述。修改后的文档更加明确地指出，互惠排名融合用于并行执行的查询，特别是在处理混合查询和多个向量查询时。

具体而言，文中更新了RRF的描述，使其更加简洁，并将“新功能”中的版本信息更新为最新的预览API版本。此外，修改还强化了有关解构搜索分数的讨论，指引用户如何获取各个分数的详细信息。这些更新有助于用户更好地理解RRF的工作原理及其在混合搜索中的应用，从而提升他们在使用Azure AI搜索的体验和效率。

## articles/search/media/search-get-started-portal-import-vectors/extract-text-images.png{#item-8a1d9b}

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "添加提取图像文本的示例图"
}
```

### Explanation
此次修改在文档中新增了一张名为“extract-text-images.png”的图像，旨在帮助用户更好地理解在门户中导入向量时提取图像文本的过程。这张图像作为视觉辅助材料，可以使相关操作和步骤更加清晰，提升用户的学习体验和操作效率。通过增加该图像，文档在视觉呈现上得到了增强，帮助用户直观理解所涉及的概念和步骤。

## articles/search/media/search-get-started-portal-import-vectors/vectorize-images.png{#item-7fbb9f}

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新图像: 向量化图像"
}
```

### Explanation
此次修改对名为“vectorize-images.png”的图像进行了更新。尽管该文件的内容或格式没有变化，但此更新可能涉及图像的清晰度或展示效果的优化。这张图像与在门户中进行向量化图像的过程相关，是用户理解和使用Azure AI功能的一个重要视觉参考。通过更新图像，文档能够为用户提供更准确、更易于理解的视觉信息，从而增强其整体学习体验。

## articles/search/media/search-get-started-portal-import-vectors/vectorize-text-ai-vision.png{#item-d49e5f}

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "添加图像: AI视觉向量化文本"
}
```

### Explanation
此次修改在文档中新增了一张名为“vectorize-text-ai-vision.png”的图像，旨在展示如何使用AI技术进行文本的向量化。这张图像将为用户提供直观的理解，有助于他们掌握在Azure AI平台上进行文本处理的相关流程和概念。通过引入这项新视觉内容，文档的说明更加丰富，能够更好地支持用户在实际操作中的理解和应用。

## articles/search/media/search-get-started-portal-import-vectors/vectorize-text-aoai.png{#item-11d419}

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "重命名图像: 向量化文本至AI视觉"
}
```

### Explanation
此次修改将名为“vectorize-text.png”的图像重命名为“vectorize-text-aoai.png”。这一变更可能是为了更准确地反映图像内容及其与Azure AI视觉相关的应用场景。重命名有助于提升文档的清晰度，使用户在查找和理解内容时能够更轻松地识别该图像的具体用途和含义。通过这种方式，文档的整体组织和信息传达都得到了改进，用户的体验得以增强。

## articles/search/media/search-get-started-portal-import-vectors/vectorize-text-catalog.png{#item-51c81e}

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "添加图像: 向量化目录"
}
```

### Explanation
此次修改在文档中新增了一张名为“vectorize-text-catalog.png”的图像，旨在展示与向量化目录相关的内容。该图像的引入为用户提供了更加明确的视觉辅助，帮助他们更好地理解在Azure AI平台上如何进行文本向量化的具体步骤。通过添加这一新图像，文档内容变得更加生动，有利于增强用户的学习体验和操作指南的有效性。

## articles/search/retrieval-augmented-generation-overview.md{#item-ec76e0}

<details>
<summary>Diff</summary>
````diff
@@ -148,7 +148,7 @@ Here are some tips for maximizing relevance and recall:
 
   + [Semantic ranker](semantic-ranking.md) that re-ranks an initial results set, using semantic models from Bing to reorder results for a better semantic fit to the original query.
 
-  + Query parameters for fine-tuning. You can [bump up the importance of vector queries](vector-search-how-to-query.md#vector-weighting) or [adjust the amount of BM25-ranked results](vector-search-how-to-query.md#maxtextsizerecall-for-hybrid-search-preview) in a hybrid query. You can also [set minimum thresholds to exclude low scoring results](vector-search-how-to-query.md#set-thresholds-to-exclude-low-scoring-results-preview) from a vector query.
+  + Query parameters for fine-tuning. You can [boost the importance of vector queries](vector-search-how-to-query.md#vector-weighting) or [adjust the amount of BM25-ranked results](hybrid-search-how-to-query.md#set-maxtextrecallsize-and-countandfacetmode) in a hybrid query response. You can also [set minimum thresholds to exclude low scoring results](vector-search-how-to-query.md#set-thresholds-to-exclude-low-scoring-results-preview) from a vector query.
 
 In comparison and benchmark testing, hybrid queries with text and vector fields, supplemented with semantic ranking, produce the most relevant results.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "修改查询参数说明"
}
```

### Explanation
此次修改对文档中的查询参数说明进行了小幅更新。具体而言，改变了对BM25排名结果调整部分的链接，使其指向了一个更合适的文档。修改确保了信息的准确性，使用户能够更方便地找到有关如何在混合查询中调整BM25排名结果的具体指导。这一更新有助于提升文档的可用性，使用户在进行相关操作时能够更顺利地获取所需信息，从而提高其在使用Azure AI时的整体体验。

## articles/search/search-api-preview.md{#item-511f5d}

<details>
<summary>Diff</summary>
````diff
@@ -44,7 +44,7 @@ Preview features are removed from this list if they're retired or transition to
 | [**Rescoring options for compressed vectors**](vector-search-how-to-quantization.md) | Relevance (scoring) | You can set options to rescore with original vectors instead of compressed vectors. Applies to HNSW and exhaustive KNN vector algorithms, using binary and scalar compression. | [Create or Update Index (preview)](/rest/api/searchservice/indexes/create-or-update?view=rest-searchservice-2024-09-01-preview&preserve-view=true).|
 | [**Lower the dimension requirements for MRL-trained text embedding models on Azure OpenAI**](vector-search-how-to-truncate-dimensions.md) | Index | Text-embedding-3-small and Text-embedding-3-large are trained using Matryoshka Representation Learning (MRL). This allows you to truncate the embedding vectors to fewer dimensions, and adjust the balance between vector index size usage and retrieval quality. A new `truncationDimension` provides the MRL behaviors as an extra parameter in a vector compression configuration. This can only be configured for new vector fields. | [Create or Update Index (preview)](/rest/api/searchservice/indexes/create-or-update?view=rest-searchservice-2024-09-01-preview&preserve-view=true). |
 | [**Unpack `@search.score` to view subscores in hybrid search results**](hybrid-search-ranking.md#unpack-a-search-score-into-subscores-preview) | Relevance (scoring) | You can investigate Reciprocal Rank Fusion (RRF) ranked results by viewing the individual query subscores of the final merged and scored result. A new `debug` property unpacks the search score. `QueryResultDocumentSubscores`, `QueryResultDocumentRerankerInput`, and `QueryResultDocumentSemanticField` provide the extra detail. | [Search Documents (preview)](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true). |
-| [**Target filters in a hybrid search to just the vector queries**](hybrid-search-how-to-query.md#hybrid-search-with-filters-targeting-vector-subqueries-preview) | Query | A filter on a hybrid query involves all subqueries on the request, regardless of type. You can override the global filter to scope the filter to a specific subquery. A new `filterOverride` parameter provides the behaviors. | [Search Documents (preview)](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true). |
+| [**Target filters in a hybrid search to just the vector queries**](hybrid-search-how-to-query.md#example-hybrid-search-with-filters-targeting-vector-subqueries-preview) | Query | A filter on a hybrid query involves all subqueries on the request, regardless of type. You can override the global filter to scope the filter to a specific subquery. A new `filterOverride` parameter provides the behaviors. | [Search Documents (preview)](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true). |
 | [**Text Split skill (token chunking)**](cognitive-search-skill-textsplit.md) | Applied AI (skills) | This skill has new parameters that improve data chunking for embedding models. A new `unit` parameter lets you specify token chunking. You can now chunk by token length, setting the length to a value that makes sense for your embedding model. You can also specify the tokenizer and any tokens that shouldn't be split during data chunking. | [Create or Update Skillset (preview)](/rest/api/searchservice/skillsets/create-or-update?view=rest-searchservice-2024-09-01-preview&preserve-view=true). |
 | [**Azure AI Vision multimodal embedding skill**](cognitive-search-skill-vision-vectorize.md) | Applied AI (skills) | A new skill type that calls Azure AI Vision multimodal API to generate embeddings for text or images during indexing. | [Create or Update Skillset (preview)](/rest/api/searchservice/skillsets/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true). |
 | [**Azure Machine Learning (AML) skill**](cognitive-search-aml-skill.md) | Applied AI (skills) | AML skill integrates an inferencing endpoint from Azure Machine Learning. In previous preview APIs, it supports connections to deployed custom models in an AML workspace. Starting in the 2024-05-01-preview, you can use this skill in workflows that connect to embedding models in the Azure AI Foundry model catalog. It's also available in the Azure portal, in skillset design, assuming Azure AI Search and Azure Machine Learning services are deployed in the same subscription. | [Create or Update Skillset (preview)](/rest/api/searchservice/skillsets/create-or-update?view=rest-searchservice-2024-05-01-preview&preserve-view=true). |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新混合搜索过滤器示例链接"
}
```

### Explanation
此次修改对文档中的一个条目进行了小幅更新，特别是针对混合搜索中的过滤器进行了链接的更改。原有的链接被更新为指向一个包含混合搜索过滤器示例的新位置，这有助于用户更好地理解如何将过滤器应用于特定的子查询。此更新确保了信息的准确性和实用性，提高了用户在使用搜索API时的体验，使他们更有可能找到所需的具体指导和例子。通过这种方式，用户能够更有效地利用新的功能，从而优化其搜索请求的结果。

## articles/search/search-get-started-portal-image-search.md{#item-438b9b}

<details>
<summary>Diff</summary>
````diff
@@ -7,7 +7,7 @@ ms.author: haileytapia
 ms.service: azure-ai-search
 ms.update-cycle: 90-days
 ms.topic: quickstart
-ms.date: 07/16/2025
+ms.date: 07/22/2025
 ms.custom:
   - references_regions
 ---
@@ -52,7 +52,7 @@ For content embedding, you can choose either image verbalization (followed by te
 | Method | Description | Supported models |
 |--|--|--|
 | Image verbalization | Uses an LLM to generate natural-language descriptions of images, and then uses an embedding model to vectorize plain text and verbalized images.<br><br>Requires an [Azure OpenAI resource](/azure/ai-services/openai/how-to/create-resource) <sup>1, 2</sup> or [Azure AI Foundry project](/azure/ai-foundry/how-to/create-projects).<br><br>For text vectorization, you can also use an [Azure AI services multi-service resource](/azure/ai-services/multi-service-resource#azure-ai-multi-services-resource-for-azure-ai-search-skills) <sup>3</sup> in a [supported region](cognitive-search-skill-vision-vectorize.md). | LLMs:<br>GPT-4o<br>GPT-4o-mini<br>phi-4 <sup>4</sup><br><br>Embedding models:<br>text-embedding-ada-002<br>text-embedding-3-small<br>text-embedding-3-large |
-| Multimodal embeddings | Uses an embedding model to directly vectorize both text and images.<br><br>Requires an [Azure AI Foundry project](/azure/ai-foundry/how-to/create-projects) or [Azure AI services multi-service resource](/azure/ai-services/multi-service-resource#azure-ai-multi-services-resource-for-azure-ai-search-skills) <sup>3</sup> in a [supported region](cognitive-search-skill-vision-vectorize.md). | Cohere-embed-v3-english<br>Cohere-embed-v3-multilingual<br>Cohere-embed-v4 <sup>5</sup> |
+| Multimodal embeddings | Uses an embedding model to directly vectorize both text and images.<br><br>Requires an [Azure AI Foundry hub-based project](/azure/ai-foundry/how-to/create-projects) or [Azure AI services multi-service resource](/azure/ai-services/multi-service-resource#azure-ai-multi-services-resource-for-azure-ai-search-skills) <sup>3</sup> in a [supported region](cognitive-search-skill-vision-vectorize.md). | Cohere-embed-v3-english<br>Cohere-embed-v3-multilingual<br>Cohere-embed-v4 <sup>5</sup> |
 
 <sup>1</sup> The endpoint of your Azure OpenAI resource must have a [custom subdomain](/azure/ai-services/cognitive-services-custom-subdomains), such as `https://my-unique-name.openai.azure.com`. If you created your resource in the [Azure portal](https://portal.azure.com/), this subdomain was automatically generated during resource setup.
 
@@ -128,6 +128,9 @@ On your Azure OpenAI resource:
 
 The Azure AI Foundry model catalog provides LLMs for image verbalization and embedding models for text and image vectorization. Your search service requires access to call the [GenAI Prompt skill](cognitive-search-skill-genai-prompt.md) and [AML skill](cognitive-search-aml-skill.md).
 
+> [!NOTE]
+> If you're using a hub-based project for multimodal embeddings, skip this step. The wizard requires key-based authentication in this scenario.
+
 On your Azure AI Foundry project:
 
 + Assign **Azure AI Project Manager** to your [search service identity](search-howto-managed-identities-data-sources.md#create-a-system-managed-identity).
@@ -197,7 +200,7 @@ Azure AI Search requires a connection to a data source for content ingestion and
 
 To connect to your data:
 
-1. On the **Connect to your data** page, specify your Azure subscription.
+1. On the **Connect to your data** page, select your Azure subscription.
 
 1. Select the storage account and container to which you uploaded the sample data.
 
@@ -233,7 +236,7 @@ To use the Document Layout skill:
 
    :::image type="content" source="media/search-get-started-portal-images/extract-your-content-doc-intelligence.png" alt-text="Screenshot of the wizard page with Azure AI Document Intelligence selected for content extraction." border="true" lightbox="media/search-get-started-portal-images/extract-your-content-doc-intelligence.png":::
 
-1. Specify your Azure subscription and multi-service resource.
+1. Select your Azure subscription and multi-service resource.
 
 1. For the authentication type, select **System assigned identity**.
 
@@ -267,7 +270,7 @@ To use the skills for image verbalization:
 
    1. For the kind, select your LLM provider: **Azure OpenAI** or **AI Foundry Hub catalog models**.
 
-   1. Specify your Azure subscription, resource, and LLM deployment.
+   1. Select your Azure subscription, resource, and LLM deployment.
 
    1. For the authentication type, select **System assigned identity**.
 
@@ -279,7 +282,7 @@ To use the skills for image verbalization:
 
    1. For the kind, select your model provider: **Azure OpenAI**, **AI Foundry Hub catalog models**, or **AI Vision vectorization**.
 
-   1. Specify your Azure subscription, resource, and embedding model deployment.
+   1. Select your Azure subscription, resource, and embedding model deployment (if applicable).
 
    1. For the authentication type, select **System assigned identity**.
 
@@ -305,7 +308,9 @@ To use the skills for multimodal embeddings:
 
    If Azure AI Vision is unavailable, make sure your search service and multi-service resource are both in a [region that supports the Azure AI Vision multimodal APIs](/azure/ai-services/computer-vision/how-to/image-retrieval).
 
-1. Specify your Azure subscription, resource, and embedding model deployment.
+1. Select your Azure subscription, resource, and embedding model deployment (if applicable).
+
+1. If you're using Azure AI Vision, select **System assigned identity** for the authentication type. Otherwise, leave it as **API key**.
 
 1. Select the checkbox that acknowledges the billing effects of using this resource.
 
@@ -321,7 +326,7 @@ The next step is to send images extracted from your documents to Azure Storage.
 
 To store the extracted images:
 
-1. On the **Image output** page, specify your Azure subscription.
+1. On the **Image output** page, select your Azure subscription.
 
 1. Select the storage account and blob container you created to store the images.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新图像搜索快速入门文档"
}
```

### Explanation
此次修改对《开始使用门户图像搜索》文档进行了小幅更新，主要是对部分说明进行了细化和链接的修正。在文档中，针对图像和文本的多模态嵌入的描述中，更新了对“Azure AI Foundry项目”的指向，使得信息更加清晰，同时提高了用户的理解度。此外，文中多处将“指定”更改为“选择”，以明确用户在操作时的意图和行为。这些改动不仅增强了文档的准确性，还有助于用户更顺利地完成图像搜索相关任务，同时确保在连接数据源和使用模型时的指导更加明确。这一系列调整旨在提升用户体验，确保他们在使用Azure AI服务时能获得更为清晰的指导和支持。

## articles/search/search-get-started-portal-import-vectors.md{#item-7dae77}

<details>
<summary>Diff</summary>
````diff
@@ -10,7 +10,7 @@ ms.custom:
   - build-2024
   - ignite-2024
 ms.topic: quickstart
-ms.date: 07/17/2025
+ms.date: 07/22/2025
 ---
 
 # Quickstart: Vectorize text in the Azure portal
@@ -185,16 +185,16 @@ This section points you to the content that works for this quickstart. Before yo
 
 ## Prepare embedding model
 
-The wizard can use embedding models deployed from Azure OpenAI, Azure AI Vision, or from the model catalog in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). Before you proceed, make sure you completed the prerequisites for [role-based access](#role-based-access).
+The wizard can use embedding models deployed from Azure OpenAI, Azure AI Vision, or the Azure AI Foundry model catalog. Before you proceed, make sure you completed the prerequisites for [role-based access](#role-based-access).
 
 ### [Azure OpenAI](#tab/model-aoai)
 
 The wizard supports text-embedding-ada-002, text-embedding-3-large, and text-embedding-3-small. Internally, the wizard calls the [AzureOpenAIEmbedding skill](cognitive-search-skill-azure-openai-embedding.md) to connect to Azure OpenAI.
 
-1. Sign in to the [Azure portal](https://portal.azure.com/) and select your Azure OpenAI resource.
-
 1. To assign roles:
 
+   1. Sign in to the [Azure portal](https://portal.azure.com/) and select your Azure OpenAI resource.
+
    1. From the left pane, select **Access control (IAM)**.
 
    1. Select **Add** > **Add role assignment**.
@@ -215,54 +215,37 @@ The wizard supports text-embedding-ada-002, text-embedding-3-large, and text-emb
 
 ### [Azure AI Vision](#tab/model-ai-vision)
 
-The wizard supports Azure AI Vision image retrieval through multimodal embeddings (version 4.0). Internally, the wizard calls the [multimodal embeddings skill](cognitive-search-skill-vision-vectorize.md) to connect to Azure AI Vision.
+The wizard supports text and image retrieval through the Azure AI Vision multimodal APIs, which are built into your Azure AI multi-service resource. Internally, the wizard calls the [Azure AI Vision multimodal embeddings skill](cognitive-search-skill-vision-vectorize.md) to make the connection.
 
-1. Sign in to the [Azure portal](https://portal.azure.com/) and select your Azure AI multi-service resource.
-
-1. To assign roles:
+Since no model deployment is required, you only need to assign roles to your search service identity.
 
-   1. From the left pane, select **Access control (IAM)**.
+To assign roles:
 
-   1. Select **Add** > **Add role assignment**.
+1. Sign in to the [Azure portal](https://portal.azure.com/) and select your multi-service resource.
 
-   1. Under **Job function roles**, select **Cognitive Services User**, and then select **Next**.
+1. From the left pane, select **Access control (IAM)**.
 
-   1. Under **Members**, select **Managed identity**, and then select **Select members**.
+1. Select **Add** > **Add role assignment**.
 
-   1. Select your subscription and the managed identity of your search service.
+1. Under **Job function roles**, select **Cognitive Services User**, and then select **Next**.
 
-The multimodal embeddings are built into your Azure AI multi-service resource, so there's no model deployment step. You should now be able to select the Azure AI Vision vectorizer in the **Import and vectorize data wizard**.
+1. Under **Members**, select **Managed identity**, and then select **Select members**.
 
-> [!NOTE]
-> If you can't select the Azure AI Vision vectorizer, make sure you have an Azure AI Vision resource in a supported region. Also make sure the managed identity of your search service has **Cognitive Services User** permissions.
+1. Select your subscription and the managed identity of your search service.
 
 ### [Azure AI Foundry model catalog](#tab/model-catalog)
 
 The wizard supports Azure, Cohere, and Facebook embedding models in the Azure AI Foundry model catalog, but it doesn't currently support the OpenAI CLIP models. Internally, the wizard calls the [AML skill](cognitive-search-aml-skill.md) to connect to the catalog.
 
-For the model catalog, you should have an [Azure AI Foundry project](/azure/ai-foundry/how-to/create-projects) with a [hub that's connected to an Azure OpenAI resource and an Azure AI Search service](/azure/ai-foundry/how-to/create-projects#create-a-project).
-
-1. Sign in to the [Azure portal](https://portal.azure.com/) and select your Azure OpenAI resource.
-
-1. To assign roles:
+To complete these steps, you must have a [hub-based project](/azure/ai-foundry/how-to/create-projects) in Azure AI Foundry. Currently, hub-based projects support API keys instead of managed identities for authentication, so there's no role assignment step. You only need to deploy a model from the catalog.
 
-   1. From the left pane, select **Access control (IAM)**.
+To deploy an embedding model:
 
-   1. Select **Add** > **Add role assignment**.
+1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and select your hub-based project.
 
-   1. Under **Job function roles**, select **Cognitive Services User**, and then select **Next**.
+1. From the left pane, select **Model catalog**.
 
-   1. Under **Members**, select **Managed identity**, and then select **Select members**.
-
-   1. Select your subscription and the managed identity of your search service.
-
-1. To deploy an embedding model:
-
-   1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and select your project.
-
-   1. From the left pane, select **Model catalog**.
-
-   1. Deploy a [supported embedding model](#supported-embedding-models).
+1. Deploy a [supported embedding model](#supported-embedding-models).
 
 ---
 
@@ -284,39 +267,33 @@ To start the wizard for vector search:
 
 ## Connect to your data
 
-The next step is to connect to a data source to use for the search index.
+In this step, you connect Azure AI Search to a [supported data source](#supported-data-sources) for content ingestion and indexing.
 
 ### [Azure Blob Storage](#tab/connect-data-storage)
 
-1. On the **Connect to your data** page, specify the Azure subscription.
+1. On the **Connect to your data** page, select your Azure subscription.
 
 1. Select the storage account and container that provide the sample data.
 
-1. If you enabled soft delete and optionally added custom metadata in [Prepare sample data](#prepare-sample-data), select the **Enable deletion tracking** checkbox.
+1. If you enabled soft delete and added custom metadata in [Prepare sample data](#prepare-sample-data), select the **Enable deletion tracking** checkbox.
 
    + On subsequent indexing runs, the search index is updated to remove any search documents based on soft-deleted blobs on Azure Storage.
 
    + Blobs support either **Native blob soft delete** or **Soft delete using custom metadata**.
 
    + If you configured your blobs for soft delete, provide the metadata property name-value pair. We recommend **IsDeleted**. If **IsDeleted** is set to **true** on a blob, the indexer drops the corresponding search document on the next indexer run.
 
-   The wizard doesn't check Azure Storage for valid settings or throw an error if the requirements aren't met. Instead, deletion detection doesn't work, and your search index is likely to collect orphaned documents over time.
-
-   :::image type="content" source="media/search-get-started-portal-import-vectors/data-source-blob.png" alt-text="Screenshot of the data source page with deletion detection options.":::
-
-1. Select the **Authenticate using managed identity** checkbox.
-
-   + For the type of managed identity, select **System-assigned**.
+   + The wizard doesn't check Azure Storage for valid settings or throw an error if the requirements aren't met. Instead, deletion detection doesn't work, and your search index is likely to collect orphaned documents over time.
 
-   + The identity should have a **Storage Blob Data Reader** role on Azure Storage.
+1. Select the **Authenticate using managed identity** checkbox. Leave the identity type as **System-assigned**.
 
-   + Don't skip this step. A connection error occurs during indexing if the wizard can't connect to Azure Storage.
+   :::image type="content" source="media/search-get-started-portal-import-vectors/data-source-blob.png" alt-text="Screenshot of the data source page with deletion detection options." lightbox="media/search-get-started-portal-import-vectors/data-source-blob.png":::
 
 1. Select **Next**.
 
 ### [ADLS Gen2](#tab/connect-data-adlsgen2)
 
-1. On the **connect to your data** page, specify the Azure subscription.
+1. On the **Connect to your data** page, select your Azure subscription.
 
 1. Select the storage account and container that provide the sample data.
 
@@ -328,23 +305,17 @@ The next step is to connect to a data source to use for the search index.
 
    + Provide the metadata property you created for deletion detection. We recommend **IsDeleted**. If **IsDeleted** is set to **true** on a blob, the indexer drops the corresponding search document on the next indexer run.
 
-   The wizard doesn't check Azure Storage for valid settings or throw an error if the requirements aren't met. Instead, deletion detection doesn't work, and your search index is likely to collect orphaned documents over time.
-
-   :::image type="content" source="media/search-get-started-portal-import-vectors/data-source-data-lake-storage.png" alt-text="Screenshot of the data source page with deletion detection options.":::
-
-1. Select the **Authenticate using managed identity** checkbox.
-
-   + For the type of managed identity, select **System-assigned**.
+      The wizard doesn't check Azure Storage for valid settings or throw an error if the requirements aren't met. Instead, deletion detection doesn't work, and your search index is likely to collect orphaned documents over time.
 
-   + The identity should have a **Storage Blob Data Reader** role on Azure Storage.
+1. Select the **Authenticate using managed identity** checkbox. Leave the identity type as **System-assigned**.
 
-   + Don't skip this step. A connection error occurs during indexing if the wizard can't connect to Azure Storage.
+   :::image type="content" source="media/search-get-started-portal-import-vectors/data-source-data-lake-storage.png" alt-text="Screenshot of the data source page with deletion detection options." lightbox="media/search-get-started-portal-import-vectors/data-source-data-lake-storage.png":::
 
 1. Select **Next**.
 
 ### [OneLake](#tab/connect-data-onelake)
 
-1. On the **connect to your data** page, select **Lakehouse URL** for the connection type.
+1. On the **Connect to your data** page, select **Lakehouse URL** for the connection type.
 
 1. Paste the URL you copied in [Prepare sample data](#prepare-sample-data).
 
@@ -354,15 +325,13 @@ The next step is to connect to a data source to use for the search index.
 
 ### [Logic Apps](#tab/connect-logic-apps)
 
-The current preview adds support for Logic Apps connectors. For a list of supported connectors and operations:
-
-+ [Use a Logic Apps connector for indexer-based indexing](search-how-to-index-logic-apps-indexers.md)
+The current preview adds support for Logic Apps connectors. For a list of supported connectors and operations, see [Use a Logic Apps connector for indexer-based indexing](search-how-to-index-logic-apps-indexers.md).
 
 ---
 
 ## Vectorize your text
 
-In this step, you specify an embedding model to vectorize chunked data. Chunking is built in and nonconfigurable. The effective settings are:
+During this step, the wizard uses your chosen [embedding model](#supported-embedding-models) to vectorize chunked data. Chunking is built in and nonconfigurable. The effective settings are:
 
 ```json
 "textSplitMode": "pages",
@@ -372,60 +341,98 @@ In this step, you specify an embedding model to vectorize chunked data. Chunking
 "unit": "characters"
 ```
 
-1. On the **Vectorize your text** page, select the source of your embedding model:
+### [Azure OpenAI](#tab/vectorize-text-aoai)
+
+1. On the **Vectorize your text** page, select **Azure OpenAI** for the kind.
 
-   + Azure OpenAI
+1. Select your Azure subscription.
 
-   + Azure AI Foundry model catalog
+1. Select your Azure OpenAI resource, and then select the model you deployed in [Prepare embedding model](#prepare-embedding-model).
+
+1. For the authentication type, select **System assigned identity**.
 
-   + Azure AI Vision (via an [Azure AI services multi-service resource](/azure/ai-services/multi-service-resource#azure-ai-multi-services-resource-for-azure-ai-search-skills) in the same region as Azure AI Search)
+1. Select the checkbox that acknowledges the billing effects of using these resources.
 
-1. Specify the Azure subscription.
+   :::image type="content" source="media/search-get-started-portal-import-vectors/vectorize-text-aoai.png" alt-text="Screenshot of the Vectorize your text page with Azure OpenAI in the wizard." lightbox="media/search-get-started-portal-import-vectors/vectorize-text-aoai.png":::
 
-1. Depending on your resource, make the following selection:
+1. Select **Next**.
 
-   + For Azure OpenAI, select the model you deployed in [Prepare embedding model](#prepare-embedding-model).
+### [Azure AI Vision](#tab/vectorize-text-ai-vision)
 
-   + For AI Foundry model catalog, select the model you deployed in [Prepare embedding model](#prepare-embedding-model).
+1. On the **Vectorize your text** page, select **AI Vision vectorization** for the kind.
 
-   + For AI Vision multimodal embeddings, select your multi-service resource.
+1. Select your Azure subscription and Azure AI multi-service resource.
 
 1. For the authentication type, select **System assigned identity**.
 
-   + The identity should have a **Cognitive Services User** role on the Azure AI services multi-service resource.
+1. Select the checkbox that acknowledges the billing effects of using these resources.
+
+   :::image type="content" source="media/search-get-started-portal-import-vectors/vectorize-text-ai-vision.png" alt-text="Screenshot of the Vectorize your text page with Azure AI Vision in the wizard." lightbox="media/search-get-started-portal-import-vectors/vectorize-text-ai-vision.png":::
+
+1. Select **Next**.
+
+### [Azure AI Foundry model catalog](#tab/vectorize-text-catalog)
+
+1. On the **Vectorize your text** page, select **AI Foundry Hub catalog models** for the kind.
+
+1. Select your Azure subscription.
+
+1. Select your hub-based project, and then select the model you deployed in [Prepare embedding model](#prepare-embedding-model).
+
+1. Leave the authentication type as **API key**.
 
 1. Select the checkbox that acknowledges the billing effects of using these resources.
 
-   :::image type="content" source="media/search-get-started-portal-import-vectors/vectorize-text.png" alt-text="Screenshot of the Vectorize your text page in the wizard.":::
+   :::image type="content" source="media/search-get-started-portal-import-vectors/vectorize-text-catalog.png" alt-text="Screenshot of the Vectorize your text page with the Azure AI Foundry model catalog in the wizard." lightbox="media/search-get-started-portal-import-vectors/vectorize-text-catalog.png":::
 
 1. Select **Next**.
 
+---
+
 ## Vectorize and enrich your images
 
 The health-plan PDFs include a corporate logo, but otherwise, there are no images. You can skip this step if you're using the sample documents.
 
-However, if you work with content that includes useful images, you can apply AI in two ways:
+However, if your content includes useful images, you can apply AI in one or both of the following ways:
 
-+ Use a supported image embedding model from the catalog or the Azure AI Vision multimodal embeddings API to vectorize images.
++ Use a supported image embedding model from the Azure AI Foundry model catalog or the Azure AI Vision multimodal embeddings API (via an Azure AI multi-service resource) to vectorize images.
 
-+ Use optical character recognition (OCR) to recognize text in images. This option invokes the [OCR skill](cognitive-search-skill-ocr.md) to read text from images.
++ Use optical character recognition (OCR) to extract text from images. This option invokes the [OCR skill](cognitive-search-skill-ocr.md).
 
-Azure AI Search and your Azure AI resource must be in the same region or configured for [keyless billing connections](cognitive-search-attach-cognitive-services.md).
+### [Vectorize images](#tab/vectorize-images)
 
-1. On the **Vectorize your images** page, specify the kind of connection the wizard should make. For image vectorization, the wizard can connect to embedding models in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) or Azure AI Vision.
+1. On the **Vectorize and enrich your images** page, select the **Vectorize images** checkbox.
 
-1. Specify the subscription.
+1. For the kind, select your model provider: **AI Foundry Hub catalog models** or **AI Vision vectorization**.
 
-1. For the Azure AI Foundry model catalog, specify the project and deployment. For more information, see [Prepare embedding models](#prepare-embedding-model).
+   If Azure AI Vision is unavailable, make sure your search service and multi-service resource are both in a [region that supports the Azure AI Vision multimodal APIs](/azure/ai-services/computer-vision/how-to/image-retrieval).
 
-1. (Optional) Crack binary images, such as scanned document files, and use [OCR](cognitive-search-skill-ocr.md) to recognize text.
+1. Select your Azure subscription, resource, and embedding model deployment (if applicable).
+
+1. If you're using Azure AI Vision, select **System assigned identity** for the authentication type. Otherwise, leave it as **API key**.
 
 1. Select the checkbox that acknowledges the billing effects of using these resources.
 
-   :::image type="content" source="media/search-get-started-portal-import-vectors/vectorize-images.png" alt-text="Screenshot of the Vectorize your images page in the wizard.":::
+   :::image type="content" source="media/search-get-started-portal-import-vectors/vectorize-images.png" alt-text="Screenshot of the Vectorize and enrich your images page in the wizard." lightbox="media/search-get-started-portal-import-vectors/vectorize-images.png":::
 
 1. Select **Next**.
 
+### [Extract text from images](#tab/extract-text-images)
+
+1. On the **Vectorize and enrich your images** page, select the **Extract text from images** checkbox.
+
+1. Select your Azure subscription and multi-service resource.
+
+1. For the authentication type, select **System assigned identity**.
+
+1. Select the checkbox that acknowledges the billing effects of using these resources.
+
+   :::image type="content" source="media/search-get-started-portal-import-vectors/extract-text-images.png" alt-text="Screenshot of the Extract text from images page in the wizard." lightbox="media/search-get-started-portal-import-vectors/extract-text-images.png":::
+
+1. Select **Next**.
+
+---
+
 ## Add semantic ranking
 
 On the **Advanced settings** page, you can optionally add [semantic ranking](semantic-search-overview.md) to rerank results at the end of query execution. Reranking promotes the most semantically relevant matches to the top.
@@ -492,11 +499,11 @@ Search Explorer accepts text strings as input and then vectorizes the text for v
 
 1. Select **Query options**, and then select **Hide vector values in search results**. This step makes the results more readable.
 
-   :::image type="content" source="media/search-get-started-portal-import-vectors/query-options.png" alt-text="Screenshot of the button for query options.":::
+   :::image type="content" source="media/search-get-started-portal-import-vectors/query-options.png" alt-text="Screenshot of the button for query options." lightbox="media/search-get-started-portal-import-vectors/query-options.png":::
 
 1. From the **View** menu, select **JSON view** so you can enter text for your vector query in the `text` vector query parameter.
 
-   :::image type="content" source="media/search-get-started-portal-import-vectors/select-json-view.png" alt-text="Screenshot of the menu command for opening the JSON view.":::
+   :::image type="content" source="media/search-get-started-portal-import-vectors/select-json-view.png" alt-text="Screenshot of the menu command for opening the JSON view." lightbox="media/search-get-started-portal-import-vectors/select-json-view.png":::
 
    The default query is an empty search (`"*"`) but includes parameters for returning the number matches. It's a hybrid query that runs text and vector queries in parallel. It also includes semantic ranking and specifies which fields to return in the results through the `select` statement.
 
@@ -544,7 +551,7 @@ Search Explorer accepts text strings as input and then vectorizes the text for v
 
 1. To run the query, select **Search**.
 
-   :::image type="content" source="media/search-get-started-portal-import-vectors/search-results.png" alt-text="Screenshot of search results.":::
+   :::image type="content" source="media/search-get-started-portal-import-vectors/search-results.png" alt-text="Screenshot of search results." lightbox="media/search-get-started-portal-import-vectors/search-results.png":::
 
    Each document is a chunk of the original PDF. The `title` field shows which PDF the chunk comes from. Each `chunk` is long. You can copy and paste one into a text editor to read the entire value.
 
@@ -566,9 +573,9 @@ Search Explorer accepts text strings as input and then vectorizes the text for v
    }
    ```
 
-## Clean up
+## Clean up resource
 
-Azure AI Search is a billable resource. If you no longer need it, delete it from your subscription to avoid charges.
+This quickstart uses billable Azure resources. If you no longer need the resources, delete them from your subscription to avoid charges.
 
 ## Next step
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新导入向量的快速入门文档"
}
```

### Explanation
此次修改对《在门户中导入向量的快速入门》文档进行了重要的更新，添加了新的示例和步骤，使内容更加丰富和清晰。主要的改动包括删减和精炼了部分文本，同时增加了更多关于如何准备和使用嵌入模型的信息。文档对模型的引用也变得更加精确，用户能够更清楚地理解每个步骤的目的和要求。在连接数据源的部分，说明了每种数据提供者的设置步骤，包括使用Azure OpenAI、Azure AI Vision以及Azure AI Foundry模型目录的详细说明，大大提升了操作的可操作性。此外，更新中还增强了对认证类型选择的明确性，确保用户在使用过程中能够顺利完成身份验证和模型部署。总的来说，这些修改旨在优化用户在使用Azure门户进行向量化处理时的体验。

## articles/search/search-region-support.md{#item-25b0f1}

<details>
<summary>Diff</summary>
````diff
@@ -45,8 +45,8 @@ You can create an Azure AI Search service in any of the following Azure public r
 | Canada Central​​ | ✅ | ✅ | ✅ | ✅ | ✅ |
 | Canada East​​ ​|  |  | ✅ | ✅ |  |
 | ​Central US​​ | ✅ | ✅ | ✅ | ✅ | ✅ |
-| East US​ | ✅ | ✅ | ✅ | ✅ |  |
-| East US 2 ​<sup>1</sup>  | ✅ | ✅ | ✅ | ✅ | ✅ |
+| East US​ <sup>1</sup> | ✅ | ✅ | ✅ | ✅ |  |
+| East US 2 | ✅ | ✅ | ✅ | ✅ | ✅ |
 | Mexico Central |  | ✅ |  |  |  |
 | North Central US​ ​| ✅ |  | ✅ | ✅ | ✅ |
 | South Central US​ | ✅ | ✅ | ✅ | ✅ | ✅ |
@@ -55,8 +55,7 @@ You can create an Azure AI Search service in any of the following Azure public r
 | West US 3​ | ✅ | ✅ | ✅ | ✅ | ✅ |
 | West Central US​ ​ | ✅ |  | ✅ | ✅ |  |
 
-<sup>1</sup> This region has capacity constraints on the following tiers: S2, S3, L1, and L2.
-
+<sup>1</sup> This region has capacity constraints in all tiers.
 ### Europe
 
 | Region | AI enrichment | Availability zones | Agentic retrieval | Semantic ranker | Query rewrite |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新区域支持文档"
}
```

### Explanation
此次修改对《区域支持》文档进行了小规模的更新，主要涉及对区域信息的调整和描述的清晰化。在表格中，东部美国（East US）区域的描述进行了简化，将其容量约束的信息由针对特定层级的说明改为涵盖所有层级，便于用户理解。此外，表格中东部美国（East US）区域及东部美国2（East US 2）区域的排列顺序进行调整，提高了信息的可读性和逻辑性。通过这些修改，文档更准确地反映了Azure各区域的服务支持情况，从而帮助用户在选择区域时做出更明智的决策。

## articles/search/search-what-is-azure-search.md{#item-93853a}

<details>
<summary>Diff</summary>
````diff
@@ -20,18 +20,18 @@ Azure AI Search is a scalable search infrastructure that indexes heterogeneous c
 
 The service handles both traditional search workloads and modern RAG (retrieval-augmented generation) patterns for conversational AI applications. This makes it suitable for enterprise search scenarios as well as AI-powered customer experiences that require dynamic content generation through chat completion models.
 
-<!-- Azure AI Search is a knowledge retrieval platform that consolidates and organizes information across different types of content. You add your content to a search index. Users, agents, and bots retrieve your content through queries and apps.
-Indexing and query workloads support native integration with AI models from Azure OpenAI, Azure AI Foundry, and Azure Machine Learning. By leveraging an extensibility layer, you can connect workloads to third-party and open-source AI models and tools.
-
-You can use Azure AI Search for regular search needs (like searching through catalogs or documents) or for AI-powered search that can have conversations with users and generate answers based on your content. -->
-
 <!-- Azure AI Search ([formerly known as "Azure Cognitive Search"](whats-new.md#new-service-name)) is an enterprise-ready information retrieval system for your heterogeneous content that you ingest into a search index, and surface to users through queries and apps. It comes with a comprehensive set of advanced search technologies, built for high-performance applications at any scale.
 
 Azure AI Search is the recommended retrieval system for building agent-to-agent (A2A) and RAG-based applications on Azure, with native LLM integrations between Azure OpenAI in Azure AI Foundry Models and Azure Machine Learning, with mechanisms for integrating third-party and open-source models and processes.
 
 Azure AI Search can be used for both traditional search as well as modern information retrieval. Common use cases include catalog or document search, information discovery (data exploration), and  retrieval-augmented generation (RAG) for conversational search.  
  -->
 
+<!-- Azure AI Search is a knowledge retrieval platform that consolidates and organizes information across different types of content. You add your content to a search index. Users, agents, and bots retrieve your content through queries and apps.
+Indexing and query workloads support native integration with AI models from Azure OpenAI, Azure AI Foundry, and Azure Machine Learning. By leveraging an extensibility layer, you can connect workloads to third-party and open-source AI models and tools.
+
+You can use Azure AI Search for regular search needs (like searching through catalogs or documents) or for AI-powered search that can have conversations with users and generate answers based on your content. -->
+
 When you create a search service, you work with the following capabilities:
 
 + A search engine for [agentic search](search-agentic-retrieval-concept.md), [vector search](vector-search-overview.md), [full text](search-lucene-query-architecture.md), [multimodal search](multimodal-search-overview.md), or [hybrid search](hybrid-search-overview.md).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新Azure搜索介绍文档"
}
```

### Explanation
此次修改对《什么是Azure搜索》文档进行了小幅更新，主要是对内容结构和表达进行了调整，以提升表达的清晰度和可读性。文中对Azure AI Search的描述进行了结构性改写，将其作为知识检索平台的功能和特性进行了更加明确的阐释。去除了部分冗余内容，并保留了核心信息，强调了其在传统搜索和现代信息检索中的应用。此外，新增或改晰的部分强调了Azure AI Search的集成功能，特别是与Azure OpenAI、Azure AI Foundry和Azure Machine Learning的原生集成，使用户可以利用扩展性层连接第三方和开源AI模型。通过这些修改，文档更有效地传达了Azure AI Search的多样性和灵活性，以便用户更好地理解其用途和应用场景。

## articles/search/semantic-how-to-query-request.md{#item-85530d}

<details>
<summary>Diff</summary>
````diff
@@ -357,4 +357,4 @@ If you anticipate consistent throughput requirements near, at, or higher than th
 Semantic ranking can be used in hybrid queries that combine keyword search and vector search into a single request and a unified response.
 
 > [!div class="nextstepaction"]
-> [Hybrid query with semantic ranker](hybrid-search-how-to-query.md#semantic-hybrid-search)
+> [Hybrid query with semantic ranker](hybrid-search-how-to-query.md#example-semantic-hybrid-search)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新语义查询请求文档"
}
```

### Explanation
此次修改对《语义如何发起查询请求》文档进行了小规模的更新，主要涉及文中链接的调整，以提高用户导航体验。具体而言，原有的链接指向“Hybrid query with semantic ranker”已被更新为指向“example-semantic-hybrid-search”，这一变化旨在提供更具体的示例，帮助用户更好地理解如何使用语义排序进行混合查询。此类细微而重要的修改旨在增强文档的实用性，使得用户在执行相关操作时能够更容易找到所需的信息和指引。

## articles/search/semantic-how-to-query-rewrite.md{#item-3e168f}

<details>
<summary>Diff</summary>
````diff
@@ -262,4 +262,4 @@ In the preceding example:
 Semantic ranking can be used in hybrid queries that combine keyword search and vector search into a single request and a unified response.
 
 > [!div class="nextstepaction"]
-> [Hybrid query with semantic ranker](hybrid-search-how-to-query.md#semantic-hybrid-search)
+> [Hybrid query with semantic ranker](hybrid-search-how-to-query.md#example-semantic-hybrid-search)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新语义查询重写文档"
}
```

### Explanation
此次修改对《如何进行语义查询重写》文档进行了小规模更新，主要修改了文中提供的链接。这一变化将指向“Hybrid query with semantic ranker”的链接更改为指向“example-semantic-hybrid-search”。此改动旨在提供更具体的示例，帮助用户理解如何在混合查询中运用语义排序技术。通过这样的更新，文档能够更有效地引导用户，使他们在使用相关功能时能够获得更直接和实用的指导，从而提升用户体验。

## articles/search/vector-search-how-to-query.md{#item-9bb93c}

<details>
<summary>Diff</summary>
````diff
@@ -177,6 +177,7 @@ api-key: {{admin-api-key}}
 
         }
     ]
+}
 ```
 
 ### [**Azure portal**](#tab/portal-vector-query)
@@ -526,17 +527,6 @@ POST https://[service-name].search.windows.net/indexes/[index-name]/docs/search?
     }
 ```
 
- <!-- Keep H2 as-is. Direct link from a blog post. Bulk of maxtextsizerecall has moved to hybrid query doc-->
-## MaxTextSizeRecall for hybrid search (preview)
-
-Vector queries are often used in hybrid constructs that include nonvector fields. If you discover that BM25-ranked results are over or under represented in a hybrid query results, you can [set `maxTextRecallSize`](hybrid-search-how-to-query.md#set-maxtextrecallsize-and-countandfacetmode) to increase or decrease the BM25-ranked results provided for hybrid ranking.
-
-You can only set this property in hybrid requests that include both `search` and `vectorQueries` components.
-
-This parameter is in preview. We recommend the  [2024-05-01-preview](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-05-01-preview&preserve-view=true) REST API version.
-
-For more information, see [Set maxTextRecallSize - Create a hybrid query](hybrid-search-how-to-query.md#set-maxtextrecallsize-and-countandfacetmode).
-
 ## Next steps
 
 As a next step, review vector query code examples in [Python](https://github.com/Azure/azure-search-vector-samples/tree/main/demo-python), [C#](https://github.com/Azure/azure-search-vector-samples/tree/main/demo-dotnet) or [JavaScript](https://github.com/Azure/azure-search-vector-samples/tree/main/demo-javascript).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新向量查询文档"
}
```

### Explanation
此次修改对《如何进行向量查询》文档进行了小规模更新，主要是对文档内容的精简和结构的调整。删除了一些关于“MaxTextSizeRecall”参数的细节，这些内容原本描述了在混合查询中如何对向量查询进行调整。此改动旨在清晰化文档，使其更专注于当前的功能和使用场景。新的结构突出了关键内容，并提供了指向代码示例的链接，帮助开发者更有效地理解向量查询的实际应用。此外，还增加了一行代码以改善格式，使文档的可读性进一步增强。

## articles/search/whats-new.md{#item-fa71b4}

<details>
<summary>Diff</summary>
````diff
@@ -78,7 +78,7 @@ Learn about the latest updates to Azure AI Search functionality, docs, and sampl
 | November | Feature | [Portal support for structured data](search-get-started-portal-import-vectors.md). The **Import and vectorize data** wizard now supports Azure SQL, Azure Cosmos DB, and Azure Table Storage. |
 | October | Feature | [Lower the dimension requirements for MRL-trained text embedding models on Azure OpenAI](vector-search-how-to-truncate-dimensions.md). Text-embedding-3-small and Text-embedding-3-large are trained using Matryoshka Representation Learning (MRL). This allows you to truncate the embedding vectors to fewer dimensions, and adjust the balance between vector index size usage and retrieval quality. A new `truncationDimension` in the [2024-09-01-preview](/rest/api/searchservice/indexes/create-or-update?view=rest-searchservice-2024-09-01-preview&preserve-view=true) enables access to MRL compression in text embedding models. This can only be configured for new vector fields. |
 | October | Feature | [Unpack `@search.score` to view subscores in hybrid search results](hybrid-search-ranking.md#unpack-a-search-score-into-subscores-preview). You can investigate Reciprocal Rank Fusion (RRF) ranked results by viewing the individual query subscores of the final merged and scored result. A new `debug` property unpacks the search score. `QueryResultDocumentSubscores`, `QueryResultDocumentRerankerInput`, and `QueryResultDocumentSemanticField` provide the extra detail. These definitions are available in the [2024-09-01-preview](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true). |
-| October | Feature | [Target filters in a hybrid search to just the vector queries](hybrid-search-how-to-query.md#hybrid-search-with-filters-targeting-vector-subqueries-preview). A filter on a hybrid query involves all subqueries on the request, regardless of type. You can override the global filter to scope the filter to a specific subquery. The new `filterOverride` parameter is available on hybrid queries using the [2024-09-01-preview](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true). |
+| October | Feature | [Target filters in a hybrid search to just the vector queries](hybrid-search-how-to-query.md#example-hybrid-search-with-filters-targeting-vector-subqueries-preview). A filter on a hybrid query involves all subqueries on the request, regardless of type. You can override the global filter to scope the filter to a specific subquery. The new `filterOverride` parameter is available on hybrid queries using the [2024-09-01-preview](/rest/api/searchservice/documents/search-post?view=rest-searchservice-2024-09-01-preview&preserve-view=true). |
 | October | Applied AI (skills) | [Text Split skill (token chunking)](cognitive-search-skill-textsplit.md). This skill has new parameters that improve data chunking for embedding models. A new `unit` parameter lets you specify token chunking. You can now chunk by token length, setting the length to a value that makes sense for your embedding model. You can also specify the tokenizer and any tokens that shouldn't be split during data chunking. The new `unit` parameter and query subscore definitions are found in the [2024-09-01-preview](/rest/api/searchservice/skillsets/create-or-update?view=rest-searchservice-2024-09-01-preview&preserve-view=true). |
 | October | API | [2024-09-01-preview](/rest/api/searchservice/search-service-api-versions?view=rest-searchservice-2024-09-01-preview&preserve-view=true). Preview release of REST APIs for truncated dimensions in text-embedding-3 models, targeted vector filtering for hybrid queries, RRF subscore details for debugging, and token chunking for Text Split skill.|
 | October | Feature | [Portal support for customer-managed key encryption (CMK)](search-security-manage-encryption-keys.md#step-4-encrypt-content). When you create new objects in the Azure portal, you can now specify CMK-encryption and select an Azure Key Vault to provide the key. |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新新增功能文档"
}
```

### Explanation
此次修改对《全新功能》的文档内容进行了小规模更新，主要修改了一个功能描述中的链接。这一变化是在十月份介绍的一个新特性，即“在混合搜索中仅将过滤器目标定向到向量查询”，将链接从以前的`#hybrid-search-with-filters-targeting-vector-subqueries-preview`更改为`#example-hybrid-search-with-filters-targeting-vector-subqueries-preview`。此改动目的在于提供更清晰的指向，使用户能够更方便地找到相关示例，进一步增强用户在混合搜索中设定过滤器的理解与应用。整个文档仍旧保持关于Azure AI搜索的新特性更新，确保开发者了解最新的功能进展。


