---
date: '2025-06-04'
permalink: https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:8d764d4...MicrosoftDocs:45b2d74
summary: 此次文档更新主要针对 Azure AI Foundry 门户相关链接进行细微调整，以提升用户体验。更新内容涵盖所有提及 Azure AI Foundry
  门户链接的文档，目的是增强用户访问资源的便捷性和文档的一致性。此次更新没有新增功能，仅对链接路径进行了优化，所有新链接增加了 `cid=learnDocs` 参数，以便于用户跟踪资源使用和支持信息。总体来看，文档内容基本保持不变，主要着重于提升可用性和用户体验，让用户在使用
  Azure AI Foundry 工具和服务时更高效。
title: '[zh_CN] Diff Insight Report - openai'

---

[View Diff on GitHub](https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:8d764d4...MicrosoftDocs:45b2d74){target="_blank"}

<format>
# Highlights
本文档的更新涵盖了多个部分，主要涉及对 Azure AI Foundry 门户相关链接的细微调整和添加，以提高用户体验。这些更改几乎遍及所有提及 Azure AI Foundry 门户链接的文档，目的是增强用户访问资源的便捷性和文档的一致性。

## New features
- 无新增功能，此次更新主要集中在链接的调整和优化。

## Breaking changes
- 无影响功能的重大变化，仅对文档中的链接路径进行了更新。

## Other updates
- 所有新的链接都添加了 `cid=learnDocs` 参数，以便于用户更好地追踪资源使用和获取相关支持信息。
- 文档内容基本保持不变，未对技术说明或功能描述进行大幅度修改。
- 针对个别文档，对术语进行了标准化，以确保一致性。

# Insights
此次所有文档的更新并未改变主体内容或功能，主要着重于提高文档的可用性和用户体验。通过在 Azure AI Foundry 门户链接中增加 `cid=learnDocs` 参数，用户访问相关学习资源时能获得更一致且便捷的体验。这种参数的加入能够在用户的学习和参考过程中提供更多的支持和追踪功能。

这种类型的更新，虽然是微小的链接调整，但具有重要的用户体验提升，它能帮助用户更快、更有效地找到所需的文档和支持信息，这对用户在使用 Azure AI Foundry 提供的工具和服务时非常有帮助。这种优化显然是为了确保用户在学习过程中能有更好的指导和帮助，从而使他们更有效率地使用 Azure OpenAI 的各种功能和服务。

整体来看，此次更新在保持文档信息完整性的情况下，做出了良好的用户体验改善，为用户在探索和使用 Azure AI 服务时提供了更清晰的指引和支持。这样的优化不仅提升了文档的可读性和导航性，也在一定程度上增强了用户的满意度。
</format>

# Summary Table
|  Filename  | Type |    Title    | Status | A  | D  | M  |
|------------|------|-------------|--------|----|----|----|
| [assistants.md](#item-eab970) | minor update | 更新 Assistants API 相关链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [content-streaming.md](#item-f10e15) | minor update | 更新 Asynchronous Filter 超链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [gpt-4-v-prompt-engineering.md](#item-fd7772) | minor update | 更新 Azure AI Foundry playground 超链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [gpt-with-vision.md](#item-991388) | minor update | 更新 Azure AI Foundry portal 超链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [provisioned-migration.md](#item-68e143) | minor update | 更新 Azure AI Foundry portal 超链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [safety-system-message-templates.md](#item-460532) | minor update | 更新 Azure AI Foundry portal 超链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [use-your-data.md](#item-455d6e) | minor update | 更新 Azure AI Foundry portal 超链接. Locale: zh_CN | modified | 15 | 15 | 30 | 
| [faq.yml](#item-6deb71) | minor update | 更新 Azure AI Foundry portal 超链接. Locale: zh_CN | modified | 10 | 10 | 20 | 
| [batch.md](#item-a131d5) | minor update | 更新 Azure AI Foundry portal 超链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [completions.md](#item-79f39a) | minor update | 更新 Azure AI Foundry 超链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [dall-e.md](#item-ac9616) | minor update | 更新图像编辑 API 的描述. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [evaluations.md](#item-dfaa1c) | minor update | 更新 Azure AI Foundry 门户超链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [fine-tune-test.md](#item-48f1b6) | minor update | 更新 Azure AI Foundry 门户超链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [fine-tuning-deploy.md](#item-286d57) | minor update | 更新 Azure AI Foundry 门户超链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [model-router.md](#item-eebd7e) | minor update | 更新 Azure AI Foundry 门户超链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [monitor-openai.md](#item-fcba4d) | minor update | 更新 Azure AI Foundry 门户超链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [on-your-data-configuration.md](#item-4875d3) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 8 | 8 | 16 | 
| [provisioned-get-started.md](#item-c8df1c) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 4 | 4 | 8 | 
| [provisioned-throughput-onboarding.md](#item-3eb72b) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [quota.md](#item-9440c2) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [reinforcement-fine-tuning.md](#item-e8028c) | minor update | 更新参数名称以提高一致性. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [risks-safety-monitor.md](#item-b2be0b) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [role-based-access-control.md](#item-4b9817) | minor update | 更新 Azure AI Foundry 门户链接以优化访问. Locale: zh_CN | modified | 11 | 11 | 22 | 
| [stored-completions.md](#item-ccc7e6) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [use-blocklists.md](#item-e99db7) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [use-web-app.md](#item-802413) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 9 | 9 | 18 | 
| [weights-and-biases-integration.md](#item-8ae868) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [work-with-code.md](#item-b193c2) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [working-with-models.md](#item-7ec098) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [audio-completions-ai-foundry.md](#item-748538) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [audio-completions-deploy-model.md](#item-c5a63e) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [batch-studio.md](#item-d4822e) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [chatgpt-studio.md](#item-ab43f3) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [connect-your-data-studio.md](#item-c34da8) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [create-resource-portal.md](#item-cb2503) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [dall-e-studio.md](#item-439729) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [fine-tuning-openai-in-ai-studio.md](#item-723c8d) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [fine-tuning-studio.md](#item-439f1e) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [fine-tuning-unified.md](#item-718336) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [gpt-v-studio.md](#item-dcd50e) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [realtime-deploy-model.md](#item-21f911) | minor update | 更新 Azure AI Foundry 门户的链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [realtime-portal.md](#item-1b81a2) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [studio.md](#item-eeeaff) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [overview.md](#item-97d507) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [quotas-limits.md](#item-06c6f9) | minor update | 更新 Azure AI Foundry 门口链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [fine-tune.md](#item-8f87b5) | minor update | 更新 Azure AI Foundry 门户链接. Locale: zh_CN | modified | 5 | 5 | 10 | 
| [whats-new.md](#item-53303b) | minor update | 更新 Azure AI Foundry 门户链接，增加学习资源访问. Locale: zh_CN | modified | 4 | 4 | 8 | 


# Modified Contents
## articles/ai-services/openai/concepts/assistants.md{#item-eab970}

<details>
<summary>Diff</summary>
````diff
@@ -35,7 +35,7 @@ Assistants API supports persistent automatically managed threads. This means tha
 > [!TIP]
 > There is no additional [pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) or [quota](../quotas-limits.md) for using Assistants unless you use the [code interpreter](../how-to/code-interpreter.md) or [file search](../how-to/file-search.md) tools.
 
-Assistants API is built on the same capabilities that power OpenAI’s GPT product. Some possible use cases range from AI-powered product recommender, sales analyst app, coding assistant, employee Q&A chatbot, and more. Start building on the no-code Assistants playground on the [Azure AI Foundry portal](https://ai.azure.com/) or start building with the API.
+Assistants API is built on the same capabilities that power OpenAI’s GPT product. Some possible use cases range from AI-powered product recommender, sales analyst app, coding assistant, employee Q&A chatbot, and more. Start building on the no-code Assistants playground on the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) or start building with the API.
 
 > [!IMPORTANT]
 > Retrieving untrusted data using Function calling, Code Interpreter or File Search with file input, and Assistant Threads functionalities could compromise the security of your Assistant, or the application that uses the Assistant. Learn about mitigation approaches [here](https://aka.ms/oai/assistant-rai).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Assistants API 相关链接. Locale: zh_CN"
}
```

### Explanation
此次修改涉及对 Assistants API 文档中一段文字的细微更新，主要是调整了一个超链接的 URL。原链接被替换为一个新的链接，该链接指向 Azure AI Foundry 门户的相关页面，增加了 `cid=learnDocs` 参数，以便于用户追踪和管理流量。除此之外，其他内容保持不变。此更改有助于提升文档的准确性和用户体验。

## articles/ai-services/openai/concepts/content-streaming.md{#item-f10e15}

<details>
<summary>Diff</summary>
````diff
@@ -30,15 +30,15 @@ Customers must understand that while the feature improves latency, it's a trade-
 
 **Customer Copyright Commitment**: Content that is retroactively flagged as protected material might not be eligible for Customer Copyright Commitment coverage. 
 
-To enable Asynchronous Filter in [Azure AI Foundry portal](https://ai.azure.com/), follow the [Content filter how-to guide](/azure/ai-services/openai/how-to/content-filters) to create a new content filtering configuration, and select **Asynchronous Filter** in the Streaming section.
+To enable Asynchronous Filter in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), follow the [Content filter how-to guide](/azure/ai-services/openai/how-to/content-filters) to create a new content filtering configuration, and select **Asynchronous Filter** in the Streaming section.
 
 ## Comparison of content filtering modes
 
 | Compare | Streaming - Default | Streaming - Asynchronous Filter |
 |---|---|---|
 |Status |GA |Public Preview |
 | Eligibility |All customers |Customers approved for modified content filtering |
-| How to enable | Enabled by default, no action needed |Customers approved for modified content filtering can configure it directly in [Azure AI Foundry portal](https://ai.azure.com/) (as part of a content filtering configuration, applied at the deployment level) |
+| How to enable | Enabled by default, no action needed |Customers approved for modified content filtering can configure it directly in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) (as part of a content filtering configuration, applied at the deployment level) |
 |Modality and availability |Text; all GPT models |Text; all GPT models |
 |Streaming experience |Content is buffered and returned in chunks |Zero latency (no buffering, filters run asynchronously) |
 |Content filtering signal |Immediate filtering signal |Delayed filtering signal (in up to ~1,000-character increments) |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Asynchronous Filter 超链接. Locale: zh_CN"
}
```

### Explanation
此次修改更新了内容流文档中与异步过滤器相关的链接。在描述如何在 Azure AI Foundry 门户中启用异步过滤器时，原有的链接被替换为添加了 `cid=learnDocs` 参数的新链接。这一变化旨在提高文档的精确性和用户体验，确保用户能够更好地访问相关资源。除此之外，文档中其他内容的格式也做了一些调整，保持信息的清晰呈现。

## articles/ai-services/openai/concepts/gpt-4-v-prompt-engineering.md{#item-fd7772}

<details>
<summary>Diff</summary>
````diff
@@ -27,7 +27,7 @@ To unlock the full potential of vision-enabled chat models, it's essential to ta
 - **Define output format:** Clearly mention the desired format for the output, such as markdown, JSON, HTML, etc. You can also suggest a specific structure, length, or specific attributes about the response.
 
 ## Example prompt inputs and outputs
-There are many ways to craft system prompts to tailor the output specifically to your needs. The following sample inputs and outputs showcase how adjusting your prompts can give you different results. Try out the model for yourself using these images and adjusting the system prompt in the [Azure AI Foundry playground](https://ai.azure.com/).
+There are many ways to craft system prompts to tailor the output specifically to your needs. The following sample inputs and outputs showcase how adjusting your prompts can give you different results. Try out the model for yourself using these images and adjusting the system prompt in the [Azure AI Foundry playground](https://ai.azure.com/?cid=learnDocs).
 
 ### Contextual specificity  
 Context can help improve feedback from the model. For example, if you're working on image descriptions for a product catalog, ensure your prompt reflects that in a clear and concise way. A prompt like “Describe images for an outdoor hiking product catalog, focusing on enthusiasm and professionalism” guides the model to generate responses that are both accurate and contextually rich.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry playground 超链接. Locale: zh_CN"
}
```

### Explanation
此次修改对与 Azure AI Foundry 游乐场的链接进行了细微的更新。原有链接被替换为一个新的链接，增加了 `cid=learnDocs` 参数。这项修改旨在提高用户体验，使用户在访问相关资源时更容易追踪和管理流量。此外，文档中其他部分的内容保持不变，确保信息的一致性和完整性。

## articles/ai-services/openai/concepts/gpt-with-vision.md{#item-991388}

<details>
<summary>Diff</summary>
````diff
@@ -29,7 +29,7 @@ This section describes the limitations of vision-enabled chat models.
 
 - **Maximum input image size**: The maximum size for input images is restricted to 20 MB.
 - **Low resolution accuracy**: When images are analyzed using the "low resolution" setting, it allows for faster responses and uses fewer input tokens for certain use cases. However, this could impact the accuracy of object and text recognition within the image.
-- **Image chat restriction**: When you upload images in [Azure AI Foundry portal](https://ai.azure.com/) or the API, there is a limit of 10 images per chat call.
+- **Image chat restriction**: When you upload images in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) or the API, there is a limit of 10 images per chat call.
 
 ## Special pricing information
 
@@ -84,8 +84,8 @@ Additionally, there's a one-time indexing cost of $0.15 to generate the Video Re
 ### Video support
 
 - **Low resolution**: Video frames are analyzed using GPT-4 Turbo with Vision's "low resolution" setting, which may affect the accuracy of small object and text recognition in the video.
-- **Video file limits**: Both MP4 and MOV file types are supported. In [Azure AI Foundry portal](https://ai.azure.com/), videos must be less than 3 minutes long. When you use the API there is no such limitation.
-- **Prompt limits**: Video prompts only contain one video and no images. In [Azure AI Foundry portal](https://ai.azure.com/), you can clear the session to try another video or images.
+- **Video file limits**: Both MP4 and MOV file types are supported. In [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), videos must be less than 3 minutes long. When you use the API there is no such limitation.
+- **Prompt limits**: Video prompts only contain one video and no images. In [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you can clear the session to try another video or images.
 - **Limited frame selection**: The service selects 20 frames from the entire video, which might not capture all the critical moments or details. Frame selection can be approximately evenly spread through the video or focused by a specific video retrieval query, depending on the prompt.
 - **Language support**: The service primarily supports English for grounding with transcripts. Transcripts don't provide accurate information on lyrics in songs.
 -->
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry portal 超链接. Locale: zh_CN"
}
```

### Explanation
此次修改对与 Azure AI Foundry 门户的链接进行了小幅更新，添加了 `cid=learnDocs` 参数，以优化用户的访问体验。在描述图像聊天限制和视频文件限制时，相关链接的更新使得用户能够更容易地获取特定的文档和指导。此外，文档中关于限制和功能的其他描述保持不变，以确保信息的连贯性。

## articles/ai-services/openai/concepts/provisioned-migration.md{#item-68e143}

<details>
<summary>Diff</summary>
````diff
@@ -260,7 +260,7 @@ Azure Reservations for Azure OpenAI provisioned offers are specific to the provi
 
 ## Managing Provisioned Throughput Commitments
 
-Provisioned throughput commitments are created and managed by selecting **Management center** in the [Azure AI Foundry portal](https://ai.azure.com/)'s navigation menu > **Quota** > **Manage Commitments**. 
+Provisioned throughput commitments are created and managed by selecting **Management center** in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)'s navigation menu > **Quota** > **Manage Commitments**. 
 
 :::image type="content" source="../media/how-to/provisioned-onboarding/notifications.png" alt-text="Screenshot of commitment purchase UI with notifications." lightbox="../media/how-to/provisioned-onboarding/notifications.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry portal 超链接. Locale: zh_CN"
}
```

### Explanation
此次修改更新了与 Azure AI Foundry 门户相关的链接，新增了 `cid=learnDocs` 参数，以改善用户体验和链接的跟踪。在描述如何管理预配的吞吐量承诺时，保证了指向相关门户的链接更具准确性和易用性。此处的其他内容保持不变，确保信息的一致性与完整性。

## articles/ai-services/openai/concepts/safety-system-message-templates.md{#item-460532}

<details>
<summary>Diff</summary>
````diff
@@ -31,7 +31,7 @@ Below are examples of recommended system message components you can include to p
 
 ## Add safety system messages in Azure AI Foundry portal 
 
-The following steps show how to leverage safety system messages in [Azure AI Foundry portal](https://ai.azure.com/).
+The following steps show how to leverage safety system messages in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 
 1. Go to Azure AI Foundry and navigate to Azure OpenAI and the Chat playground.
     :::image type="content" source="../media/navigate-chat-playground.PNG" alt-text="Screenshot of the Azure AI Foundry portal selection.":::
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry portal 超链接. Locale: zh_CN"
}
```

### Explanation
本次修改对 Azure AI Foundry 门户的超链接进行了小幅调整，增加了 `cid=learnDocs` 参数。这一变更旨在优化用户访问相关资源的体验。在说明如何在 Azure AI Foundry 门户中使用安全系统消息的步骤时，该链接的更新提高了文档的准确性和可用性，确保了用户能够更方便地找到所需的信息。其他内容保持不变，确保了信息的连贯性。

## articles/ai-services/openai/concepts/use-your-data.md{#item-455d6e}

<details>
<summary>Diff</summary>
````diff
@@ -18,14 +18,14 @@ Use this article to learn about Azure OpenAI On Your Data, which makes it easier
 
 ## What is Azure OpenAI On Your Data
 
-Azure OpenAI On Your Data enables you to run advanced AI models such as GPT-35-Turbo and GPT-4 on your own enterprise data without needing to train or fine-tune models. You can chat on top of and analyze your data with greater accuracy. You can specify sources to support the responses based on the latest information available in your designated data sources. You can access Azure OpenAI On Your Data using a REST API, via the SDK or the web-based interface in the [Azure AI Foundry portal](https://ai.azure.com/). You can also create a web app that connects to your data to enable an enhanced chat solution or deploy it directly as a copilot in the Copilot Studio (preview).
+Azure OpenAI On Your Data enables you to run advanced AI models such as GPT-35-Turbo and GPT-4 on your own enterprise data without needing to train or fine-tune models. You can chat on top of and analyze your data with greater accuracy. You can specify sources to support the responses based on the latest information available in your designated data sources. You can access Azure OpenAI On Your Data using a REST API, via the SDK or the web-based interface in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). You can also create a web app that connects to your data to enable an enhanced chat solution or deploy it directly as a copilot in the Copilot Studio (preview).
 
 ## Developing with Azure OpenAI On Your Data
 
 :::image type="content" source="../media/use-your-data/workflow-diagram.png" alt-text="A diagram showing an example workflow.":::
 
 Typically, the development process you'd use with Azure OpenAI On Your Data is:
-1. **Ingest**: Upload files using either [Azure AI Foundry portal](https://ai.azure.com/) or the ingestion API. This enables your data to be cracked, chunked and embedded into an Azure AI Search instance that can be used by Azure OpenAI models. If you have an existing [supported data source](#supported-data-sources), you can also connect it directly.
+1. **Ingest**: Upload files using either [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) or the ingestion API. This enables your data to be cracked, chunked and embedded into an Azure AI Search instance that can be used by Azure OpenAI models. If you have an existing [supported data source](#supported-data-sources), you can also connect it directly.
 
 1. **Develop**: After trying Azure OpenAI On Your Data, begin developing your application using the available REST API and SDKs, which are available in several languages. It will create prompts and search intents to pass to the Azure OpenAI service.
 
@@ -38,7 +38,7 @@ Typically, the development process you'd use with Azure OpenAI On Your Data is:
     
     1. **Response generation**: The resulting data is submitted along with other information like the system message to the Large Language Model (LLM) and the response is sent back to the application.
 
-To get started, [connect your data source](../use-your-data-quickstart.md) using [Azure AI Foundry portal](https://ai.azure.com/) and start asking questions and chatting on your data.
+To get started, [connect your data source](../use-your-data-quickstart.md) using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and start asking questions and chatting on your data.
 
 ## Azure Role-based access controls (Azure RBAC) for adding data sources
 
@@ -139,7 +139,7 @@ Azure OpenAI On Your Data lets you restrict the documents that can be used in re
 
 ### Index field mapping 
 
-If you're using your own index, you'll be prompted in the [Azure AI Foundry portal](https://ai.azure.com/) to define which fields you want to map for answering questions when you add your data source. You can provide multiple fields for *Content data*, and should include all fields that have text pertaining to your use case. 
+If you're using your own index, you'll be prompted in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) to define which fields you want to map for answering questions when you add your data source. You can provide multiple fields for *Content data*, and should include all fields that have text pertaining to your use case. 
 
 :::image type="content" source="../media/use-your-data/index-data-mapping.png" alt-text="A screenshot showing the index field mapping options in Azure AI Foundry portal." lightbox="../media/use-your-data/index-data-mapping.png":::
 
@@ -192,7 +192,7 @@ You might want to use Azure Blob Storage as a data source if you want to connect
 
 To keep your Azure AI Search index up-to-date with your latest data, you can schedule an automatic index refresh rather than manually updating it every time your data is updated. Automatic index refresh is only available when you choose **Azure Blob Storage** as the data source. To enable an automatic index refresh:
 
-1. [Add a data source](../quickstart.md) using [Azure AI Foundry portal](https://ai.azure.com/).
+1. [Add a data source](../quickstart.md) using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 1. Under **Select or add data source** select **Indexer schedule** and choose the refresh cadence you would like to apply.
 
     :::image type="content" source="../media/use-your-data/indexer-schedule.png" alt-text="A screenshot of the indexer schedule in Azure AI Foundry portal." lightbox="../media/use-your-data/indexer-schedule.png":::
@@ -224,7 +224,7 @@ To modify the schedule, you can use the [Azure portal](https://portal.azure.com/
 
 # [Upload files (preview)](#tab/file-upload)
 
-Using [Azure AI Foundry portal](https://ai.azure.com/), you can upload files from your machine to try Azure OpenAI On Your Data. You also have the option to create a new Azure Blob Storage account and Azure AI Search resource. The service then stores the files to an Azure storage container and performs ingestion from the container. You can use the [quickstart](../use-your-data-quickstart.md) article to learn how to use this data source option.
+Using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you can upload files from your machine to try Azure OpenAI On Your Data. You also have the option to create a new Azure Blob Storage account and Azure AI Search resource. The service then stores the files to an Azure storage container and performs ingestion from the container. You can use the [quickstart](../use-your-data-quickstart.md) article to learn how to use this data source option.
 
 :::image type="content" source="../media/quickstarts/add-your-data-source.png" alt-text="A screenshot showing options for selecting a data source in Azure AI Foundry portal." lightbox="../media/quickstarts/add-your-data-source.png":::
 
@@ -308,11 +308,11 @@ Mapping these fields correctly helps ensure the model has better response and ci
 
 ### Use Elasticsearch as a data source via API  
 
-Along with using Elasticsearch databases in [Azure AI Foundry portal](https://ai.azure.com/), you can also use your Elasticsearch database using the [API](../references/elasticsearch.md). 
+Along with using Elasticsearch databases in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you can also use your Elasticsearch database using the [API](../references/elasticsearch.md). 
 
 # [MongoDB Atlas (preview)](#tab/mongo-db-atlas)
 
-You can connect your MongoDB Atlas vector index with Azure OpenAI On Your Data for inferencing. You can use it through the [Azure AI Foundry portal](https://ai.azure.com/), API and SDK.
+You can connect your MongoDB Atlas vector index with Azure OpenAI On Your Data for inferencing. You can use it through the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), API and SDK.
 
 ### Prerequisites 
 
@@ -363,15 +363,15 @@ When you add your MongoDB Atlas data source, you can specify data fields to prop
 
 ## Deploy to a copilot (preview), Teams app (preview), or web app 
 
-After you connect Azure OpenAI to your data, you can deploy it using the **Deploy to** button in [Azure AI Foundry portal](https://ai.azure.com/).
+After you connect Azure OpenAI to your data, you can deploy it using the **Deploy to** button in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 
 :::image type="content" source="../media/use-your-data/deploy-model.png" alt-text="A screenshot showing the model deployment button in Azure AI Foundry portal." lightbox="../media/use-your-data/deploy-model.png":::
 
 This gives you multiple options for deploying your solution.
 
 #### [Copilot (preview)](#tab/copilot)
 
-You can deploy to a copilot in [Copilot Studio](/microsoft-copilot-studio/fundamentals-what-is-copilot-studio) (preview) directly from [Azure AI Foundry portal](https://ai.azure.com/), enabling you to bring conversational experiences to various channels such as: Microsoft Teams, websites, Dynamics 365, and other [Azure Bot Service channels](/microsoft-copilot-studio/publication-connect-bot-to-azure-bot-service-channels). The tenant used in the Azure OpenAI and Copilot Studio (preview) should be the same. For more information, see [Use a connection to Azure OpenAI On Your Data](/microsoft-copilot-studio/nlu-generative-answers-azure-openai).
+You can deploy to a copilot in [Copilot Studio](/microsoft-copilot-studio/fundamentals-what-is-copilot-studio) (preview) directly from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), enabling you to bring conversational experiences to various channels such as: Microsoft Teams, websites, Dynamics 365, and other [Azure Bot Service channels](/microsoft-copilot-studio/publication-connect-bot-to-azure-bot-service-channels). The tenant used in the Azure OpenAI and Copilot Studio (preview) should be the same. For more information, see [Use a connection to Azure OpenAI On Your Data](/microsoft-copilot-studio/nlu-generative-answers-azure-openai).
 
 > [!NOTE]
 > Deploying to a copilot in Copilot Studio (preview) is only available in US regions.
@@ -393,15 +393,15 @@ A Teams app lets you bring conversational experience to your users in Teams to i
 - Your Azure account has been assigned **Cognitive Services OpenAI user** or **Cognitive Services OpenAI Contributor** role of the Azure OpenAI resource you're using, allowing your account to make Azure OpenAI API calls. For more information, see [Azure OpenAI On Your data configuration](../how-to/on-your-data-configuration.md#using-the-api) and [Add role assignment to an Azure OpenAI resource](/azure/ai-services/openai/how-to/role-based-access-control#add-role-assignment-to-an-azure-openai-resource) for instructions on setting this role in the Azure portal. 
 
 
-You can deploy to a standalone Teams app directly from [Azure AI Foundry portal](https://ai.azure.com/). Follow the steps below: 
+You can deploy to a standalone Teams app directly from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). Follow the steps below: 
 
 1. After you've added your data to the chat model, select **Deploy** and then **a new Teams app (preview)**. 
 
 1. Enter the name of your Teams app and download the resulting .zip file.
 
 1. Extract the .zip file and open the folder in Visual Studio Code.
 
-1. If you chose **API key** in the data connection step, manually copy and paste your Azure AI Search key into the `src\prompts\chat\config.json` file. Your Azure AI Search Key can be found in [Azure AI Foundry portal](https://ai.azure.com/) Playground by selecting the **View code** button with the key located under Azure Search Resource Key. If you chose **System assigned managed identity**, you can skip this step. Learn more about different data connection options in the [Data connection](/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search#data-connection) section.
+1. If you chose **API key** in the data connection step, manually copy and paste your Azure AI Search key into the `src\prompts\chat\config.json` file. Your Azure AI Search Key can be found in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) Playground by selecting the **View code** button with the key located under Azure Search Resource Key. If you chose **System assigned managed identity**, you can skip this step. Learn more about different data connection options in the [Data connection](/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search#data-connection) section.
 
 1. Open the Visual Studio Code terminal and log into Azure CLI, selecting the account that you assigned **Cognitive Service OpenAI User** role to. Use the `az login` command in the terminal to log in.
 
@@ -467,7 +467,7 @@ A small chunk size like 256 produces more granular chunks. This size also means
 
 ### Runtime parameters
 
-You can modify the following additional settings in the **Data parameters** section in [Azure AI Foundry portal](https://ai.azure.com/) and [the API](../references/on-your-data.md). You don't need to reingest your data when you update these parameters. 
+You can modify the following additional settings in the **Data parameters** section in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and [the API](../references/on-your-data.md). You don't need to reingest your data when you update these parameters. 
 
 
 |Parameter name  | Description  |
@@ -484,7 +484,7 @@ It's possible for the model to return `"TYPE":"UNCITED_REFERENCE"` instead of `"
 
 You can define a system message to steer the model's reply when using Azure OpenAI On Your Data. This message allows you to customize your replies on top of the retrieval augmented generation (RAG) pattern that Azure OpenAI On Your Data uses. The system message is used in addition to an internal base prompt to provide the experience. To support this, we truncate the system message after a specific [number of tokens](#token-usage-estimation-for-azure-openai-on-your-data) to ensure the model can answer questions using your data. If you are defining extra behavior on top of the default experience, ensure that your system prompt is detailed and explains the exact expected customization. 
 
-Once you select add your dataset, you can use the **System message** section in the [Azure AI Foundry portal](https://ai.azure.com/), or the `role_information` [parameter in the API](../references/on-your-data.md).
+Once you select add your dataset, you can use the **System message** section in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), or the `role_information` [parameter in the API](../references/on-your-data.md).
 
 :::image type="content" source="../media/use-your-data/system-message.png" alt-text="A screenshot showing the system message option in Azure AI Foundry portal." lightbox="../media/use-your-data/system-message.png":::
 
@@ -679,7 +679,7 @@ token_output = TokenEstimator.estimate_tokens(input_text)
 
 ## Troubleshooting 
 
-To troubleshoot failed operations, always look out for errors or warnings specified either in the API response or [Azure AI Foundry portal](https://ai.azure.com/). Here are some of the common errors and warnings: 
+To troubleshoot failed operations, always look out for errors or warnings specified either in the API response or [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). Here are some of the common errors and warnings: 
 
 ### Failed ingestion jobs
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry portal 超链接. Locale: zh_CN"
}
```

### Explanation
本次修改涉及对文档中提到的 Azure AI Foundry 门户的超链接进行了调整，添加了 `cid=learnDocs` 参数。这一更新旨在改进用户访问体验，确保用户能够更准确地访问相关资源。在介绍 Azure OpenAI On Your Data 的功能以及使用说明时，所有提到的 Azure AI Foundry 门户链接均进行了这一修改，以保持链接的统一性和有效性。虽然进行了显著的文本更改，但内容的整体结构和信息完整性均得以保证。

## articles/ai-services/openai/faq.yml{#item-6deb71}

<details>
<summary>Diff</summary>
````diff
@@ -125,19 +125,19 @@ sections:
         answer: |
           A Limited Access registration form is not required to access most Azure OpenAI models. Learn more on the [Azure OpenAI Limited Access page](/legal/cognitive-services/openai/limited-access?context=/azure/ai-services/openai/context/context).
       - question: |
-          My guest account has been given access to an Azure OpenAI resource, but I'm unable to access that resource in the [Azure AI Foundry portal](https://ai.azure.com/). How do I enable access?
+          My guest account has been given access to an Azure OpenAI resource, but I'm unable to access that resource in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). How do I enable access?
         answer: | 
-          This is expected behavior when using the default sign-in experience for the [Azure AI Foundry](https://ai.azure.com).
+          This is expected behavior when using the default sign-in experience for the [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs).
           
           To access Azure AI Foundry from a guest account that has been granted access to an Azure OpenAI resource:
           
-          1. Open a private browser session and then navigate to [https://ai.azure.com](https://ai.azure.com).
+          1. Open a private browser session and then navigate to [https://ai.azure.com](https://ai.azure.com/?cid=learnDocs).
           2. Rather than immediately entering your guest account credentials instead select `Sign-in options` 
           3. Now select **Sign in to an organization** 
           4. Enter the domain name of the organization that granted your guest account access to the Azure OpenAI resource. 
           5. Now sign-in with your guest account credentials. 
           
-          You should now be able to access the resource via the [Azure AI Foundry portal](https://ai.azure.com/).
+          You should now be able to access the resource via the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
           
           Alternatively if you're signed into the [Azure portal](https://portal.azure.com) from the Azure OpenAI resource's Overview pane you can select **Go to Azure AI Foundry** to automatically sign in with the appropriate organizational context.   
   
@@ -175,7 +175,7 @@ sections:
         answer:
           We do offer an Availability SLA for all resources and a Latency SLA for Provisioned-Managed Deployments. For more information about the SLA for Azure OpenAI Service, see the [Service Level Agreements (SLA) for Online Services page](https://azure.microsoft.com/support/legal/sla/cognitive-services/v1_1/). 
       - question: |
-          How do I enable fine-tuning? Create a custom model is greyed out in [Azure AI Foundry portal](https://ai.azure.com/).  
+          How do I enable fine-tuning? Create a custom model is greyed out in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).  
         answer: |
           In order to successfully access fine-tuning, you need Cognitive Services OpenAI Contributor assigned. Even someone with high-level Service Administrator permissions would still need this account explicitly set in order to access fine-tuning. For more information, please review the [role-based access control guidance](/azure/ai-services/openai/how-to/role-based-access-control#cognitive-services-openai-contributor).
       - question: |
@@ -304,9 +304,9 @@ sections:
         answer:
           You can customize your published web app in the Azure portal. The source code for the published web app is [available on GitHub](https://go.microsoft.com/fwlink/?linkid=2244395), where you can find information on changing the app frontend, as well as instructions for building and deploying the app.
       - question: |
-          Will my web app be overwritten when I deploy the app again from the [Azure AI Foundry portal](https://ai.azure.com/)?
+          Will my web app be overwritten when I deploy the app again from the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)?
         answer:
-          Your app code won't be overwritten when you update your app. The app will be updated to use the Azure OpenAI resource, Azure AI Search index (if you're using Azure OpenAI on your data), and model settings selected in the [Azure AI Foundry portal](https://ai.azure.com/) without any change to the appearance or functionality. 
+          Your app code won't be overwritten when you update your app. The app will be updated to use the Azure OpenAI resource, Azure AI Search index (if you're using Azure OpenAI on your data), and model settings selected in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) without any change to the appearance or functionality. 
   - name: Using your data
     questions:
       - question: |
@@ -316,15 +316,15 @@ sections:
       - question: |
           How can I access Azure OpenAI on your data?  
         answer:
-          All Azure OpenAI customers can use Azure OpenAI on your data via the [Azure AI Foundry portal](https://ai.azure.com/) and Rest API.
+          All Azure OpenAI customers can use Azure OpenAI on your data via the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and Rest API.
       - question: |
           What data sources does Azure OpenAI on your data support?
         answer:
           Azure OpenAI on your data supports ingestion from Azure AI Search, Azure Blob Storage, and uploading local files. You can learn more about Azure OpenAI on your data from the [conceptual article](./concepts/use-your-data.md) and [quickstart](./use-your-data-quickstart.md).
       - question: |
           How much does it cost to use Azure OpenAI on your data?
         answer:
-          When using Azure OpenAI on your data, you incur costs when you use Azure AI Search, Azure Blob Storage, Azure Web App Service, semantic search and OpenAI models. There's no additional cost for using the "your data" feature in the [Azure AI Foundry portal](https://ai.azure.com/).
+          When using Azure OpenAI on your data, you incur costs when you use Azure AI Search, Azure Blob Storage, Azure Web App Service, semantic search and OpenAI models. There's no additional cost for using the "your data" feature in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
       - question: |
           How can I customize or automate the index creation process?
         answer:
@@ -354,7 +354,7 @@ sections:
         answer:
           You must send queries in the same language of your data. Your data can be in any of the languages supported by [Azure AI Search](/azure/search/search-language-support).
       - question: |
-          If Semantic Search is enabled for my Azure AI Search resource, will it be automatically applied to Azure OpenAI on your data in the [Azure AI Foundry portal](https://ai.azure.com/)?
+          If Semantic Search is enabled for my Azure AI Search resource, will it be automatically applied to Azure OpenAI on your data in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)?
         answer:
           When you select "Azure AI Search" as the data source, you can choose to apply semantic search. 
           If you select "Azure Blob Container" or "Upload files" as the data source, you can create the index as usual. Afterwards you would reingest the data using the "Azure AI Search" option to select the same index and apply Semantic Search. You will then be ready to chat on your data with semantic search applied.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry portal 超链接. Locale: zh_CN"
}
```

### Explanation
本次修改对 FAQ 文档中的多处链接进行了调整，增加了 `cid=learnDocs` 参数，以优化用户访问 Azure AI Foundry 门户的体验。具体而言，涉及的链接包括与 Azure OpenAI 资源访问和Fine-tuning功能相关的各种说明。这些更改确保了在用户访问这些页面时，可以更顺畅地找到所需的信息，并提供了一致的用户体验。虽然文本内容进行了大幅修改，但整体信息的完整性和准确性得到了保持。

## articles/ai-services/openai/how-to/batch.md{#item-a131d5}

<details>
<summary>Diff</summary>
````diff
@@ -91,7 +91,7 @@ The following aren't currently supported:
 ### Batch deployment
 
 > [!NOTE]
-> In the [Azure AI Foundry portal](https://ai.azure.com/) the batch deployment types will appear as `Global-Batch` and `Data Zone Batch`. To learn more about Azure OpenAI deployment types, see our [deployment types guide](../how-to/deployment-types.md).
+> In the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) the batch deployment types will appear as `Global-Batch` and `Data Zone Batch`. To learn more about Azure OpenAI deployment types, see our [deployment types guide](../how-to/deployment-types.md).
 
 :::image type="content" source="../media/how-to/global-batch/global-batch.png" alt-text="Screenshot that shows the model deployment dialog in Azure AI Foundry portal with Global-Batch deployment type highlighted." lightbox="../media/how-to/global-batch/global-batch.png":::
 
@@ -163,7 +163,7 @@ Yes. Similar to other deployment types, you can create content filters and assoc
 
 ### Can I request additional quota?
 
-Yes, from the quota page in the [Azure AI Foundry portal](https://ai.azure.com/). Default quota allocation can be found in the [quota and limits article](../quotas-limits.md#batch-quota).
+Yes, from the quota page in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). Default quota allocation can be found in the [quota and limits article](../quotas-limits.md#batch-quota).
 
 ### What happens if the API doesn't complete my request within the 24 hour time frame?
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry portal 超链接. Locale: zh_CN"
}
```

### Explanation
本次修改对文档中提到的 Azure AI Foundry 门户的超链接进行了调整，添加了 `cid=learnDocs` 参数。这一更新的目的是为了提升用户访问体验，确保用户在访问门户时能够更准确地获取相关信息。在讨论批量部署类型及相关配额请求时，所有引用 Azure AI Foundry 门户的链接均进行了这一更新。这些更改保持了文档的内容一致性和完整性，同时也增强了文档的可用性。

## articles/ai-services/openai/how-to/completions.md{#item-79f39a}

<details>
<summary>Diff</summary>
````diff
@@ -19,7 +19,7 @@ Azure OpenAI in Azure AI Foundry Models provides a **completion endpoint** that
 > [!IMPORTANT]
 > Unless you have a specific use case that requires the completions endpoint, we recommend instead using the [responses API](./responses.md) of [chat completions endpoint](./chatgpt.md) which allows you to take advantage of the latest models like GPT-4o, GPT-4o mini, and GPT-4 Turbo. 
 
-The best way to start exploring completions is through the playground in [Azure AI Foundry](https://ai.azure.com). It's a simple text box where you enter a prompt to generate a completion. You can start with a simple prompt like this one:
+The best way to start exploring completions is through the playground in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs). It's a simple text box where you enter a prompt to generate a completion. You can start with a simple prompt like this one:
 
 ```console
 write a tagline for an ice cream shop
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 超链接. Locale: zh_CN"
}
```

### Explanation
本次修改对文档中关于 Azure AI Foundry 的超链接进行了更新，添加了 `cid=learnDocs` 参数，以改善用户访问体验。在描述如何开始探索 completions 时，这一链接的更新确保用户能够更顺畅地访问相关的在线资源。这一更改没有影响文档的基本内容，而是增强了引用部分的可靠性和一致性，为用户提供了更便捷的导航选项。

## articles/ai-services/openai/how-to/dall-e.md{#item-ac9616}

<details>
<summary>Diff</summary>
````diff
@@ -237,7 +237,7 @@ The format in which DALL-E 3 generated images are returned. Must be one of `url`
 
 ## Call the Image Edit API
 
-The Image Edit API allows you to modify existing images based on text prompts you provide. The API call is similar to the image generation API call, but you also need to provide an image URL or base 64-encoded image data.
+The Image Edit API allows you to modify existing images based on text prompts you provide. The API call is similar to the image generation API call, but you also need to provide an input image (base64-encoded image data).
 
 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新图像编辑 API 的描述. Locale: zh_CN"
}
```

### Explanation
本次修改对文档中关于图像编辑 API 的描述进行了细微调整。在解释如何使用图像编辑 API 时，原文中的措辞“提供图像 URL 或 base 64 编码的图像数据”被改为“提供输入图像（base64 编码的图像数据）”。这一更改旨在简化表述，使其更加清晰易懂，同时保持了文档的技术准确性。这一修改不会影响 Api 的功能，但会提升用户对 API 使用要求的理解。

## articles/ai-services/openai/how-to/evaluations.md{#item-dfaa1c}

<details>
<summary>Diff</summary>
````diff
@@ -135,7 +135,7 @@ When you click into each testing criteria, you will see different types of grade
 
 ## Getting started
 
-1. Select the **Azure OpenAI Evaluation (PREVIEW)** within [Azure AI Foundry portal](https://ai.azure.com/). To see this view as an option may need to first select an existing Azure OpenAI resource in a supported region.
+1. Select the **Azure OpenAI Evaluation (PREVIEW)** within [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). To see this view as an option may need to first select an existing Azure OpenAI resource in a supported region.
 2. Select **+ New evaluation**
 
     :::image type="content" source="../media/how-to/evaluations/new-evaluation.png" alt-text="Screenshot of the Azure OpenAI evaluation UX with new evaluation selected." lightbox="../media/how-to/evaluations/new-evaluation.png":::
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户超链接. Locale: zh_CN"
}
```

### Explanation
本次修改对“获取开始”部分的描述进行了微小调整，具体体现在关于 Azure AI Foundry 门户的超链接上。原本的链接被更新为包含 `cid=learnDocs` 参数，以提升用户体验并优化链接的导航性。这一更改旨在确保用户在访问 Azure AI Foundry 时获得更加流畅的体验。其他文本内容保持不变，该修改并未影响任何功能或指令，仅增强了文档的可用性。

## articles/ai-services/openai/how-to/fine-tune-test.md{#item-48f1b6}

<details>
<summary>Diff</summary>
````diff
@@ -146,7 +146,7 @@ az cognitiveservices account deployment create
 
 ## [Portal](#tab/portal)
 
-After your custom model deploys, you can use it like any other deployed model. You can use the **Playgrounds** in the [Azure AI Foundry portal](https://ai.azure.com) to experiment with your new deployment. You can continue to use the same parameters with your custom model, such as `temperature` and `max_tokens`, as you can with other deployed models.
+After your custom model deploys, you can use it like any other deployed model. You can use the **Playgrounds** in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) to experiment with your new deployment. You can continue to use the same parameters with your custom model, such as `temperature` and `max_tokens`, as you can with other deployed models.
 
 :::image type="content" source="../media/fine-tuning/chat-playground.png" alt-text="Screenshot of the Playground pane in Azure AI Foundry portal, with sections highlighted." lightbox="../media/fine-tuning/chat-playground.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户超链接. Locale: zh_CN"
}
```

### Explanation
本次修改主要是对文档中关于如何使用自定义模型的描述进行了细微的更新，特别是对 Azure AI Foundry 门户的链接进行了调整。将原有的链接更新为包含 `cid=learnDocs` 参数，以优化用户导航体验。这一更改并未影响其他内容的解释或功能，旨在提升用户访问门户时的便捷性和有效性。整体而言，这是一项小幅度的更新，有助于强化文档的实用性。

## articles/ai-services/openai/how-to/fine-tuning-deploy.md{#item-286d57}

<details>
<summary>Diff</summary>
````diff
@@ -305,7 +305,7 @@ az cognitiveservices account deployment create
 
 ## [Portal](#tab/portal)
 
-After your custom model deploys, you can use it like any other deployed model. You can use the **Playgrounds** in the [Azure AI Foundry portal](https://ai.azure.com) to experiment with your new deployment. You can continue to use the same parameters with your custom model, such as `temperature` and `max_tokens`, as you can with other deployed models.
+After your custom model deploys, you can use it like any other deployed model. You can use the **Playgrounds** in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) to experiment with your new deployment. You can continue to use the same parameters with your custom model, such as `temperature` and `max_tokens`, as you can with other deployed models.
 
 :::image type="content" source="../media/quickstarts/playground-load-new.png" alt-text="Screenshot of the Playground pane in Azure AI Foundry portal, with sections highlighted." lightbox="../media/quickstarts/playground-load-new.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户超链接. Locale: zh_CN"
}
```

### Explanation
本次修改对文档中描述如何使用自定义模型的部分进行了轻微更新，特别是对 Azure AI Foundry 门户链接的调整。原先的链接经过修改，以包含 `cid=learnDocs` 参数，这样可以增强用户在页面上的导航体验。除此之外，文档的其他部分内容保持不变。这一小幅更新有助于提升用户访问 Azure AI Foundry 门户的效率，使其更加友好和实用。

## articles/ai-services/openai/how-to/model-router.md{#item-eebd7e}

<details>
<summary>Diff</summary>
````diff
@@ -32,7 +32,7 @@ Model router is packaged as a single Azure AI Foundry model that you deploy. Fol
 
 You can use model router through the [chat completions API](/azure/ai-services/openai/chatgpt-quickstart) in the same way you'd use other OpenAI chat models. Set the `model` parameter to the name of our model router deployment, and set the `messages` parameter to the messages you want to send to the model.
 
-In the [Azure AI Foundry portal](https://ai.azure.com/), you can navigate to your model router deployment on the **Models + endpoints** page and select it to enter the model playground. In the playground experience, you can enter messages and see the model's responses. Each response message shows which underlying model was selected to respond.
+In the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you can navigate to your model router deployment on the **Models + endpoints** page and select it to enter the model playground. In the playground experience, you can enter messages and see the model's responses. Each response message shows which underlying model was selected to respond.
 
 
 > [!IMPORTANT]
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户超链接. Locale: zh_CN"
}
```

### Explanation
此次修改对文档中关于模型路由器的说明进行了一些小幅更新，具体体现在 Azure AI Foundry 门户的链接地址上。原有的链接已更新为包含 `cid=learnDocs` 参数，该改动旨在提升用户在访问门户时的体验与便捷性。这一更新并未改变文档的框架和其他内容的表达，因此仍然保持了对用户的清晰指导，确保他们能够顺利使用模型路由器和相关功能。

## articles/ai-services/openai/how-to/monitor-openai.md{#item-fcba4d}

<details>
<summary>Diff</summary>
````diff
@@ -74,7 +74,7 @@ After you configure the diagnostic settings, you can work with metrics and log d
 
 [!INCLUDE [horz-monitor-kusto-queries](~/reusable-content/ce-skilling/azure/includes/azure-monitor/horizontals/horz-monitor-kusto-queries.md)]
 
-After you deploy an Azure OpenAI model, you can send some completions calls by using the **playground** environment in [Azure AI Foundry](https://ai.azure.com/).
+After you deploy an Azure OpenAI model, you can send some completions calls by using the **playground** environment in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs).
 
 Any text that you enter in the **Completions playground** or the **Chat completions playground** generates metrics and log data for your Azure OpenAI resource. In the Log Analytics workspace for your resource, you can query the monitoring data by using the [Kusto](/azure/data-explorer/kusto/query/) query language.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户超链接. Locale: zh_CN"
}
```

### Explanation
此次修改对文档中关于监控 Azure OpenAI 模型的部分进行了小幅更新，主要是对 Azure AI Foundry 门户链接的调整。原来的链接已被更新为包含 `cid=learnDocs` 参数，目的是为了改善用户的访问体验。这一更改不会影响文档的整体结构和内容其他信息的清晰度，用户依然可以通过文档指导有效地使用**Playground**环境来发送完成调用，并收集相关的监控指标和日志数据。

## articles/ai-services/openai/how-to/on-your-data-configuration.md{#item-4875d3}

<details>
<summary>Diff</summary>
````diff
@@ -164,7 +164,7 @@ This step can be skipped only if you have a [shared private link](#create-shared
 
 You can disable public network access of your Azure OpenAI resource in the Azure portal. 
 
-To allow access to your Azure OpenAI from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/), you need to create [private endpoint connections](/azure/ai-services/cognitive-services-virtual-networks?tabs=portal#use-private-endpoints) that connect to your Azure OpenAI resource.
+To allow access to your Azure OpenAI from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you need to create [private endpoint connections](/azure/ai-services/cognitive-services-virtual-networks?tabs=portal#use-private-endpoints) that connect to your Azure OpenAI resource.
 
 
 ## Configure Azure AI Search
@@ -188,7 +188,7 @@ For more information, see the [Azure AI Search RBAC article](/azure/search/searc
 
 You can disable public network access of your Azure AI Search resource in the Azure portal. 
 
-To allow access to your Azure AI Search resource from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/), you need to create [private endpoint connections](/azure/search/service-create-private-endpoint) that connect to your Azure AI Search resource.
+To allow access to your Azure AI Search resource from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you need to create [private endpoint connections](/azure/search/service-create-private-endpoint) that connect to your Azure AI Search resource.
 
 
 ### Enable trusted service
@@ -242,7 +242,7 @@ In the Azure portal, navigate to your storage account networking tab, choose "Se
 
 You can disable public network access of your Storage Account in the Azure portal. 
 
-To allow access to your Storage Account from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/), you need to create [private endpoint connections](/azure/storage/common/storage-private-endpoints) that connect to your blob storage.
+To allow access to your Storage Account from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you need to create [private endpoint connections](/azure/storage/common/storage-private-endpoints) that connect to your blob storage.
 
 
 
@@ -271,9 +271,9 @@ To enable the developers to use these resources to build applications, the admin
 
 |Role| Resource | Description |
 |--|--|--|
-| `Cognitive Services OpenAI Contributor` | Azure OpenAI | Call public ingestion API from [Azure AI Foundry portal](https://ai.azure.com/). The `Contributor` role is not enough, because if you only have `Contributor` role, you cannot call data plane API via Microsoft Entra ID authentication, and Microsoft Entra ID authentication is required in the secure setup described in this article. |
-| `Contributor` | Azure AI Search | List API-Keys to list indexes from [Azure AI Foundry portal](https://ai.azure.com/).|
-| `Contributor` | Storage Account | List Account SAS to upload files from [Azure AI Foundry portal](https://ai.azure.com/).|
+| `Cognitive Services OpenAI Contributor` | Azure OpenAI | Call public ingestion API from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). The `Contributor` role is not enough, because if you only have `Contributor` role, you cannot call data plane API via Microsoft Entra ID authentication, and Microsoft Entra ID authentication is required in the secure setup described in this article. |
+| `Contributor` | Azure AI Search | List API-Keys to list indexes from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).|
+| `Contributor` | Storage Account | List Account SAS to upload files from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).|
 | `Contributor` | The resource group or Azure subscription where the developer need to deploy the web app to | Deploy web app to the developer's Azure subscription.|
 | `Role Based Access Control Administrator` | Azure OpenAI | Permission to configure the necessary role assignment on the Azure OpenAI resource. Enables the web app to call Azure OpenAI. |
 
@@ -297,7 +297,7 @@ Configure your local machine `hosts` file to point your resources host names to
 
 ## Azure AI Foundry portal
 
-You should be able to use all [Azure AI Foundry portal](https://ai.azure.com/) features, including both ingestion and inference, from your on-premises client machines.
+You should be able to use all [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) features, including both ingestion and inference, from your on-premises client machines.
 
 ## Web app
 The web app communicates with your Azure OpenAI resource. Since your Azure OpenAI resource has public network disabled, the web app needs to be set up to use the private endpoint in your virtual network to access your Azure OpenAI resource.
@@ -308,7 +308,7 @@ The web app needs to resolve your Azure OpenAI host name to the private IP of th
 1. [Add a DNS record](/azure/dns/private-dns-getstarted-portal#create-an-additional-dns-record). The IP is the private IP of the private endpoint for your Azure OpenAI resource, and you can get the IP address from the network interface associated with the private endpoint for your Azure OpenAI.
 1. [Link the private DNS zone to your virtual network](/azure/dns/private-dns-getstarted-portal#link-the-virtual-network) so the web app integrated in this virtual network can use this private DNS zone.
 
-When deploying the web app from [Azure AI Foundry portal](https://ai.azure.com/), select the same location with the virtual network, and select a proper SKU, so it can support the [virtual network integration feature](/azure/app-service/overview-vnet-integration). 
+When deploying the web app from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), select the same location with the virtual network, and select a proper SKU, so it can support the [virtual network integration feature](/azure/app-service/overview-vnet-integration). 
 
 After the web app is deployed, from the Azure portal networking tab, configure the web app outbound traffic virtual network integration, choose the third subnet that you reserved for web app.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次更新涉及对文档中与数据配置相关的部分进行了调整，主要是对 Azure AI Foundry 门户链接的修正。在多个地方，原先的链接已改为包含 `cid=learnDocs` 参数。这项更改旨在改善用户访问体验，使其更加便捷。此外，文档的内容结构和指导信息未发生变化，用户可继续按照指南信息有效地配置和使用与 Azure OpenAI、Azure AI 搜索及其他服务相关的功能。

## articles/ai-services/openai/how-to/provisioned-get-started.md{#item-c8df1c}

<details>
<summary>Diff</summary>
````diff
@@ -36,7 +36,7 @@ Creating a new deployment requires available (unused) quota to cover the desired
 
 Then 200 PTUs of quota are considered used, and there are 300 PTUs available for use to create new deployments. 
 
-A default amount of global, data zone, and regional provisioned quota is assigned to eligible subscriptions in several regions. You can view the quota available to you in a region by visiting the Quotas pane in [Azure AI Foundry portal](https://ai.azure.com/) and selecting the desired subscription and region. For example, the screenshot below shows a quota limit of 500 PTUs in West US for the selected subscription. Note that you might see lower values of available default quotas. 
+A default amount of global, data zone, and regional provisioned quota is assigned to eligible subscriptions in several regions. You can view the quota available to you in a region by visiting the Quotas pane in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and selecting the desired subscription and region. For example, the screenshot below shows a quota limit of 500 PTUs in West US for the selected subscription. Note that you might see lower values of available default quotas. 
 
 :::image type="content" source="../media/provisioned/available-quota.png" alt-text="A screenshot of the available quota in Azure AI Foundry portal." lightbox="../media/provisioned/available-quota.png":::
 
@@ -57,7 +57,7 @@ Once you have verified your quota, you can create a deployment. To create a prov
 
 
 
-1. Sign into the [Azure AI Foundry portal](https://ai.azure.com).
+1. Sign into the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 1. Choose the subscription that was enabled for provisioned deployments & select the desired resource in a region where you have the quota.
 1. Under **Management** in the left-nav select **Deployments**.
 1. Select Create new deployment and configure the following fields. Expand the **advanced options** drop-down menu.
@@ -106,7 +106,7 @@ REST, ARM template, Bicep, and Terraform can also be used to create deployments.
 
 Due to the dynamic nature of capacity availability, it is possible that the region of your selected resource might not have the service capacity to create the deployment of the specified model, version, and number of PTUs. 
 
-In this event, the wizard in [Azure AI Foundry portal](https://ai.azure.com/) will direct you to other regions with available quota and capacity to create a deployment of the desired model. If this happens, the deployment dialog will look like this: 
+In this event, the wizard in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) will direct you to other regions with available quota and capacity to create a deployment of the desired model. If this happens, the deployment dialog will look like this: 
 
 :::image type="content" source="../media/provisioned/deployment-screen-2.png" alt-text="Screenshot of the Azure AI Foundry portal deployment page for a provisioned deployment with no capacity available." lightbox="../media/provisioned/deployment-screen-2.png":::
 
@@ -164,7 +164,7 @@ The inferencing code for provisioned deployments is the same a standard deployme
 
 ## Understanding expected throughput
 The amount of throughput that you can achieve on the endpoint is a factor of the number of PTUs deployed, input size, output size, and call rate. The number of concurrent calls and total tokens processed can vary based on these values. Our recommended way for determining the throughput for your deployment is as follows:
-1. Use the Capacity calculator for a sizing estimate. You can find the capacity calculator in [Azure AI Foundry portal](https://ai.azure.com/) under the quotas page and Provisioned tab.  
+1. Use the Capacity calculator for a sizing estimate. You can find the capacity calculator in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) under the quotas page and Provisioned tab.  
 1. Benchmark the load using real traffic workload. For more information about benchmarking, see the [benchmarking](#run-a-benchmark) section.
 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改在文档中对 Azure AI Foundry 门户的链接进行了更新，主要是在多个位置添加了 `cid=learnDocs` 参数，以改善用户体验和访问路径。这些链接出现在有关配额查看、部署创建及容量计算器的相关说明中。虽然文档内容保持一致，这些小幅度的更改旨在确保用户能够更方便地访问 Azure AI Foundry 门户，并准确获取所需的相关信息和资源。

## articles/ai-services/openai/how-to/provisioned-throughput-onboarding.md{#item-3eb72b}

<details>
<summary>Diff</summary>
````diff
@@ -119,7 +119,7 @@ Choose a model, and click **Confirm**. Select a provision-managed deployment typ
 
 :::image type="content" source="../media/provisioned/deployment-ptu-capacity-calculator.png" alt-text="A screenshot of deployment workflow PTU capacity calculator." lightbox="../media/provisioned/deployment-ptu-capacity-calculator.png":::
 
-To estimate provisioned capacity using request level data, open the capacity planner in the [Azure AI Foundry](https://ai.azure.com). The capacity calculator is under **Shared resources** > **Model Quota** > **Azure OpenAI Provisioned**.
+To estimate provisioned capacity using request level data, open the capacity planner in the [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs). The capacity calculator is under **Shared resources** > **Model Quota** > **Azure OpenAI Provisioned**.
 
 The **Provisioned** option and the capacity planner are only available in certain regions within the Quota pane, if you don't see this option setting the quota region to *Sweden Central* will make this option available. Enter the following parameters based on your workload.
 
@@ -144,7 +144,7 @@ The values in the output column are the estimated value of PTU units required fo
 
 Discounts on top of the hourly usage price can be obtained by purchasing an Azure Reservation for Azure OpenAI Provisioned, Data Zone Provisioned, and Global Provisioned. An Azure Reservation is a term-discounting mechanism shared by many Azure products. For example, Compute and Cosmos DB. For Azure OpenAI Provisioned, Data Zone Provisioned, and Global Provisioned, the reservation provides a discount in exchange for committing to payment for fixed number of PTUs for a one-month or one-year period.  
 
-* Azure Reservations are purchased via the Azure portal, not the [Azure AI Foundry portal](https://ai.azure.com/) Link to Azure reservation portal.
+* Azure Reservations are purchased via the Azure portal, not the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) Link to Azure reservation portal.
 
 * Reservations are purchased regionally and can be flexibly scoped to cover usage from a group of deployments. Reservation scopes include: 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改对文档中提到的 Azure AI Foundry 门户链接进行了细微更新，具体而言，增加了链接中的 `cid=learnDocs` 参数。这一更改出现在关于使用请求级数据估算提供容量和 Azure 预留的相关段落中。尽管文档内容本身并未发生重大变化，这项更新旨在提高用户访问链接的便利性，确保他们能够顺利访问到所需的信息和工具，进一步优化用户体验。

## articles/ai-services/openai/how-to/quota.md{#item-9440c2}

<details>
<summary>Diff</summary>
````diff
@@ -42,11 +42,11 @@ The flexibility to distribute TPM globally within a subscription and region has
 
 When you create a model deployment, you have the option to assign Tokens-Per-Minute (TPM) to that deployment. TPM can be modified in increments of 1,000, and will map to the TPM and RPM rate limits enforced on your deployment, as discussed above.
 
-To create a new deployment from within the [Azure AI Foundry portal](https://ai.azure.com/) select **Deployments** > **Deploy model** > **Deploy base model** > **Select Model** > **Confirm**.
+To create a new deployment from within the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) select **Deployments** > **Deploy model** > **Deploy base model** > **Select Model** > **Confirm**.
 
 :::image type="content" source="../media/quota/deployment-new.png" alt-text="Screenshot of the deployment UI of Azure AI Foundry" lightbox="../media/quota/deployment-new.png":::
 
-Post deployment you can adjust your TPM allocation by selecting and editing your model from the **Deployments** page in [Azure AI Foundry portal](https://ai.azure.com/). You can also modify this setting from the **Management** > **Model quota** page.
+Post deployment you can adjust your TPM allocation by selecting and editing your model from the **Deployments** page in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). You can also modify this setting from the **Management** > **Model quota** page.
 
 > [!IMPORTANT]
 > Quotas and limits are subject to change, for the most up-date-information consult our [quotas and limits article](../quotas-limits.md).
@@ -66,7 +66,7 @@ All other model classes have a common max TPM value.
 
 ## View and request quota
 
-For an all up view of your quota allocations across deployments in a given region, select **Management** > **Quota** in [Azure AI Foundry portal](https://ai.azure.com/):
+For an all up view of your quota allocations across deployments in a given region, select **Management** > **Quota** in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs):
 
 :::image type="content" source="../media/quota/quota-new.png" alt-text="Screenshot of the quota UI of Azure AI Foundry" lightbox="../media/quota/quota-new.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改涉及在文档中更新 Azure AI Foundry 门户的链接，增加了 `cid=learnDocs` 参数。这一更改出现在创建模型部署和调整 Tokens-Per-Minute (TPM) 分配的相关说明中。虽然文档的主要内容和指引没有改变，但这些链接的更新旨在改善用户体验，确保用户在访问 Azure AI Foundry 门户时能够更方便地获取相关信息和资源，从而提高整体可用性。

## articles/ai-services/openai/how-to/reinforcement-fine-tuning.md{#item-e8028c}

<details>
<summary>Diff</summary>
````diff
@@ -176,11 +176,11 @@ Models which we're supporting as grader models are:
     "model": string,
     "pass_threshold": number,
     "range": number[],
-    "sampling_parameters": {
+    "sampling_params": {
         "seed": number,
         "top_p": number,
         "temperature": number,
-        "max_completion_tokens": number,
+        "max_completions_tokens": number,
         "reasoning_effort": "low" | "medium" | "high"
     }
 }
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新参数名称以提高一致性. Locale: zh_CN"
}
```

### Explanation
此次修改对文档中的一些参数名称进行了微调，以提高术语的一致性。具体而言，将 `"sampling_parameters"` 更新为 `"sampling_params"`，以及将 `"max_completion_tokens"` 改为 `"max_completions_tokens"`。这些更改旨在使文档中的技术说明更加清晰和一致，从而帮助用户更好地理解与模型评分相关的配置参数。尽管修改相对较小，但这些改进可以增强文档的专业性和可读性。

## articles/ai-services/openai/how-to/risks-safety-monitor.md{#item-b2be0b}

<details>
<summary>Diff</summary>
````diff
@@ -14,13 +14,13 @@ manager: nitinme
 
 When you use an Azure OpenAI model deployment with a content filter, you might want to check the results of the filtering activity. You can use that information to further adjust your [filter configuration](/azure/ai-services/openai/how-to/content-filters) to serve your specific business needs and Responsible AI principles.  
 
-[Azure AI Foundry](https://ai.azure.com/) provides a Risks & Safety monitoring dashboard for each of your deployments that uses a content filter configuration.
+[Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) provides a Risks & Safety monitoring dashboard for each of your deployments that uses a content filter configuration.
 
 ## Access Risks & Safety monitoring
 
 To access Risks & Safety monitoring, you need an Azure OpenAI resource in one of the supported Azure regions: East US, Switzerland North, France Central, Sweden Central, Canada East. You also need a model deployment that uses a content filter configuration.
 
-Go to [Azure AI Foundry](https://ai.azure.com/) and sign in with the credentials associated with your Azure OpenAI resource. Select a project. Then select the **Models + endpoints** tab on the left and then select your model deployment from the list. On the deployment's page, select the **Monitoring** tab at the top. Then select **Open in Azure Monitor** to view the full report in the Azure portal.
+Go to [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) and sign in with the credentials associated with your Azure OpenAI resource. Select a project. Then select the **Models + endpoints** tab on the left and then select your model deployment from the list. On the deployment's page, select the **Monitoring** tab at the top. Then select **Open in Azure Monitor** to view the full report in the Azure portal.
 
 ## Configure metrics   
 
@@ -56,7 +56,7 @@ To use Potentially abusive user detection, you need:
 ### Set up your Azure Data Explorer database
 
 In order to protect the data privacy of user information and manage the permission of the data, we support the option for our customers to bring their own storage to get the detailed potentially abusive user detection insights (including user GUID and statistics on harmful request by category) stored in a compliant way and with full control. Follow these steps to enable it:
-1. In [Azure AI Foundry](https://ai.azure.com/), navigate to the model deployment that you'd like to set up user abuse analysis with, and select **Add a data store**. 
+1. In [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs), navigate to the model deployment that you'd like to set up user abuse analysis with, and select **Add a data store**. 
 1. Fill in the required information and select **Save**. We recommend you create a new database to store the analysis results.
 1. After you connect the data store, take the following steps to grant permission to write analysis results to the connected database:
     1. Go to your Azure OpenAI resource's page in the Azure portal, and choose the **Identity** tab.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改对文档中提到的 Azure AI Foundry 门户链接进行了更新，新增了 `cid=learnDocs` 参数。这一修改出现在关于如何访问风险与安全监控以及具体配置步骤的说明中。尽管链接内容没有实质性变化，但此更新旨在优化用户在访问 Azure AI Foundry 门户时的导航体验，确保用户能更方便地找到相关信息和资源。这种微小的调整有助于提高文档的可用性和专业性。

## articles/ai-services/openai/how-to/role-based-access-control.md{#item-4b9817}

<details>
<summary>Diff</summary>
````diff
@@ -48,8 +48,8 @@ If a user were granted role-based access to only this role for an Azure OpenAI r
 
 ✅ View the resource in [Azure portal](https://portal.azure.com) <br>
 ✅ View the resource endpoint under **Keys and Endpoint** <br>
-✅ Ability to view the resource and associated model deployments in [Azure AI Foundry portal](https://ai.azure.com/). <br>
-✅ Ability to view what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/). <br>
+✅ Ability to view the resource and associated model deployments in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). <br>
+✅ Ability to view what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). <br>
 ✅ Use the Chat, Completions, and DALL-E (preview) playground experiences to generate text and images with any models that have already been deployed to this Azure OpenAI resource. <br>
 ✅ Make inference API calls with Microsoft Entra ID.
 
@@ -91,7 +91,7 @@ This role is typically granted access at the resource group level for a user in
 ✅ View resources in the assigned resource group in the [Azure portal](https://portal.azure.com). <br>
 ✅ View the resource endpoint under **Keys and Endpoint** <br>
 ✅ View/Copy/Regenerate keys under **Keys and Endpoint** <br>
-✅ Ability to view what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/) <br>
+✅ Ability to view what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) <br>
 ✅ Use the Chat, Completions, and DALL-E (preview) playground experiences to generate text and images with any models that have already been deployed to this Azure OpenAI resource <br>
 ✅ Create customized content filters <br>
 ✅ Add data sources to Azure OpenAI On Your Data. **You must also have the [Cognitive Services OpenAI Contributor](#cognitive-services-openai-contributor) role as well**.
@@ -112,27 +112,27 @@ Viewing quota requires the **Cognitive Services Usages Reader** role. This role
 
 This role can be found in the Azure portal under **Subscriptions** > ***Access control (IAM)** > **Add role assignment** > search for **Cognitive Services Usages Reader**. The role must be applied at the subscription level, it does not exist at the resource level.
 
-If you don't wish to use this role, the subscription **Reader** role provides equivalent access, but it also grants read access beyond the scope of what is needed for viewing quota. Model deployment via the [Azure AI Foundry portal](https://ai.azure.com/) is also partially dependent on the presence of this role.
+If you don't wish to use this role, the subscription **Reader** role provides equivalent access, but it also grants read access beyond the scope of what is needed for viewing quota. Model deployment via the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) is also partially dependent on the presence of this role.
 
 This role provides little value by itself and is instead typically assigned in combination with one or more of the previously described roles.
 
 #### Cognitive Services Usages Reader + Cognitive Services OpenAI User
 
 All the capabilities of Cognitive Services OpenAI User plus the ability to:
 
-✅ View quota allocations in [Azure AI Foundry portal](https://ai.azure.com/)
+✅ View quota allocations in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)
 
 #### Cognitive Services Usages Reader + Cognitive Services OpenAI Contributor
 
 All the capabilities of Cognitive Services OpenAI Contributor plus the ability to:
 
-✅ View quota allocations in [Azure AI Foundry portal](https://ai.azure.com/)
+✅ View quota allocations in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)
 
 #### Cognitive Services Usages Reader + Cognitive Services Contributor
 
 All the capabilities of Cognitive Services Contributor plus the ability to:
 
-✅ View & edit quota allocations in [Azure AI Foundry portal](https://ai.azure.com/) <br>
+✅ View & edit quota allocations in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) <br>
 ✅ Create new model deployments or edit existing model deployments (via Azure AI Foundry) <br>
 
 ## Summary
@@ -141,8 +141,8 @@ All the capabilities of Cognitive Services Contributor plus the ability to:
 |-------------|--------------------|------------------------|------------------|-------------------------|
 |View the resource in Azure portal |✅|✅|✅| ➖ |
 |View the resource endpoint under “Keys and Endpoint” |✅|✅|✅| ➖ |
-|View the resource and associated model deployments in [Azure AI Foundry portal](https://ai.azure.com/) |✅|✅|✅| ➖ |
-|View what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/)|✅|✅|✅| ➖ |
+|View the resource and associated model deployments in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) |✅|✅|✅| ➖ |
+|View what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)|✅|✅|✅| ➖ |
 |Use the Chat, Completions, and DALL-E (preview) playground experiences with any models that have already been deployed to this Azure OpenAI resource.|✅|✅|✅| ➖ |
 |Create or edit model deployments|❌|✅|✅| ➖ |
 |Create or deploy custom fine-tuned models|❌|✅|✅| ➖ |
@@ -160,7 +160,7 @@ All the capabilities of Cognitive Services Contributor plus the ability to:
 
 **Issue:**
 
-When selecting an existing Azure Cognitive Search resource the search indices don't load, and the loading wheel spins continuously. In [Azure AI Foundry portal](https://ai.azure.com/), go to **Playground Chat** > **Add your data (preview)** under Assistant setup. Selecting **Add a data source** opens a modal that allows you to add a data source through either Azure Cognitive Search or Blob Storage. Selecting the Azure Cognitive Search option and an existing Azure Cognitive Search resource should load the available Azure Cognitive Search indices to select from.
+When selecting an existing Azure Cognitive Search resource the search indices don't load, and the loading wheel spins continuously. In [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), go to **Playground Chat** > **Add your data (preview)** under Assistant setup. Selecting **Add a data source** opens a modal that allows you to add a data source through either Azure Cognitive Search or Blob Storage. Selecting the Azure Cognitive Search option and an existing Azure Cognitive Search resource should load the available Azure Cognitive Search indices to select from.
 
 **Root cause** 
 
@@ -186,7 +186,7 @@ For this API call, you need a **subscription-level scope** role. You can use the
 
 **Root cause:**
 
-Insufficient subscription-level access for the user attempting to access the blob storage in [Azure AI Foundry portal](https://ai.azure.com/). The user may **not** have the necessary permissions to call the Azure Management API endpoint: ```https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{accountName}/listAccountSas?api-version=2022-09-01```
+Insufficient subscription-level access for the user attempting to access the blob storage in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). The user may **not** have the necessary permissions to call the Azure Management API endpoint: ```https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{accountName}/listAccountSas?api-version=2022-09-01```
 
 Public access to the blob storage is disabled by the owner of the Azure subscription for security reasons.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接以优化访问. Locale: zh_CN"
}
```

### Explanation
此次修改对文档中提到的 Azure AI Foundry 门户链接进行了更新，新增了 `cid=learnDocs` 参数，以优化用户的访问体验。整个文档涉及角色基础访问控制的相关说明，修改包括增强用户在 Azure AI Foundry 门户中各种功能的可见性和使用体验。虽然改动主要集中在链接内容上，但此更新有助于提升用户查找信息的效率，使得链接更加可访问和相关，符合用户的业务需求。整体来看，这一更新旨在增强文档的清晰度和导航便捷性。

## articles/ai-services/openai/how-to/stored-completions.md{#item-ccc7e6}

<details>
<summary>Diff</summary>
````diff
@@ -245,7 +245,7 @@ curl $AZURE_OPENAI_ENDPOINT/openai/deployments/gpt-4o/chat/completions?api-versi
 
 ---
 
-Once stored completions are enabled for an Azure OpenAI deployment, they'll begin to show up in the [Azure AI Foundry portal](https://ai.azure.com) in the **Stored Completions** pane.
+Once stored completions are enabled for an Azure OpenAI deployment, they'll begin to show up in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) in the **Stored Completions** pane.
 
 :::image type="content" source="../media/stored-completions/stored-completions.png" alt-text="Screenshot of the stored completions User Experience." lightbox="../media/stored-completions/stored-completions.png":::
 
@@ -255,7 +255,7 @@ Distillation allows you to turn your stored completions into a fine-tuning datas
 
 Distillation requires a minimum of 10 stored completions, though it's recommended to provide hundreds to thousands of stored completions for the best results.
 
-1. From the **Stored Completions** pane in the [Azure AI Foundry portal](https://ai.azure.com) use the **Filter** options to select the completions you want to train your model with.
+1. From the **Stored Completions** pane in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) use the **Filter** options to select the completions you want to train your model with.
 
 2. To begin distillation, select **Distill**
 
@@ -284,7 +284,7 @@ The [evaluation](./evaluations.md) of large language models is a critical step i
 
 Stored completions can be used as a dataset for running evaluations.
 
-1. From the **Stored Completions** pane in the [Azure AI Foundry portal](https://ai.azure.com) use the **Filter** options to select the completions you want to be part of your evaluation dataset.
+1. From the **Stored Completions** pane in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) use the **Filter** options to select the completions you want to be part of your evaluation dataset.
 
 2. To configure the evaluation, select **Evaluate**
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改对有关存储完成内容的文档进行了轻微更新，具体表现为所有提到的 Azure AI Foundry 门户链接中添加了 `cid=learnDocs` 参数。这些链接出现在如何使用存储的完成内容进行训练和评估的说明中。尽管实际内容没有变化，这一更新旨在改善用户访问 Azure AI Foundry 门户的体验，使其更便于用户查找和利用相关资源。整体而言，这些微小的调整不仅增加了文档的可读性，还可能提高用户对文档内容的理解与使用效率。

## articles/ai-services/openai/how-to/use-blocklists.md{#item-e99db7}

<details>
<summary>Diff</summary>
````diff
@@ -62,7 +62,7 @@ The response code should be `201` (created a new list) or `200` (updated an exis
 
 ### Apply a blocklist to a content filter
 
-If you haven't yet created a content filter, you can do so in [Azure AI Foundry](https://ai.azure.com/). See [Content filtering](/azure/ai-services/openai/how-to/content-filters#create-a-content-filter-in-azure-ai-foundry).
+If you haven't yet created a content filter, you can do so in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs). See [Content filtering](/azure/ai-services/openai/how-to/content-filters#create-a-content-filter-in-azure-ai-foundry).
 
 To apply a **completion** blocklist to a content filter, use the following cURL command: 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改对使用黑名单的文档进行了小幅更新，特别是在提到创建内容过滤器的部分，将原有的 Azure AI Foundry 门户链接替换为包含 `cid=learnDocs` 参数的新链接。这一更新旨在提高用户访问相关资源时的便利性，增强文档的可读性和实用性。通过这种方式，用户在创建内容过滤器的过程中能更快速地找到所需信息，从而提高工作效率。整体而言，这一小改动对用户体验有着积极的影响。

## articles/ai-services/openai/how-to/use-web-app.md{#item-802413}

<details>
<summary>Diff</summary>
````diff
@@ -17,7 +17,7 @@ recommendations: false
 > [!NOTE]
 > The web app and its [source code](https://github.com/microsoft/sample-app-aoai-chatGPT) are provided "as is" and as a sample only. Customers are responsible for all customization and implementation of their web apps. See the support section for the web app on [GitHub](https://github.com/microsoft/sample-app-aoai-chatGPT/blob/main/SUPPORT.md) for more information.
 
-Along with [Azure AI Foundry portal](https://ai.azure.com/), APIs, and SDKs, you can use the customizable standalone web app to interact with Azure OpenAI models by using a graphical user interface. Key features include:
+Along with [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), APIs, and SDKs, you can use the customizable standalone web app to interact with Azure OpenAI models by using a graphical user interface. Key features include:
 * Connectivity with multiple data sources to support rich querying and retrieval-augmented generation, including Azure AI Search, Prompt Flow, and more.
 * Conversation history and user feedback collection through Cosmos DB.
 * Authentication with role-based access control via Microsoft Entra ID.
@@ -119,7 +119,7 @@ To modify the application user interface, follow the instructions in the previou
 
 You can turn on chat history for your users of the web app. When you turn on the feature, users have access to their individual previous queries and responses.
 
-To turn on chat history, deploy or redeploy your model as a web app by using [Azure AI Foundry portal](https://ai.azure.com/) and select **Enable chat history and user feedback in the web app**.
+To turn on chat history, deploy or redeploy your model as a web app by using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and select **Enable chat history and user feedback in the web app**.
 
 :::image type="content" source="../media/use-your-data/enable-chat-history.png" alt-text="Screenshot of the checkbox for enabling chat history in Azure OpenAI or Azure AI Foundry." lightbox="../media/use-your-data/enable-chat-history.png":::
 
@@ -191,15 +191,15 @@ To connect to Azure AI Search without redeploying your app, you can modify the f
 - `AZURE_SEARCH_ENABLE_IN_DOMAIN`: Limits responses to queries related only to your data.
     - Data type: boolean, should be set to `True`.
 - `AZURE_SEARCH_CONTENT_COLUMNS`: Specifies the list of fields in your Azure AI Search index that contain the text content of your documents, used when formulating a bot response.
-    - Data type: text, defaults to `content` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
+    - Data type: text, defaults to `content` if deployed from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs),
 - `AZURE_SEARCH_FILENAME_COLUMN`: Specifies the field from your Azure AI Search index that provides a unique identifier of the source data to display in the UI.
-    - Data type: text, defaults to `filepath` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
+    - Data type: text, defaults to `filepath` if deployed from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs),
 - `AZURE_SEARCH_TITLE_COLUMN`: Specifies the field from your Azure AI Search index that provides a relevant title or header for your data content to display in the UI.
-    - Data type: text, defaults to `title` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
+    - Data type: text, defaults to `title` if deployed from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs),
 - `AZURE_SEARCH_URL_COLUMN`: Specifies the field from your Azure AI Search index that contains a URL for the document.
-    - Data type: text, defaults to `url` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
+    - Data type: text, defaults to `url` if deployed from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs),
 - `AZURE_SEARCH_VECTOR_COLUMNS`: Specifies the list of fields in your Azure AI Search index that contain vector embeddings of your documents, used when formulating a bot response.
-    - Data type: text, defaults to `contentVector` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
+    - Data type: text, defaults to `contentVector` if deployed from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs),
 - `AZURE_SEARCH_QUERY_TYPE`: Specifies the query type to use: `simple`, `semantic`, `vector`, `vectorSimpleHybrid`, or `vectorSemanticHybrid`. This setting takes precedence over `AZURE_SEARCH_USE_SEMANTIC_SEARCH`.
     - Data type: text, we recommend testing with `vectorSemanticHybrid`.
 - `AZURE_SEARCH_PERMITTED_GROUPS_COLUMN`: Specifies the field from your Azure AI Search index that contains Microsoft Entra group IDs, determining document-level access control.
@@ -294,7 +294,7 @@ The JSON to paste in the Advanced edit JSON editor is:
 
 ### Creating and deploying your prompt flow in Azure AI Foundry portal
 
-Follow [this tutorial](../../../ai-foundry/how-to/flow-deploy.md) to create, test, and deploy an inferencing endpoint for your prompt flow in [Azure AI Foundry portal](https://ai.azure.com/).
+Follow [this tutorial](../../../ai-foundry/how-to/flow-deploy.md) to create, test, and deploy an inferencing endpoint for your prompt flow in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 
 ### Enable underlying citations from your prompt flow
 
@@ -404,7 +404,7 @@ If you customized or changed the app's source code, you need to update your app'
 
 ## Deleting your Cosmos DB instance
 
-Deleting your web app doesn't delete your Cosmos DB instance automatically. To delete your Cosmos DB instance along with all stored chats, you need to go to the associated resource in the [Azure portal](https://portal.azure.com) and delete it. If you delete the Cosmos DB resource but keep the chat history option selected on subsequent updates from the [Azure AI Foundry portal](https://ai.azure.com/), the application notifies the user of a connection error. However, the user can continue to use the web app without access to the chat history.
+Deleting your web app doesn't delete your Cosmos DB instance automatically. To delete your Cosmos DB instance along with all stored chats, you need to go to the associated resource in the [Azure portal](https://portal.azure.com) and delete it. If you delete the Cosmos DB resource but keep the chat history option selected on subsequent updates from the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), the application notifies the user of a connection error. However, the user can continue to use the web app without access to the chat history.
 
 ## Enabling Microsoft Entra ID authentication between services
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改对使用 Web 应用的文档进行了小幅更新，主要在于对提到的 Azure AI Foundry 门户链接添加了 `cid=learnDocs` 参数。这一变化出现在多个地方，包括介绍应用程序功能、启用聊天记录的说明，以及创建和部署提示流的教程链接。这些更新旨在增强用户访问相关资源的便利性和准确性，从而提高整体用户体验。虽然内容的实质没有变化，但每个链接的小调整使得文档更加连贯，更容易引导用户找到所需的信息，更有效地与 Azure OpenAI 模型进行交互。

## articles/ai-services/openai/how-to/weights-and-biases-integration.md{#item-8ae868}

<details>
<summary>Diff</summary>
````diff
@@ -87,7 +87,7 @@ Give your Azure OpenAI resource the **Key Vault Secrets Officer** role.
 
 ## Link Weights & Biases with Azure OpenAI
 
-1. Navigate to the [Azure AI Foundry portal](https://ai.azure.com) and select your Azure OpenAI fine-tuning resource.
+1. Navigate to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and select your Azure OpenAI fine-tuning resource.
 
     :::image type="content" source="../media/how-to/weights-and-biases/manage-integrations.png" alt-text="Screenshot of the manage integrations button." lightbox="../media/how-to/weights-and-biases/manage-integrations.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改对“Weights 和 Biases 集成”文档进行了小幅更新，具体表现为在导航到 Azure AI Foundry 门户的指示中添加了 `cid=learnDocs` 参数。这个小的修改旨在为用户提供更清晰的链接，使他们在访问 Azure AI Foundry 门户时能够直接导航到相关内容，从而提升用户体验。此调整虽然只是一处小改动，但可以帮助用户更快找到所需资源，增强文档的连贯性和易用性。整体来看，这种优化有助于用户更高效地管理他们的 Azure OpenAI 微调资源。

## articles/ai-services/openai/how-to/work-with-code.md{#item-b193c2}

<details>
<summary>Diff</summary>
````diff
@@ -27,7 +27,7 @@ You can use Codex for a variety of tasks including:
 
 ## How to use completions models with code
 
-Here are a few examples of using completion models that can be tested in the [Azure AI Foundry](https://ai.azure.com) playground with a deployment of `gpt-35-turbo-instruct`.
+Here are a few examples of using completion models that can be tested in the [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) playground with a deployment of `gpt-35-turbo-instruct`.
 
 ### Saying "Hello" (Python)
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改对“如何处理代码”文档进行了一处小幅更新，在提及 Azure AI Foundry 游乐场的链接时，增加了 `cid=learnDocs` 参数。这一变化确保用户在访问该门户时能够更方便地找到相关的文档和资源。尽管此处的内容修改较小，但通过这一链接的优化，可以提升用户体验，增强用户与 Azure OpenAI 服务的交互便利性。整体来说，这种细微的改动有助于提高文档的连贯性和实用性，为用户提供更清晰的导航路径。

## articles/ai-services/openai/how-to/working-with-models.md{#item-7ec098}

<details>
<summary>Diff</summary>
````diff
@@ -20,7 +20,7 @@ You can get a list of models that are available for both inference and fine-tuni
 
 ## Model updates
 
-Azure OpenAI now supports automatic updates for select model deployments. On models where automatic update support is available, a model version drop-down is visible in [Azure AI Foundry portal](https://ai.azure.com/) under **Deployments** and **Edit**:
+Azure OpenAI now supports automatic updates for select model deployments. On models where automatic update support is available, a model version drop-down is visible in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) under **Deployments** and **Edit**:
 
 :::image type="content" source="../media/models/auto-update-new.png" alt-text="Screenshot of the deploy model UI in the Azure AI Foundry portal." lightbox="../media/models/auto-update-new.png":::
 
@@ -43,13 +43,13 @@ When you select a specific model version for a deployment, this version remains
 
 ## Viewing retirement dates
 
-For currently deployed models, in the [Azure AI Foundry portal](https://ai.azure.com/) select **Deployments**:
+For currently deployed models, in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) select **Deployments**:
 
 :::image type="content" source="../media/models/deployments-new.png" alt-text="Screenshot of the deployment UI of the Azure AI Foundry portal." lightbox="../media/models/deployments-new.png":::
 
 ## Model deployment upgrade configuration
 
-You can check what model upgrade options are set for previously deployed models in the [Azure AI Foundry portal](https://ai.azure.com). Select **Deployments** > Under the deployment name column select one of the deployment names that are highlighted in blue.
+You can check what model upgrade options are set for previously deployed models in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). Select **Deployments** > Under the deployment name column select one of the deployment names that are highlighted in blue.
 
 Selecting a deployment name opens the **Properties** for the model deployment. You can view what upgrade options are set for your deployment under **Version update policy**:
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改对“与模型合作”文档进行了小幅更新，主要内容为在提到 Azure AI Foundry 门户的多个链接中，增加了 `cid=learnDocs` 参数。这一优化确保用户在访问该门户时能够直接获得与文档相对应的信息，提升了用户导航的便捷性。尽管这是一个小改动，但它加强了文档的准确性和可用性，帮助用户更有效地找到相关功能和更新信息。总的来说，此次修改旨在改善用户体验，使文档更具连贯性和易用性。

## articles/ai-services/openai/includes/audio-completions-ai-foundry.md{#item-748538}

<details>
<summary>Diff</summary>
````diff
@@ -15,10 +15,10 @@ ms.date: 1/7/2025
 
 ## Use GPT-4o audio generation
 
-To chat with your deployed `gpt-4o-mini-audio-preview` model in the **Chat** playground of [Azure AI Foundry portal](https://ai.azure.com), follow these steps:
+To chat with your deployed `gpt-4o-mini-audio-preview` model in the **Chat** playground of [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), follow these steps:
 
-1. Go to the [Azure AI Foundry portal](https://ai.azure.com) and select your project that has your deployed `gpt-4o-mini-audio-preview` model.
-1. Go to your project in [Azure AI Foundry](https://ai.azure.com). 
+1. Go to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and select your project that has your deployed `gpt-4o-mini-audio-preview` model.
+1. Go to your project in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs). 
 1. Select **Playgrounds** from the left pane.
 1. Select **Audio playground** > **Try the Chat playground**. 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改针对“音频完成 AI Foundry”文档进行了小幅更新，主要是在提到 Azure AI Foundry 门户的链接时，添加了 `cid=learnDocs` 参数。这一更新旨在提高用户访问文档和功能的便捷性，确保用户能够直接找到相关资源。具体来说，在描述如何与已部署的 `gpt-4o-mini-audio-preview` 模型进行互动时，文中出现的链接被统一修改，以增强文档的连贯性。虽然变化不大，但这样的细节调整有助于改善用户体验，使用户能够更有效地利用 Azure AI Foundry 提供的工具和服务。总的来说，这次修改提升了文档的准确性和实用性。

## articles/ai-services/openai/includes/audio-completions-deploy-model.md{#item-c5a63e}

<details>
<summary>Diff</summary>
````diff
@@ -8,7 +8,7 @@ ms.date: 5/23/2025
 ---
 
 To deploy the `gpt-4o-mini-audio-preview` model in the Azure AI Foundry portal:
-1. Go to the [Azure AI Foundry portal](https://ai.azure.com) and create or select your project. 
+1. Go to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and create or select your project. 
 1. Select **Models + endpoints** from under **My assets** in the left pane.
 1. Select **+ Deploy model** > **Deploy base model** to open the deployment window. 
 1. Search for and select the `gpt-4o-mini-audio-preview` model and then select **Confirm**.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此次修改针对“音频完成模型部署”文档进行了小幅更新，主要内容是在描述如何在 Azure AI Foundry 门户中部署 `gpt-4o-mini-audio-preview` 模型时，将链接中的 `ai.azure.com` URL 修改为带有 `cid=learnDocs` 参数的版本。这一改动旨在提高用户的导航体验，使用户在访问相关资源时能够直接获取到与文档对应的信息。尽管这是一个小的调整，但对增加文档的一致性和可用性有积极作用。总体而言，此次修改旨在改善用户体验，确保用户能够轻松找到所需的工具和服务。

## articles/ai-services/openai/includes/batch/batch-studio.md{#item-d4822e}

<details>
<summary>Diff</summary>
````diff
@@ -74,7 +74,7 @@ For this article, we'll create a file named `test.jsonl` and will copy the conte
 Once your input file is prepared, you first need to upload the file to then be able to initiate a batch job. File upload can be done both programmatically or via the Azure AI Foundry portal. This example demonstrates uploading a file directly to your Azure OpenAI resource. Alternatively, you can [configure Azure Blob Storage for Azure OpenAI Batch](../../how-to/batch-blob-storage.md). 
 
 
-1. Sign in to [Azure AI Foundry portal](https://ai.azure.com).
+1. Sign in to [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 2. Select the Azure OpenAI resource where you have a global batch model deployment available.
 3. Select **Batch jobs** > **+Create batch jobs**.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在这次修改中，“批处理工作室”文档进行了细微更新，主要是对 Azure AI Foundry 门户的链接进行了调整。现在，链接的 URL 中包含了参数 `cid=learnDocs`，目的是提升用户访问相关文档和资源的体验。这一变更在指南中明确了如何通过 Azure AI Foundry 门户上传文件以启动批处理作业，确保用户在操作该步骤时能够更便利地获取所需信息。尽管修改较小，但它增强了文档的一致性和用户友好性，有助于用户快速找到帮助和支持。总的来说，此次更新旨在改善用户体验，使指南更加直观易用。

## articles/ai-services/openai/includes/chatgpt-studio.md{#item-ab43f3}

<details>
<summary>Diff</summary>
````diff
@@ -15,7 +15,7 @@ ms.date: 09/19/2024
 
 ## Go to Azure AI Foundry
 
-Navigate to the [Azure AI Foundry portal](https://ai.azure.com/) and sign-in with credentials that have access to your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
+Navigate to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and sign-in with credentials that have access to your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
 
 From Azure AI Foundry, select **Chat playground**.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
此修改对“ChatGPT 工作室”文档进行了小幅调整，主要是在导航到 Azure AI Foundry 门户部分更新了链接。新的链接版本中添加了 `cid=learnDocs` 参数，旨在提升用户访问相关资源时的体验。用户在登录时需要使用拥有 Azure OpenAI 资源访问权限的凭据，修改后的链接确保用户更容易找到与文档相关的支持和信息。尽管修改的内容较小，但它增强了文档的一致性和可用性，有助于提高用户导航的效率。整体来看，此次更新旨在优化用户体验，使得指南更加清晰和易于理解。

## articles/ai-services/openai/includes/connect-your-data-studio.md{#item-c34da8}

<details>
<summary>Diff</summary>
````diff
@@ -16,7 +16,7 @@ recommendations: false
 > [!TIP]
 > You can [use the Azure Developer CLI](../how-to/azure-developer-cli.md) to programmatically create the resources needed for Azure OpenAI On Your Data 
 
-Navigate to [Azure AI Foundry portal](https://ai.azure.com/) and sign-in with credentials that have access to your Azure OpenAI resource. 
+Navigate to [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and sign-in with credentials that have access to your Azure OpenAI resource. 
 
 1. You can either [create an Azure AI Foundry project](../../../ai-foundry/how-to/create-projects.md) by clicking **Create project**, or continue directly by clicking the button on the **Focused on Azure OpenAI in Azure AI Foundry Models** tile.  
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在“连接您的数据工作室”文档中，此次修改主要是更新了导航到 Azure AI Foundry 门户的链接。新的链接现在包含了 `cid=learnDocs` 参数，增强了用户访问相关文档时的体验。这一改动确保用户在登录时能够更容易地找到所需的信息和帮助，从而提升了整体使用体验。文档中还强调了用户可以通过 Azure Developer CLI 创建所需资源的方式，提供了进一步的操作指引。虽有少量的文本变更，但此更新增强了文档的一致性，提高了用户的导航效率和便利性。总体来看，这一调整旨在优化用户在使用 Azure OpenAI 服务时的体验。

## articles/ai-services/openai/includes/create-resource-portal.md{#item-cb2503}

<details>
<summary>Diff</summary>
````diff
@@ -96,7 +96,7 @@ Before you can generate text or inference, you need to deploy a model. You can s
 
 To deploy a model, follow these steps:
 
-1. Sign in to [Azure AI Foundry portal](https://ai.azure.com).
+1. Sign in to [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 
 2. Choose the subscription and the Azure OpenAI resource to work with, and select **Use resource**.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
该修改针对“创建资源门户”的文档，主要是对用户登录 Azure AI Foundry 门户的链接进行了更新。新的链接增加了 `cid=learnDocs` 参数，目的是提升用户在访问文档时的体验。通过这一更新，用户可以更便捷地找到相关的支持信息，有助于他们在登录后顺利进行模型部署。文档进一步指引用户选择相应的订阅和 Azure OpenAI 资源，并提供后续操作的清晰步骤。尽管修改的内容较小，但此次更新提高了文档的可用性与一致性，确保用户在使用 Azure OpenAI 服务时能够获得更好的指导和支持。

## articles/ai-services/openai/includes/dall-e-studio.md{#item-439729}

<details>
<summary>Diff</summary>
````diff
@@ -20,7 +20,7 @@ Use this guide to get started generating images with Azure OpenAI in your browse
 
 ## Go to Azure AI Foundry
 
-Browse to [Azure AI Foundry](https://ai.azure.com/) and sign in with the credentials associated with your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
+Browse to [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) and sign in with the credentials associated with your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
 
 From the Azure AI Foundry landing page, create or select a new project. Navigate to the **Models + endpoints** page on the left nav. Select **Deploy model** and then choose one of the DALL-E models from the list. Complete the deployment process. 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在“DALL·E 工作室”文档中，修改主要针对用户登录 Azure AI Foundry 门户的链接进行了调整。新的链接包含了 `cid=learnDocs` 参数，这一改动旨在改善用户在访问时的体验。更新后，用户可以更方便地找到相关的支持信息和文档，帮助他们在使用 Azure OpenAI 生成图像时更顺利。文档中还明确指引用户在登录后选择适当的目录、Azure 订阅以及 Azure OpenAI 资源，确保他们能顺利进行模型部署。虽然这次修改涉及的内容较小，但其目的是提升文档的可用性，从而更好地支持用户在使用 Azure OpenAI 服务的过程中获取必要的信息。

## articles/ai-services/openai/includes/fine-tuning-openai-in-ai-studio.md{#item-723c8d}

<details>
<summary>Diff</summary>
````diff
@@ -98,7 +98,7 @@ In general, doubling the dataset size can lead to a linear increase in model qua
 
 To fine-tune an Azure OpenAI model in an existing Azure AI Foundry project, follow these steps:
 
-1. Sign in to [Azure AI Foundry](https://ai.azure.com) and select your project. If you don't have a project already, first [create a project](../../../ai-foundry/how-to/create-projects.md).
+1. Sign in to [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) and select your project. If you don't have a project already, first [create a project](../../../ai-foundry/how-to/create-projects.md).
 
 1. From the collapsible left menu, select **Fine-tuning** > **+ Fine-tune model**.
 
@@ -212,7 +212,7 @@ You can monitor the progress of your deployment on the **Deployments** page in A
 
 ### Use a deployed fine-tuned model
 
-After your fine-tuned model deploys, you can use it like any other deployed model. You can use the **Playground** in [Azure AI Foundry](https://ai.azure.com) to experiment with your new deployment. You can also use the REST API to call your fine-tuned model from your own application. You can even begin to use this new fine-tuned model in your prompt flow to build your generative AI application.
+After your fine-tuned model deploys, you can use it like any other deployed model. You can use the **Playground** in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) to experiment with your new deployment. You can also use the REST API to call your fine-tuned model from your own application. You can even begin to use this new fine-tuned model in your prompt flow to build your generative AI application.
 
 > [!NOTE]
 > For chat models, the [system message that you use to guide your fine-tuned model](../concepts/system-message.md) (whether it's deployed or available for testing in the playground) must be the same as the system message you used for training. If you use a different system message, the model might not perform as expected.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在“在 AI Studio 中微调 OpenAI 的文档”中，进行了细微的更新，特别是在用户登录 Azure AI Foundry 门户的链接上。此修改引入了 `cid=learnDocs` 参数，目的是为了提升用户的访问体验，使他们在登录后更便捷地找到相关信息和支持。更新后的文档保持了大的结构不变，但在相关步骤中强调了用户如何选定项目以及如何微调模型。尽管改动的地方较小，文档依然清晰地指导用户完成微调过程，并确保用户可以在之后使用微调后的模型进行实验和应用。此外，链接的更新也有助于提供更好的用户支持和参考资料。

## articles/ai-services/openai/includes/fine-tuning-studio.md{#item-439f1e}

<details>
<summary>Diff</summary>
````diff
@@ -245,7 +245,7 @@ If you're ready to deploy for production or have particular data residency needs
 
 ### Use a deployed fine-tuned model
 
-After your fine-tuned model deploys, you can use it like any other deployed model. You can use the **Playground** in [Azure AI Foundry](https://ai.azure.com) to experiment with your new deployment. You can also use the REST API to call your fine-tuned model from your own application. You can even begin to use this new fine-tuned model in your prompt flow to build your generative AI application.
+After your fine-tuned model deploys, you can use it like any other deployed model. You can use the **Playground** in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) to experiment with your new deployment. You can also use the REST API to call your fine-tuned model from your own application. You can even begin to use this new fine-tuned model in your prompt flow to build your generative AI application.
 
 > [!NOTE]
 > For chat models, the [system message that you use to guide your fine-tuned model](../concepts/system-message.md) (whether it's deployed or available for testing in the playground) must be the same as the system message you used for training. If you use a different system message, the model might not perform as expected.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在“微调 Studio”文档中，对用户登录 Azure AI Foundry 的链接进行了小幅更新。此次修改在链接中添加了 `cid=learnDocs` 参数，以期优化用户的访问体验，使其在登录后更容易找到所需的信息和文档。更新内容保持了文档的整体结构不变，仍然清晰指示用户如何使用已部署的微调模型，包括利用 Playgrounds 进行实验，以及通过 REST API 调用其微调后的模型。这一更新虽然不大，但通过改善链接，有助于用户更顺利地进行生成 AI 应用的开发和测试。因此，这一修改对提升用户体验具有积极的影响。

## articles/ai-services/openai/includes/fine-tuning-unified.md{#item-718336}

<details>
<summary>Diff</summary>
````diff
@@ -14,7 +14,7 @@ ms.custom:
 
 There are two unique fine-tuning experiences in the Azure AI Foundry portal:
 
-* [Hub/Project view](https://ai.azure.com) - supports fine-tuning models from multiple providers including Azure OpenAI, Meta Llama, Microsoft Phi, etc.
+* [Hub/Project view](https://ai.azure.com/?cid=learnDocs) - supports fine-tuning models from multiple providers including Azure OpenAI, Meta Llama, Microsoft Phi, etc.
 * [Azure OpenAI centric view](https://ai.azure.com/resource/overview) - only supports fine-tuning Azure OpenAI models, but has support for additional features like the [Weights & Biases (W&B) preview integration](../how-to/weights-and-biases-integration.md). 
 
 If you are only fine-tuning Azure OpenAI models, we recommend the Azure OpenAI centric fine-tuning experience which is available by navigating to [https://ai.azure.com/resource/overview](https://ai.azure.com/resource/overview). 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在“统一微调”文档中，链接稍作修改，以增强用户对 Azure AI Foundry 门户的访问体验。具体来说，原有的 Hub/Project 视图链接被更新，添加了 `cid=learnDocs` 参数，这旨在帮助用户更便捷地获取相关文档支持。文档中仍然提到两种独特的微调体验：一种是支持多种模型提供者的 Hub/Project 视图，另一种是仅支持 Azure OpenAI 模型的 Azure OpenAI 专属视图。尽管改动不大，添加的参数可能会帮助用户获得更好的导航和帮助，使他们在微调模型的过程中能够顺利获取须知信息。这一更新，将有助于改善用户在 Azure 平台上的使用体验。

## articles/ai-services/openai/includes/gpt-v-studio.md{#item-dcd50e}

<details>
<summary>Diff</summary>
````diff
@@ -10,7 +10,7 @@ ms.custom: references_regions, ignite-2024
 ms.date: 01/29/2025
 ---
 
-Use this article to get started using [Azure AI Foundry](https://ai.azure.com) to deploy and test a chat completion model with image understanding. 
+Use this article to get started using [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) to deploy and test a chat completion model with image understanding. 
 
 
 ## Prerequisites
@@ -28,7 +28,7 @@ You need an image to complete this quickstart. You can use this sample image or
 
 ## Go to Azure AI Foundry
 
-1. Browse to [Azure AI Foundry](https://ai.azure.com/) and sign in with the credentials associated with your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
+1. Browse to [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) and sign in with the credentials associated with your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
 1. Select the project you'd like to work in.
 1. On the left nav menu, select **Models + endpoints** and select **+ Deploy model**.
 1. Choose an image-capable deployment by selecting model name: **gpt-4o** or **gpt-4o-mini**. In the window that appears, select a name and deployment type. Make sure your Azure OpenAI resource is connected. For more information about model deployment, see the [resource deployment guide](/azure/ai-services/openai/how-to/create-resource).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在“GPT-V Studio”文档中，对 Azure AI Foundry 的访问链接进行了小幅修改，添加了 `cid=learnDocs` 参数。这一更新使得用户在使用该链接时，能够更容易地找到相关的指导和文档。修改涉及到文档中关于如何开始使用 Azure AI Foundry 部署和测试具有图像理解能力的聊天完成模型的部分。此外，关于进入 Azure AI Foundry 的步骤说明中，链接同样进行了更新。这些调整旨在改善用户体验，确保用户能够在登录后的页面上更顺畅地获取信息，进一步简化他们在使用 Azure 服务过程中的操作。因此，虽然更改较小，但它们可能对用户的导航和信息获取产生积极影响。

## articles/ai-services/openai/includes/realtime-deploy-model.md{#item-21f911}

<details>
<summary>Diff</summary>
````diff
@@ -8,7 +8,7 @@ ms.date: 1/21/2025
 ---
 
 To deploy the `gpt-4o-mini-realtime-preview` model in the Azure AI Foundry portal:
-1. Go to the [Azure AI Foundry portal](https://ai.azure.com) and create or select your project. 
+1. Go to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and create or select your project. 
 1. Select **Models + endpoints** from under **My assets** in the left pane.
 1. Select **+ Deploy model** > **Deploy base model** to open the deployment window. 
 1. Search for and select the `gpt-4o-mini-realtime-preview` model and then select **Confirm**.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户的链接. Locale: zh_CN"
}
```

### Explanation
在“实时部署模型”文档中，对 Azure AI Foundry 门户的链接进行了细微的更新，原本的链接被替换为带有 `cid=learnDocs` 参数的链接。这一修改旨在增强用户在访问门户时获取相关文档支持的便利性。具体来说，文档指导用户如何在 Azure AI Foundry 门户中部署 `gpt-4o-mini-realtime-preview` 模型，最新的链接将连接到包含学习文档的页面，使用户在选择或创建项目后，能更轻松地获取必要的信息。虽然此次更改看似微小，但它能够提升用户体验，帮助他们在使用 Azure 服务时更有效地进行导航和获取支持。

## articles/ai-services/openai/includes/realtime-portal.md{#item-1b81a2}

<details>
<summary>Diff</summary>
````diff
@@ -13,9 +13,9 @@ ms.date: 3/20/2025
 
 ## Use the GPT-4o real-time audio
 
-To chat with your deployed `gpt-4o-mini-realtime-preview` model in the [Azure AI Foundry](https://ai.azure.com) **Real-time audio** playground, follow these steps:
+To chat with your deployed `gpt-4o-mini-realtime-preview` model in the [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) **Real-time audio** playground, follow these steps:
 
-1. Go to the [Azure AI Foundry portal](https://ai.azure.com) and select your project that has your deployed `gpt-4o-mini-realtime-preview` model.
+1. Go to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and select your project that has your deployed `gpt-4o-mini-realtime-preview` model.
 1. Select **Playgrounds** from the left pane.
 1. Select **Audio playground** > **Try the Audio playground**. 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在“实时门户”文档中，针对 Azure AI Foundry 的访问链接进行了小幅更新，新的链接中添加了 `cid=learnDocs` 参数。这项修改主要体现在有关如何使用部署的 `gpt-4o-mini-realtime-preview` 模型进行实时音频聊天的步骤说明中。在介绍用户如何通过 Azure AI Foundry 的 **实时音频** 沙盒进行聊天时，更新后的链接旨在帮助用户更便捷地获取相应的学习资料和支持。此次更改尽管是对链接的细微调整，但可以帮助用户更加顺畅地使用 Azure AI Foundry，提升他们在使用过程中的导航体验和信息获取效率。

## articles/ai-services/openai/includes/studio.md{#item-eeeaff}

<details>
<summary>Diff</summary>
````diff
@@ -39,7 +39,7 @@ In the Completions playground you can also view Python and curl code samples pre
 
 To use the Azure OpenAI for text summarization in the Completions playground, follow these steps:
 
-1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com).
+1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 1. Select the subscription and OpenAI resource to work with. 
 1. Select **Completions playground** on the landing page.
 1. Select your deployment from the **Deployments** dropdown. If your resource doesn't have a deployment, select **Create a deployment** and then revisit this step.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在“工作室”文档中，对 Azure AI Foundry 门户的登录链接进行了小幅更新，新的链接在末尾添加了 `cid=learnDocs` 参数。这一变更主要出现在关于如何在 Completions 沙盒中使用 Azure OpenAI 进行文本摘要的步骤说明中。用户在使用该功能前首先需要登录 Azure AI Foundry，此次更新的链接旨在为用户提供更便利的访问路径，以获取相关学习和支持资料。尽管该修改是一处小的调整，但它能有效提升用户使用 Azure 的体验，确保他们在登录后能更轻松地找到必要的信息以支持其操作。

## articles/ai-services/openai/overview.md{#item-97d507}

<details>
<summary>Diff</summary>
````diff
@@ -24,7 +24,7 @@ Azure OpenAI provides REST API access to OpenAI's powerful language models inclu
 | Price | [Available here](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) <br> For details on vision-enabled chat models, see the [special pricing information](../openai/concepts/gpt-with-vision.md#special-pricing-information).|
 | Virtual network support & private link support | Yes.  |
 | Managed Identity| Yes, via Microsoft Entra ID | 
-| UI experience | [Azure portal](https://portal.azure.com) for account & resource management, <br> [Azure AI Foundry](https://ai.azure.com) for model exploration and fine-tuning |
+| UI experience | [Azure portal](https://portal.azure.com) for account & resource management, <br> [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) for model exploration and fine-tuning |
 | Model regional availability | [Model availability](./concepts/models.md) |
 | Content filtering | Prompts and completions are evaluated against our content policy with automated systems. High severity content is filtered. |
 
@@ -41,7 +41,7 @@ Start with the [Create and deploy an Azure OpenAI resource](./how-to/create-reso
 1. When you have an Azure OpenAI resource, you can deploy a model such as GPT-4o.
 1. When you have a deployed model, you can:
 
-    - Try out the [Azure AI Foundry portal](https://ai.azure.com/) playgrounds to explore the capabilities of the models. 
+    - Try out the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) playgrounds to explore the capabilities of the models. 
     - You can also just start making API calls to the service using the REST API or SDKs.
     
     For example, you can try [real-time audio](./realtime-audio-quickstart.md) and [assistants](./assistants-quickstart.md) in the playgrounds or via code.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在“概述”文档中，对 Azure AI Foundry 门户的链接进行了细微调整，新增了 `cid=learnDocs` 参数。这项修改出现在关于用户界面体验的描述中，以及在介绍如何探索模型能力的步骤中。这一变更确保用户在尝试使用 Azure AI Foundry 的沙盒功能时，能够更方便地访问学习资源，以便获取更全面的支持和信息。这虽然是一次小的链接更新，但它提升了用户体验，帮助用户更加顺畅地使用 Azure 服务，获取所需的教程和指导。

## articles/ai-services/openai/quotas-limits.md{#item-06c6f9}

<details>
<summary>Diff</summary>
````diff
@@ -45,8 +45,8 @@ The following sections provide you with a quick guide to the default quotas and
 | Max number of `/chat/completions` functions | 128 |
 | Max number of `/chat completions` tools | 128 |
 | Maximum number of Provisioned throughput units per deployment | 100,000 |
-| Max files per Assistant/thread | 10,000 when using the API or [Azure AI Foundry portal](https://ai.azure.com/).|
-| Max file size for Assistants & fine-tuning | 512 MB<br/><br/>200 MB via [Azure AI Foundry portal](https://ai.azure.com/) |
+| Max files per Assistant/thread | 10,000 when using the API or [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).|
+| Max file size for Assistants & fine-tuning | 512 MB<br/><br/>200 MB via [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) |
 | Max size for all uploaded files for Assistants |200 GB |
 | Assistants token limit | 2,000,000 token limit |
 | GPT-4o max images per request (# of images in the messages array/conversation history) | 50 |
@@ -197,7 +197,7 @@ M = million | K = thousand
 
 ### gpt-4o audio
 
-The rate limits for each `gpt-4o` audio model deployment are 100 K TPM and 1 K RPM. During the preview, [Azure AI Foundry portal](https://ai.azure.com/) and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit is 100 K TPM and 1 K RPM.
+The rate limits for each `gpt-4o` audio model deployment are 100 K TPM and 1 K RPM. During the preview, [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit is 100 K TPM and 1 K RPM.
 
 | Model|Tier| Quota Limit in tokens per minute (TPM) | Requests per minute |
 |---|---|:---:|:---:|
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门口链接. Locale: zh_CN"
}
```

### Explanation
在“配额和限制”文档中，对 Azure AI Foundry 门户中的某些链接进行了小幅修改，添加了 `cid=learnDocs` 参数。这一变化出现在关于助手的最大文件数和文件大小的限制说明，以及关于 `gpt-4o` 音频模型部署的速率限制部分。通过这种更新，用户在引用 Azure AI Foundry 门户时，将能够更轻松地访问与学习和支持相关的内容，从而提升他们使用该平台的体验。这次更改虽然很小，但对用户而言，可以更方便地获得所需的资源和信息。

## articles/ai-services/openai/tutorials/fine-tune.md{#item-8f87b5}

<details>
<summary>Diff</summary>
````diff
@@ -34,7 +34,7 @@ In this tutorial you learn how to:
 - [Jupyter Notebooks](https://jupyter.org/)
 - An Azure OpenAI resource in a [region where `gpt-4o-mini-2024-07-18` fine-tuning is available](../concepts/models.md). If you don't have a resource the process of creating one is documented in our resource [deployment guide](../how-to/create-resource.md).
 - Fine-tuning access requires **Cognitive Services OpenAI Contributor**.
-- If you don't already have access to view quota and deploy models in [Azure AI Foundry portal](https://ai.azure.com/), then you need [more permissions](../how-to/role-based-access-control.md).
+- If you don't already have access to view quota and deploy models in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), then you need [more permissions](../how-to/role-based-access-control.md).
 
 > [!IMPORTANT]
 > We recommend reviewing the [pricing information](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/#pricing) for fine-tuning to familiarize yourself with the associated costs. Testing of this tutorial resulted in 48,000 tokens being billed (4,800 training tokens * 10 epochs of training). Training costs are in addition to the costs that are associated with fine-tuning inference, and the hourly hosting costs of having a fine-tuned model deployed. Once you have completed the tutorial, you should delete your fine-tuned model deployment otherwise you continue to incur the hourly hosting cost.
@@ -694,7 +694,7 @@ fine_tuned_model = response.fine_tuned_model
 
 Unlike the previous Python SDK commands in this tutorial, since the introduction of the quota feature, model deployment must be done using the [REST API](/rest/api/aiservices/accountmanagement/deployments/create-or-update?tabs=HTTP), which requires separate authorization, a different API path, and a different API version.
 
-Alternatively, you can deploy your fine-tuned model using any of the other common deployment methods like [Azure AI Foundry portal](https://ai.azure.com/), or [Azure CLI](/cli/azure/cognitiveservices/account/deployment#az-cognitiveservices-account-deployment-create()).
+Alternatively, you can deploy your fine-tuned model using any of the other common deployment methods like [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), or [Azure CLI](/cli/azure/cognitiveservices/account/deployment#az-cognitiveservices-account-deployment-create()).
 
 |variable      | Definition|
 |--------------|-----------|
@@ -745,13 +745,13 @@ print(r.reason)
 print(r.json())
 ```
 
-You can check on your deployment progress in the [Azure AI Foundry portal](https://ai.azure.com/).
+You can check on your deployment progress in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 
 It isn't uncommon for this process to take some time to complete when dealing with deploying fine-tuned models.
 
 ## Use a deployed customized model
 
-After your fine-tuned model is deployed, you can use it like any other deployed model in either the [Chat Playground of Azure AI Foundry portal](https://ai.azure.com), or via the chat completion API. For example, you can send a chat completion call to your deployed model, as shown in the following Python example. You can continue to use the same parameters with your customized model, such as temperature and max_tokens, as you can with other deployed models.
+After your fine-tuned model is deployed, you can use it like any other deployed model in either the [Chat Playground of Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), or via the chat completion API. For example, you can send a chat completion call to your deployed model, as shown in the following Python example. You can continue to use the same parameters with your customized model, such as temperature and max_tokens, as you can with other deployed models.
 
 ```python
 # Use the deployed customized model
@@ -784,7 +784,7 @@ Unlike other types of Azure OpenAI models, fine-tuned/customized models have [an
 
 Deleting the deployment won't affect the model itself, so you can re-deploy the fine-tuned model that you trained for this tutorial at any time.
 
-You can delete the deployment in [Azure AI Foundry portal](https://ai.azure.com/), via [REST API](/rest/api/aiservices/accountmanagement/deployments/delete?tabs=HTTP), [Azure CLI](/cli/azure/cognitiveservices/account/deployment#az-cognitiveservices-account-deployment-delete()), or other supported deployment methods.
+You can delete the deployment in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), via [REST API](/rest/api/aiservices/accountmanagement/deployments/delete?tabs=HTTP), [Azure CLI](/cli/azure/cognitiveservices/account/deployment#az-cognitiveservices-account-deployment-delete()), or other supported deployment methods.
 
 ## Troubleshooting
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接. Locale: zh_CN"
}
```

### Explanation
在“微调”教程的文档中，涉及到 Azure AI Foundry 门户的链接进行了小幅度的调整，添加了 `cid=learnDocs` 参数。这一修改出现在关于获取权限、检查部署进度，以及通过 Azure AI Foundry 门户使用微调模型的说明部分。通过这种更新，用户在访问门户时将更直接地链接到学习资源，增加了用户获得信息的便利性。这些更改虽然看似微小，但它们改善了用户体验，并帮助用户在进行微调模型的过程中更轻松地导航相关文档和资源。

## articles/ai-services/openai/whats-new.md{#item-53303b}

<details>
<summary>Diff</summary>
````diff
@@ -141,7 +141,7 @@ The `gpt-4o-realtime-preview` model version 2024-12-17 is available for global d
 
 - Added support for [prompt caching](./how-to/prompt-caching.md) with the `gpt-4o-realtime-preview` model.
 - Added support for new voices. The `gpt-4o-realtime-preview` models now support the following voices: "alloy", "ash", "ballad", "coral", "echo", "sage", "shimmer", "verse".
-- Rate limits are no longer based on connections per minute. Rate limiting is now based on RPM (requests per minute) and TPM (tokens per minute) for the `gpt-4o-realtime-preview` model. The rate limits for each `gpt-4o-realtime-preview` model deployment are 100K TPM and 1K RPM. During the preview, [Azure AI Foundry portal](https://ai.azure.com/) and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit will be 100K TPM and 1K RPM.
+- Rate limits are no longer based on connections per minute. Rate limiting is now based on RPM (requests per minute) and TPM (tokens per minute) for the `gpt-4o-realtime-preview` model. The rate limits for each `gpt-4o-realtime-preview` model deployment are 100K TPM and 1K RPM. During the preview, [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit will be 100K TPM and 1K RPM.
 
 For more information, see the [GPT-4o real-time audio quickstart](realtime-audio-quickstart.md) and the [how-to guide](./how-to/realtime-audio.md).
 
@@ -271,7 +271,7 @@ Global batch now supports GPT-4o (2024-08-06). See the [global batch getting sta
 
 ### Azure OpenAI Studio UX updates
 
-As of September 19, 2024, when you go to the [Azure OpenAI Studio](https://oai.azure.com/) you no longer see the legacy Azure OpenAI Studio by default. If needed you'll still be able to go back to the previous experience by using the **Switch to the old look** toggle in the top bar of the UI for the next couple of weeks. If you switch back to legacy [Azure AI Foundry portal](https://ai.azure.com/), it helps if you fill out the feedback form to let us know why. We're actively monitoring this feedback to improve the new experience.
+As of September 19, 2024, when you go to the [Azure OpenAI Studio](https://oai.azure.com/) you no longer see the legacy Azure OpenAI Studio by default. If needed you'll still be able to go back to the previous experience by using the **Switch to the old look** toggle in the top bar of the UI for the next couple of weeks. If you switch back to legacy [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), it helps if you fill out the feedback form to let us know why. We're actively monitoring this feedback to improve the new experience.
 
 
 ### GPT-4o 2024-08-06 provisioned deployments
@@ -314,7 +314,7 @@ OpenAI has incorporated additional safety measures into the `o1` models, includi
 
 ### Availability
 
-The `o1-preview` and `o1-mini` are available in the East US2 region for limited access through the [Azure AI Foundry portal](https://ai.azure.com) early access playground. Data processing for the `o1` models might occur in a different region than where they're available for use.
+The `o1-preview` and `o1-mini` are available in the East US2 region for limited access through the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) early access playground. Data processing for the `o1` models might occur in a different region than where they're available for use.
 
 To try the `o1-preview` and `o1-mini` models in the early access playground **registration is required, and access will be granted based on Microsoft’s eligibility criteria.**
 
@@ -372,7 +372,7 @@ On August 6, 2024, OpenAI [announced](https://openai.com/index/introducing-struc
 
 Azure customers can test out GPT-4o `2024-08-06` today in the new Azure AI Foundry early access playground (preview).
 
-Unlike the previous early access playground, the [Azure AI Foundry portal](https://ai.azure.com/) early access playground (preview) doesn't require you to have a resource in a specific region.
+Unlike the previous early access playground, the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) early access playground (preview) doesn't require you to have a resource in a specific region.
 
 > [!NOTE]
 > Prompts and completions made through the early access playground (preview) might be processed in any Azure OpenAI region, and are currently subject to a 10 request per minute per Azure subscription limit. This limit might change in the future.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新 Azure AI Foundry 门户链接，增加学习资源访问. Locale: zh_CN"
}
```

### Explanation
在“最新动态”文档中，关于 Azure AI Foundry 门户部分的链接进行了小幅修改，增加了 `cid=learnDocs` 参数。这项修改出现在有关速率限制、使用 Azure OpenAI Studio 的说明以及对特定模型可用性的描述中。这一更新的主要目的是帮助用户更方便地访问与学习相关的资源，提升用户体验和信息获取的效率。尽管更改的内容相对简单，但它有效地引导用户发现更多的学习支持信息，从而提高了使用 Azure AI 的便利性和整体满意度。


