---
date: '2025-06-04'
permalink: https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:8d764d4...MicrosoftDocs:45b2d74
summary: This report highlights a minor update to documentation for Azure OpenAI services,
  focusing on improving user engagement analytics. A new tracking parameter has been
  added to URLs that direct users to the Azure AI Foundry portal, allowing for better
  tracking of interactions with the documentation. The functionality of the documentation
  remains unchanged, but consistency has been improved with field name changes in
  one document. No new features or breaking changes were introduced in this update.
  The primary goal is to enhance understanding of user interactions by collecting
  more detailed analytics, ultimately improving user experience and documentation
  effectiveness within the Azure ecosystem.
title: '[en_US] Diff Insight Report - openai'

---

[View Diff on GitHub](https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:8d764d4...MicrosoftDocs:45b2d74){target="_blank"}

# Highlights
The code diff illustrates a comprehensive minor update across various documentation files related to Azure OpenAI services. The update primarily focuses on enhancing analytics by adding a tracking parameter (`?cid=learnDocs`) to URLs linking to the Azure AI Foundry portal. The documentation remains functionally consistent but now includes improved user engagement tracking. Additionally, one document has had field name changes to improve consistency.

## New features
- No new features were introduced in this update.

## Breaking changes
- No breaking changes were introduced.

## Other updates
- Added a tracking parameter (`?cid=learnDocs`) to numerous hypertext links directing users to the Azure AI Foundry portal, enhancing the ability to track engagement with the documentation.
- Renamed fields in the 'reinforcement-fine-tuning.md' to improve consistency.

# Insights
The primary goal of this series of updates is to enhance tracking and understanding of user interactions with the Azure AI Foundry portal through documentation links. By appending a tracking parameter to URLs, the Azure documentation team can accumulate more detailed analytics, offering insights into how frequently and extensively users engage with portal links provided in the documentation.

The addition of tracking parameters across the board ensures that traffic analysis can be applied consistently, aiding understanding of user habits and informing potential improvements in navigation and resource allocation. This approach aligns with best practices in web analytics, which prioritize the acquisition of actionable insights into user behavior.

Furthermore, the rename of fields in the 'reinforcement-fine-tuning.md' serves to refine the clarity and consistency of terminology used in the documentation, making it easier for users to understand and apply the guidelines provided. These updates are slated to bolster the documentation’s utility without detracting from the underlying content and instructions.

Overall, these minor updates signify a strategic effort to improve the user experience by leveraging enhanced analytics capabilities. This adjustment will enable more targeted efforts to refine documentation based on concrete data, ultimately aiming to enhance user satisfaction and resource efficacy within the Azure ecosystem.

# Summary Table
|  Filename  | Type |    Title    | Status | A  | D  | M  |
|------------|------|-------------|--------|----|----|----|
| [assistants.md](#item-eab970) | minor update | Update Assistants API Link with Tracking Parameters | modified | 1 | 1 | 2 | 
| [content-streaming.md](#item-f10e15) | minor update | Update Azure AI Foundry Portal Link with Tracking Parameters | modified | 2 | 2 | 4 | 
| [gpt-4-v-prompt-engineering.md](#item-fd7772) | minor update | Update Azure AI Foundry Playground Link with Tracking Parameters | modified | 1 | 1 | 2 | 
| [gpt-with-vision.md](#item-991388) | minor update | Update Azure AI Foundry Portal Links with Tracking Parameters | modified | 3 | 3 | 6 | 
| [provisioned-migration.md](#item-68e143) | minor update | Update Azure AI Foundry Portal Link with Tracking Parameters | modified | 1 | 1 | 2 | 
| [safety-system-message-templates.md](#item-460532) | minor update | Update Azure AI Foundry Portal Link with Tracking Parameters | modified | 1 | 1 | 2 | 
| [use-your-data.md](#item-455d6e) | minor update | Update Azure AI Foundry Portal Link with Tracking Parameters | modified | 15 | 15 | 30 | 
| [faq.yml](#item-6deb71) | minor update | Update Azure AI Foundry Portal Links with Tracking Parameters | modified | 10 | 10 | 20 | 
| [batch.md](#item-a131d5) | minor update | Update Azure AI Foundry Portal Links with Tracking Parameters | modified | 2 | 2 | 4 | 
| [completions.md](#item-79f39a) | minor update | Add Tracking Parameter to Azure AI Foundry Link | modified | 1 | 1 | 2 | 
| [dall-e.md](#item-ac9616) | minor update | Clarification on Input Image Format for Image Edit API | modified | 1 | 1 | 2 | 
| [evaluations.md](#item-dfaa1c) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Link | modified | 1 | 1 | 2 | 
| [fine-tune-test.md](#item-48f1b6) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Link | modified | 1 | 1 | 2 | 
| [fine-tuning-deploy.md](#item-286d57) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Link | modified | 1 | 1 | 2 | 
| [model-router.md](#item-eebd7e) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Link | modified | 1 | 1 | 2 | 
| [monitor-openai.md](#item-fcba4d) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Link | modified | 1 | 1 | 2 | 
| [on-your-data-configuration.md](#item-4875d3) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Links | modified | 8 | 8 | 16 | 
| [provisioned-get-started.md](#item-c8df1c) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Links | modified | 4 | 4 | 8 | 
| [provisioned-throughput-onboarding.md](#item-3eb72b) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Links | modified | 2 | 2 | 4 | 
| [quota.md](#item-9440c2) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Links | modified | 3 | 3 | 6 | 
| [reinforcement-fine-tuning.md](#item-e8028c) | minor update | Rename Fields in Grader Model Parameters | modified | 2 | 2 | 4 | 
| [risks-safety-monitor.md](#item-b2be0b) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Links | modified | 3 | 3 | 6 | 
| [role-based-access-control.md](#item-4b9817) | minor update | Add Tracking Parameter to Azure AI Foundry Links | modified | 11 | 11 | 22 | 
| [stored-completions.md](#item-ccc7e6) | minor update | Add Tracking Parameter to Azure AI Foundry Links | modified | 3 | 3 | 6 | 
| [use-blocklists.md](#item-e99db7) | minor update | Add Tracking Parameter to Azure AI Foundry Link | modified | 1 | 1 | 2 | 
| [use-web-app.md](#item-802413) | minor update | Add Tracking Parameter to Azure AI Foundry Links | modified | 9 | 9 | 18 | 
| [weights-and-biases-integration.md](#item-8ae868) | minor update | Add Tracking Parameter to Azure AI Foundry Link | modified | 1 | 1 | 2 | 
| [work-with-code.md](#item-b193c2) | minor update | Add Tracking Parameter to Azure AI Foundry Playground Link | modified | 1 | 1 | 2 | 
| [working-with-models.md](#item-7ec098) | minor update | Add Tracking Parameter to Azure AI Foundry Links | modified | 3 | 3 | 6 | 
| [audio-completions-ai-foundry.md](#item-748538) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Links | modified | 3 | 3 | 6 | 
| [audio-completions-deploy-model.md](#item-c5a63e) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Link | modified | 1 | 1 | 2 | 
| [batch-studio.md](#item-d4822e) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Link | modified | 1 | 1 | 2 | 
| [chatgpt-studio.md](#item-ab43f3) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Link | modified | 1 | 1 | 2 | 
| [connect-your-data-studio.md](#item-c34da8) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Link | modified | 1 | 1 | 2 | 
| [create-resource-portal.md](#item-cb2503) | minor update | Add Tracking Parameter to Azure AI Foundry Portal Link | modified | 1 | 1 | 2 | 
| [dall-e-studio.md](#item-439729) | minor update | Add Tracking Parameter to Azure AI Foundry Link | modified | 1 | 1 | 2 | 
| [fine-tuning-openai-in-ai-studio.md](#item-723c8d) | minor update | Add Tracking Parameter to Azure AI Foundry Links | modified | 2 | 2 | 4 | 
| [fine-tuning-studio.md](#item-439f1e) | minor update | Add Tracking Parameter to Azure AI Foundry Link | modified | 1 | 1 | 2 | 
| [fine-tuning-unified.md](#item-718336) | minor update | Add Tracking Parameter to Hub/Project View Link | modified | 1 | 1 | 2 | 
| [gpt-v-studio.md](#item-dcd50e) | minor update | Add Tracking Parameter to Azure AI Foundry Links | modified | 2 | 2 | 4 | 
| [realtime-deploy-model.md](#item-21f911) | minor update | Add Tracking Parameter to Azure AI Foundry Link | modified | 1 | 1 | 2 | 
| [realtime-portal.md](#item-1b81a2) | minor update | Add Tracking Parameter to Azure AI Foundry Links in Real-time Portal | modified | 2 | 2 | 4 | 
| [studio.md](#item-eeeaff) | minor update | Add Tracking Parameter to Azure AI Foundry Link in Studio Guide | modified | 1 | 1 | 2 | 
| [overview.md](#item-97d507) | minor update | Add Tracking Parameter to Azure AI Foundry Links in Overview Document | modified | 2 | 2 | 4 | 
| [quotas-limits.md](#item-06c6f9) | minor update | Add Tracking Parameter to Azure AI Foundry Links in Quotas and Limits Document | modified | 3 | 3 | 6 | 
| [fine-tune.md](#item-8f87b5) | minor update | Add Tracking Parameter to Azure AI Foundry Links in Fine-Tuning Tutorial | modified | 5 | 5 | 10 | 
| [whats-new.md](#item-53303b) | minor update | Add Tracking Parameter to Links in 'What's New' Document | modified | 4 | 4 | 8 | 


# Modified Contents
## articles/ai-services/openai/concepts/assistants.md{#item-eab970}

<details>
<summary>Diff</summary>
````diff
@@ -35,7 +35,7 @@ Assistants API supports persistent automatically managed threads. This means tha
 > [!TIP]
 > There is no additional [pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) or [quota](../quotas-limits.md) for using Assistants unless you use the [code interpreter](../how-to/code-interpreter.md) or [file search](../how-to/file-search.md) tools.
 
-Assistants API is built on the same capabilities that power OpenAI’s GPT product. Some possible use cases range from AI-powered product recommender, sales analyst app, coding assistant, employee Q&A chatbot, and more. Start building on the no-code Assistants playground on the [Azure AI Foundry portal](https://ai.azure.com/) or start building with the API.
+Assistants API is built on the same capabilities that power OpenAI’s GPT product. Some possible use cases range from AI-powered product recommender, sales analyst app, coding assistant, employee Q&A chatbot, and more. Start building on the no-code Assistants playground on the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) or start building with the API.
 
 > [!IMPORTANT]
 > Retrieving untrusted data using Function calling, Code Interpreter or File Search with file input, and Assistant Threads functionalities could compromise the security of your Assistant, or the application that uses the Assistant. Learn about mitigation approaches [here](https://aka.ms/oai/assistant-rai).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Assistants API Link with Tracking Parameters"
}
```

### Explanation
The code diff reflects a minor update made to the 'assistants.md' file within the AI Services documentation. The modification consists of a single addition and a single deletion, resulting in two changes overall. Specifically, the update involves a change in the URL linked to the "Azure AI Foundry portal." The original URL has been modified to include a tracking parameter (`?cid=learnDocs`), which is likely intended to help track the source of traffic to that page. This update does not alter any functionality but serves to improve analytics on user engagement with the documentation. The content preceding and following the change remains the same, ensuring that the core information provided about the Assistants API and its capabilities remains intact.

## articles/ai-services/openai/concepts/content-streaming.md{#item-f10e15}

<details>
<summary>Diff</summary>
````diff
@@ -30,15 +30,15 @@ Customers must understand that while the feature improves latency, it's a trade-
 
 **Customer Copyright Commitment**: Content that is retroactively flagged as protected material might not be eligible for Customer Copyright Commitment coverage. 
 
-To enable Asynchronous Filter in [Azure AI Foundry portal](https://ai.azure.com/), follow the [Content filter how-to guide](/azure/ai-services/openai/how-to/content-filters) to create a new content filtering configuration, and select **Asynchronous Filter** in the Streaming section.
+To enable Asynchronous Filter in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), follow the [Content filter how-to guide](/azure/ai-services/openai/how-to/content-filters) to create a new content filtering configuration, and select **Asynchronous Filter** in the Streaming section.
 
 ## Comparison of content filtering modes
 
 | Compare | Streaming - Default | Streaming - Asynchronous Filter |
 |---|---|---|
 |Status |GA |Public Preview |
 | Eligibility |All customers |Customers approved for modified content filtering |
-| How to enable | Enabled by default, no action needed |Customers approved for modified content filtering can configure it directly in [Azure AI Foundry portal](https://ai.azure.com/) (as part of a content filtering configuration, applied at the deployment level) |
+| How to enable | Enabled by default, no action needed |Customers approved for modified content filtering can configure it directly in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) (as part of a content filtering configuration, applied at the deployment level) |
 |Modality and availability |Text; all GPT models |Text; all GPT models |
 |Streaming experience |Content is buffered and returned in chunks |Zero latency (no buffering, filters run asynchronously) |
 |Content filtering signal |Immediate filtering signal |Delayed filtering signal (in up to ~1,000-character increments) |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Azure AI Foundry Portal Link with Tracking Parameters"
}
```

### Explanation
The code diff showcases a minor update made to the 'content-streaming.md' file related to content streaming features in Azure AI services. The modification includes two additions and two deletions, resulting in a total of four changes. The primary focus of the changes is the linkage to the Azure AI Foundry portal, which has been updated to include a tracking parameter (`?cid=learnDocs`) in the URL. 

This adjustment enables better tracking of traffic to the portal from the documentation. Additionally, the section that details how to enable the Asynchronous Filter has been updated to ensure consistency in how the portal is referenced throughout the document. While the overall structure and information about content filtering modes remain unchanged, this update aims to enhance monitoring and analytics capabilities associated with user engagement.

## articles/ai-services/openai/concepts/gpt-4-v-prompt-engineering.md{#item-fd7772}

<details>
<summary>Diff</summary>
````diff
@@ -27,7 +27,7 @@ To unlock the full potential of vision-enabled chat models, it's essential to ta
 - **Define output format:** Clearly mention the desired format for the output, such as markdown, JSON, HTML, etc. You can also suggest a specific structure, length, or specific attributes about the response.
 
 ## Example prompt inputs and outputs
-There are many ways to craft system prompts to tailor the output specifically to your needs. The following sample inputs and outputs showcase how adjusting your prompts can give you different results. Try out the model for yourself using these images and adjusting the system prompt in the [Azure AI Foundry playground](https://ai.azure.com/).
+There are many ways to craft system prompts to tailor the output specifically to your needs. The following sample inputs and outputs showcase how adjusting your prompts can give you different results. Try out the model for yourself using these images and adjusting the system prompt in the [Azure AI Foundry playground](https://ai.azure.com/?cid=learnDocs).
 
 ### Contextual specificity  
 Context can help improve feedback from the model. For example, if you're working on image descriptions for a product catalog, ensure your prompt reflects that in a clear and concise way. A prompt like “Describe images for an outdoor hiking product catalog, focusing on enthusiasm and professionalism” guides the model to generate responses that are both accurate and contextually rich.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Azure AI Foundry Playground Link with Tracking Parameters"
}
```

### Explanation
The code diff indicates a minor update to the 'gpt-4-v-prompt-engineering.md' file, focusing on how to effectively craft prompts for vision-enabled chat models. This modification includes two changes: the addition of a tracking parameter in the URL pointing to the Azure AI Foundry playground. 

The original URL has been modified to include `?cid=learnDocs`, which aids in tracking user engagement with the content. This update occurs in the context of providing examples of how to craft system prompts, reinforcing the practical application of the guidelines described in the document. The overall aim of the change is to enhance analytics without altering the substantive content regarding prompt engineering.

## articles/ai-services/openai/concepts/gpt-with-vision.md{#item-991388}

<details>
<summary>Diff</summary>
````diff
@@ -29,7 +29,7 @@ This section describes the limitations of vision-enabled chat models.
 
 - **Maximum input image size**: The maximum size for input images is restricted to 20 MB.
 - **Low resolution accuracy**: When images are analyzed using the "low resolution" setting, it allows for faster responses and uses fewer input tokens for certain use cases. However, this could impact the accuracy of object and text recognition within the image.
-- **Image chat restriction**: When you upload images in [Azure AI Foundry portal](https://ai.azure.com/) or the API, there is a limit of 10 images per chat call.
+- **Image chat restriction**: When you upload images in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) or the API, there is a limit of 10 images per chat call.
 
 ## Special pricing information
 
@@ -84,8 +84,8 @@ Additionally, there's a one-time indexing cost of $0.15 to generate the Video Re
 ### Video support
 
 - **Low resolution**: Video frames are analyzed using GPT-4 Turbo with Vision's "low resolution" setting, which may affect the accuracy of small object and text recognition in the video.
-- **Video file limits**: Both MP4 and MOV file types are supported. In [Azure AI Foundry portal](https://ai.azure.com/), videos must be less than 3 minutes long. When you use the API there is no such limitation.
-- **Prompt limits**: Video prompts only contain one video and no images. In [Azure AI Foundry portal](https://ai.azure.com/), you can clear the session to try another video or images.
+- **Video file limits**: Both MP4 and MOV file types are supported. In [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), videos must be less than 3 minutes long. When you use the API there is no such limitation.
+- **Prompt limits**: Video prompts only contain one video and no images. In [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you can clear the session to try another video or images.
 - **Limited frame selection**: The service selects 20 frames from the entire video, which might not capture all the critical moments or details. Frame selection can be approximately evenly spread through the video or focused by a specific video retrieval query, depending on the prompt.
 - **Language support**: The service primarily supports English for grounding with transcripts. Transcripts don't provide accurate information on lyrics in songs.
 -->
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Azure AI Foundry Portal Links with Tracking Parameters"
}
```

### Explanation
The code diff reflects a minor update to the 'gpt-with-vision.md' file, which discusses the limitations of vision-enabled chat models. The changes include three additions and three deletions, resulting in six changes overall. A key modification in this update is the addition of a tracking parameter (`?cid=learnDocs`) to the URLs linking to the Azure AI Foundry portal.

This change is applied to sections detailing image and video restrictions, specifically indicating limits on the number of images per chat call and video file characteristics. The update aims to improve monitoring of user engagement with the documentation without altering the overall content or context of the guidelines provided. The goal is to ensure that analytics efforts can be better aligned with user interactions on the Azure platform.

## articles/ai-services/openai/concepts/provisioned-migration.md{#item-68e143}

<details>
<summary>Diff</summary>
````diff
@@ -260,7 +260,7 @@ Azure Reservations for Azure OpenAI provisioned offers are specific to the provi
 
 ## Managing Provisioned Throughput Commitments
 
-Provisioned throughput commitments are created and managed by selecting **Management center** in the [Azure AI Foundry portal](https://ai.azure.com/)'s navigation menu > **Quota** > **Manage Commitments**. 
+Provisioned throughput commitments are created and managed by selecting **Management center** in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)'s navigation menu > **Quota** > **Manage Commitments**. 
 
 :::image type="content" source="../media/how-to/provisioned-onboarding/notifications.png" alt-text="Screenshot of commitment purchase UI with notifications." lightbox="../media/how-to/provisioned-onboarding/notifications.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Azure AI Foundry Portal Link with Tracking Parameters"
}
```

### Explanation
The code diff represents a minor update to the 'provisioned-migration.md' file, which discusses managing provisioned throughput commitments for Azure OpenAI services. In this modification, a tracking parameter (`?cid=learnDocs`) has been added to the URL linking to the Azure AI Foundry portal. 

This change improves the ability to track user engagement with the documentation without affecting the content or instructions provided within the section. The updated link allows for a clearer understanding of how users interact with the Azure portal's management features, specifically for managing throughput commitments. Overall, the goal of this update is to enhance analytics while maintaining the integrity of the existing content.

## articles/ai-services/openai/concepts/safety-system-message-templates.md{#item-460532}

<details>
<summary>Diff</summary>
````diff
@@ -31,7 +31,7 @@ Below are examples of recommended system message components you can include to p
 
 ## Add safety system messages in Azure AI Foundry portal 
 
-The following steps show how to leverage safety system messages in [Azure AI Foundry portal](https://ai.azure.com/).
+The following steps show how to leverage safety system messages in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 
 1. Go to Azure AI Foundry and navigate to Azure OpenAI and the Chat playground.
     :::image type="content" source="../media/navigate-chat-playground.PNG" alt-text="Screenshot of the Azure AI Foundry portal selection.":::
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Azure AI Foundry Portal Link with Tracking Parameters"
}
```

### Explanation
The code diff indicates a minor update to the 'safety-system-message-templates.md' file, which provides guidance on utilizing safety system messages within the Azure AI Foundry portal. In this update, a tracking parameter (`?cid=learnDocs`) has been appended to the URL leading to the Azure AI Foundry portal.

This modification enables better tracking of user interactions with the documentation while ensuring that the instructions on leveraging safety system messages remain intact and clear. Adding this tracking parameter aids in understanding how users engage with the portal, specifically regarding safety features, without changing the tutorial's content or intent. Overall, the aim of this update is to enhance analytics capabilities while preserving the existing guidance for users.

## articles/ai-services/openai/concepts/use-your-data.md{#item-455d6e}

<details>
<summary>Diff</summary>
````diff
@@ -18,14 +18,14 @@ Use this article to learn about Azure OpenAI On Your Data, which makes it easier
 
 ## What is Azure OpenAI On Your Data
 
-Azure OpenAI On Your Data enables you to run advanced AI models such as GPT-35-Turbo and GPT-4 on your own enterprise data without needing to train or fine-tune models. You can chat on top of and analyze your data with greater accuracy. You can specify sources to support the responses based on the latest information available in your designated data sources. You can access Azure OpenAI On Your Data using a REST API, via the SDK or the web-based interface in the [Azure AI Foundry portal](https://ai.azure.com/). You can also create a web app that connects to your data to enable an enhanced chat solution or deploy it directly as a copilot in the Copilot Studio (preview).
+Azure OpenAI On Your Data enables you to run advanced AI models such as GPT-35-Turbo and GPT-4 on your own enterprise data without needing to train or fine-tune models. You can chat on top of and analyze your data with greater accuracy. You can specify sources to support the responses based on the latest information available in your designated data sources. You can access Azure OpenAI On Your Data using a REST API, via the SDK or the web-based interface in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). You can also create a web app that connects to your data to enable an enhanced chat solution or deploy it directly as a copilot in the Copilot Studio (preview).
 
 ## Developing with Azure OpenAI On Your Data
 
 :::image type="content" source="../media/use-your-data/workflow-diagram.png" alt-text="A diagram showing an example workflow.":::
 
 Typically, the development process you'd use with Azure OpenAI On Your Data is:
-1. **Ingest**: Upload files using either [Azure AI Foundry portal](https://ai.azure.com/) or the ingestion API. This enables your data to be cracked, chunked and embedded into an Azure AI Search instance that can be used by Azure OpenAI models. If you have an existing [supported data source](#supported-data-sources), you can also connect it directly.
+1. **Ingest**: Upload files using either [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) or the ingestion API. This enables your data to be cracked, chunked and embedded into an Azure AI Search instance that can be used by Azure OpenAI models. If you have an existing [supported data source](#supported-data-sources), you can also connect it directly.
 
 1. **Develop**: After trying Azure OpenAI On Your Data, begin developing your application using the available REST API and SDKs, which are available in several languages. It will create prompts and search intents to pass to the Azure OpenAI service.
 
@@ -38,7 +38,7 @@ Typically, the development process you'd use with Azure OpenAI On Your Data is:
     
     1. **Response generation**: The resulting data is submitted along with other information like the system message to the Large Language Model (LLM) and the response is sent back to the application.
 
-To get started, [connect your data source](../use-your-data-quickstart.md) using [Azure AI Foundry portal](https://ai.azure.com/) and start asking questions and chatting on your data.
+To get started, [connect your data source](../use-your-data-quickstart.md) using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and start asking questions and chatting on your data.
 
 ## Azure Role-based access controls (Azure RBAC) for adding data sources
 
@@ -139,7 +139,7 @@ Azure OpenAI On Your Data lets you restrict the documents that can be used in re
 
 ### Index field mapping 
 
-If you're using your own index, you'll be prompted in the [Azure AI Foundry portal](https://ai.azure.com/) to define which fields you want to map for answering questions when you add your data source. You can provide multiple fields for *Content data*, and should include all fields that have text pertaining to your use case. 
+If you're using your own index, you'll be prompted in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) to define which fields you want to map for answering questions when you add your data source. You can provide multiple fields for *Content data*, and should include all fields that have text pertaining to your use case. 
 
 :::image type="content" source="../media/use-your-data/index-data-mapping.png" alt-text="A screenshot showing the index field mapping options in Azure AI Foundry portal." lightbox="../media/use-your-data/index-data-mapping.png":::
 
@@ -192,7 +192,7 @@ You might want to use Azure Blob Storage as a data source if you want to connect
 
 To keep your Azure AI Search index up-to-date with your latest data, you can schedule an automatic index refresh rather than manually updating it every time your data is updated. Automatic index refresh is only available when you choose **Azure Blob Storage** as the data source. To enable an automatic index refresh:
 
-1. [Add a data source](../quickstart.md) using [Azure AI Foundry portal](https://ai.azure.com/).
+1. [Add a data source](../quickstart.md) using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 1. Under **Select or add data source** select **Indexer schedule** and choose the refresh cadence you would like to apply.
 
     :::image type="content" source="../media/use-your-data/indexer-schedule.png" alt-text="A screenshot of the indexer schedule in Azure AI Foundry portal." lightbox="../media/use-your-data/indexer-schedule.png":::
@@ -224,7 +224,7 @@ To modify the schedule, you can use the [Azure portal](https://portal.azure.com/
 
 # [Upload files (preview)](#tab/file-upload)
 
-Using [Azure AI Foundry portal](https://ai.azure.com/), you can upload files from your machine to try Azure OpenAI On Your Data. You also have the option to create a new Azure Blob Storage account and Azure AI Search resource. The service then stores the files to an Azure storage container and performs ingestion from the container. You can use the [quickstart](../use-your-data-quickstart.md) article to learn how to use this data source option.
+Using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you can upload files from your machine to try Azure OpenAI On Your Data. You also have the option to create a new Azure Blob Storage account and Azure AI Search resource. The service then stores the files to an Azure storage container and performs ingestion from the container. You can use the [quickstart](../use-your-data-quickstart.md) article to learn how to use this data source option.
 
 :::image type="content" source="../media/quickstarts/add-your-data-source.png" alt-text="A screenshot showing options for selecting a data source in Azure AI Foundry portal." lightbox="../media/quickstarts/add-your-data-source.png":::
 
@@ -308,11 +308,11 @@ Mapping these fields correctly helps ensure the model has better response and ci
 
 ### Use Elasticsearch as a data source via API  
 
-Along with using Elasticsearch databases in [Azure AI Foundry portal](https://ai.azure.com/), you can also use your Elasticsearch database using the [API](../references/elasticsearch.md). 
+Along with using Elasticsearch databases in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you can also use your Elasticsearch database using the [API](../references/elasticsearch.md). 
 
 # [MongoDB Atlas (preview)](#tab/mongo-db-atlas)
 
-You can connect your MongoDB Atlas vector index with Azure OpenAI On Your Data for inferencing. You can use it through the [Azure AI Foundry portal](https://ai.azure.com/), API and SDK.
+You can connect your MongoDB Atlas vector index with Azure OpenAI On Your Data for inferencing. You can use it through the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), API and SDK.
 
 ### Prerequisites 
 
@@ -363,15 +363,15 @@ When you add your MongoDB Atlas data source, you can specify data fields to prop
 
 ## Deploy to a copilot (preview), Teams app (preview), or web app 
 
-After you connect Azure OpenAI to your data, you can deploy it using the **Deploy to** button in [Azure AI Foundry portal](https://ai.azure.com/).
+After you connect Azure OpenAI to your data, you can deploy it using the **Deploy to** button in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 
 :::image type="content" source="../media/use-your-data/deploy-model.png" alt-text="A screenshot showing the model deployment button in Azure AI Foundry portal." lightbox="../media/use-your-data/deploy-model.png":::
 
 This gives you multiple options for deploying your solution.
 
 #### [Copilot (preview)](#tab/copilot)
 
-You can deploy to a copilot in [Copilot Studio](/microsoft-copilot-studio/fundamentals-what-is-copilot-studio) (preview) directly from [Azure AI Foundry portal](https://ai.azure.com/), enabling you to bring conversational experiences to various channels such as: Microsoft Teams, websites, Dynamics 365, and other [Azure Bot Service channels](/microsoft-copilot-studio/publication-connect-bot-to-azure-bot-service-channels). The tenant used in the Azure OpenAI and Copilot Studio (preview) should be the same. For more information, see [Use a connection to Azure OpenAI On Your Data](/microsoft-copilot-studio/nlu-generative-answers-azure-openai).
+You can deploy to a copilot in [Copilot Studio](/microsoft-copilot-studio/fundamentals-what-is-copilot-studio) (preview) directly from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), enabling you to bring conversational experiences to various channels such as: Microsoft Teams, websites, Dynamics 365, and other [Azure Bot Service channels](/microsoft-copilot-studio/publication-connect-bot-to-azure-bot-service-channels). The tenant used in the Azure OpenAI and Copilot Studio (preview) should be the same. For more information, see [Use a connection to Azure OpenAI On Your Data](/microsoft-copilot-studio/nlu-generative-answers-azure-openai).
 
 > [!NOTE]
 > Deploying to a copilot in Copilot Studio (preview) is only available in US regions.
@@ -393,15 +393,15 @@ A Teams app lets you bring conversational experience to your users in Teams to i
 - Your Azure account has been assigned **Cognitive Services OpenAI user** or **Cognitive Services OpenAI Contributor** role of the Azure OpenAI resource you're using, allowing your account to make Azure OpenAI API calls. For more information, see [Azure OpenAI On Your data configuration](../how-to/on-your-data-configuration.md#using-the-api) and [Add role assignment to an Azure OpenAI resource](/azure/ai-services/openai/how-to/role-based-access-control#add-role-assignment-to-an-azure-openai-resource) for instructions on setting this role in the Azure portal. 
 
 
-You can deploy to a standalone Teams app directly from [Azure AI Foundry portal](https://ai.azure.com/). Follow the steps below: 
+You can deploy to a standalone Teams app directly from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). Follow the steps below: 
 
 1. After you've added your data to the chat model, select **Deploy** and then **a new Teams app (preview)**. 
 
 1. Enter the name of your Teams app and download the resulting .zip file.
 
 1. Extract the .zip file and open the folder in Visual Studio Code.
 
-1. If you chose **API key** in the data connection step, manually copy and paste your Azure AI Search key into the `src\prompts\chat\config.json` file. Your Azure AI Search Key can be found in [Azure AI Foundry portal](https://ai.azure.com/) Playground by selecting the **View code** button with the key located under Azure Search Resource Key. If you chose **System assigned managed identity**, you can skip this step. Learn more about different data connection options in the [Data connection](/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search#data-connection) section.
+1. If you chose **API key** in the data connection step, manually copy and paste your Azure AI Search key into the `src\prompts\chat\config.json` file. Your Azure AI Search Key can be found in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) Playground by selecting the **View code** button with the key located under Azure Search Resource Key. If you chose **System assigned managed identity**, you can skip this step. Learn more about different data connection options in the [Data connection](/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search#data-connection) section.
 
 1. Open the Visual Studio Code terminal and log into Azure CLI, selecting the account that you assigned **Cognitive Service OpenAI User** role to. Use the `az login` command in the terminal to log in.
 
@@ -467,7 +467,7 @@ A small chunk size like 256 produces more granular chunks. This size also means
 
 ### Runtime parameters
 
-You can modify the following additional settings in the **Data parameters** section in [Azure AI Foundry portal](https://ai.azure.com/) and [the API](../references/on-your-data.md). You don't need to reingest your data when you update these parameters. 
+You can modify the following additional settings in the **Data parameters** section in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and [the API](../references/on-your-data.md). You don't need to reingest your data when you update these parameters. 
 
 
 |Parameter name  | Description  |
@@ -484,7 +484,7 @@ It's possible for the model to return `"TYPE":"UNCITED_REFERENCE"` instead of `"
 
 You can define a system message to steer the model's reply when using Azure OpenAI On Your Data. This message allows you to customize your replies on top of the retrieval augmented generation (RAG) pattern that Azure OpenAI On Your Data uses. The system message is used in addition to an internal base prompt to provide the experience. To support this, we truncate the system message after a specific [number of tokens](#token-usage-estimation-for-azure-openai-on-your-data) to ensure the model can answer questions using your data. If you are defining extra behavior on top of the default experience, ensure that your system prompt is detailed and explains the exact expected customization. 
 
-Once you select add your dataset, you can use the **System message** section in the [Azure AI Foundry portal](https://ai.azure.com/), or the `role_information` [parameter in the API](../references/on-your-data.md).
+Once you select add your dataset, you can use the **System message** section in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), or the `role_information` [parameter in the API](../references/on-your-data.md).
 
 :::image type="content" source="../media/use-your-data/system-message.png" alt-text="A screenshot showing the system message option in Azure AI Foundry portal." lightbox="../media/use-your-data/system-message.png":::
 
@@ -679,7 +679,7 @@ token_output = TokenEstimator.estimate_tokens(input_text)
 
 ## Troubleshooting 
 
-To troubleshoot failed operations, always look out for errors or warnings specified either in the API response or [Azure AI Foundry portal](https://ai.azure.com/). Here are some of the common errors and warnings: 
+To troubleshoot failed operations, always look out for errors or warnings specified either in the API response or [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). Here are some of the common errors and warnings: 
 
 ### Failed ingestion jobs
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Azure AI Foundry Portal Link with Tracking Parameters"
}
```

### Explanation
The code diff reflects a minor update to the 'use-your-data.md' file, which outlines how to use Azure OpenAI with your own data. The primary change involves adding a tracking parameter (`?cid=learnDocs`) to various links directing users to the Azure AI Foundry portal.

This update enhances the tracking capabilities of user engagement with the portal without altering the instructional content of the document. Each instance where the portal link appears has been modified to ensure that developers and users can still access resources effectively while providing insights into user interactions with the documentation. The focus remains on using Azure OpenAI On Your Data, making this modification a seamless integration with existing guidelines and recommendations. Overall, the changes aim to improve the analytical understanding of how users interact with the service while maintaining the clarity and usefulness of the instructions provided.

## articles/ai-services/openai/faq.yml{#item-6deb71}

<details>
<summary>Diff</summary>
````diff
@@ -125,19 +125,19 @@ sections:
         answer: |
           A Limited Access registration form is not required to access most Azure OpenAI models. Learn more on the [Azure OpenAI Limited Access page](/legal/cognitive-services/openai/limited-access?context=/azure/ai-services/openai/context/context).
       - question: |
-          My guest account has been given access to an Azure OpenAI resource, but I'm unable to access that resource in the [Azure AI Foundry portal](https://ai.azure.com/). How do I enable access?
+          My guest account has been given access to an Azure OpenAI resource, but I'm unable to access that resource in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). How do I enable access?
         answer: | 
-          This is expected behavior when using the default sign-in experience for the [Azure AI Foundry](https://ai.azure.com).
+          This is expected behavior when using the default sign-in experience for the [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs).
           
           To access Azure AI Foundry from a guest account that has been granted access to an Azure OpenAI resource:
           
-          1. Open a private browser session and then navigate to [https://ai.azure.com](https://ai.azure.com).
+          1. Open a private browser session and then navigate to [https://ai.azure.com](https://ai.azure.com/?cid=learnDocs).
           2. Rather than immediately entering your guest account credentials instead select `Sign-in options` 
           3. Now select **Sign in to an organization** 
           4. Enter the domain name of the organization that granted your guest account access to the Azure OpenAI resource. 
           5. Now sign-in with your guest account credentials. 
           
-          You should now be able to access the resource via the [Azure AI Foundry portal](https://ai.azure.com/).
+          You should now be able to access the resource via the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
           
           Alternatively if you're signed into the [Azure portal](https://portal.azure.com) from the Azure OpenAI resource's Overview pane you can select **Go to Azure AI Foundry** to automatically sign in with the appropriate organizational context.   
   
@@ -175,7 +175,7 @@ sections:
         answer:
           We do offer an Availability SLA for all resources and a Latency SLA for Provisioned-Managed Deployments. For more information about the SLA for Azure OpenAI Service, see the [Service Level Agreements (SLA) for Online Services page](https://azure.microsoft.com/support/legal/sla/cognitive-services/v1_1/). 
       - question: |
-          How do I enable fine-tuning? Create a custom model is greyed out in [Azure AI Foundry portal](https://ai.azure.com/).  
+          How do I enable fine-tuning? Create a custom model is greyed out in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).  
         answer: |
           In order to successfully access fine-tuning, you need Cognitive Services OpenAI Contributor assigned. Even someone with high-level Service Administrator permissions would still need this account explicitly set in order to access fine-tuning. For more information, please review the [role-based access control guidance](/azure/ai-services/openai/how-to/role-based-access-control#cognitive-services-openai-contributor).
       - question: |
@@ -304,9 +304,9 @@ sections:
         answer:
           You can customize your published web app in the Azure portal. The source code for the published web app is [available on GitHub](https://go.microsoft.com/fwlink/?linkid=2244395), where you can find information on changing the app frontend, as well as instructions for building and deploying the app.
       - question: |
-          Will my web app be overwritten when I deploy the app again from the [Azure AI Foundry portal](https://ai.azure.com/)?
+          Will my web app be overwritten when I deploy the app again from the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)?
         answer:
-          Your app code won't be overwritten when you update your app. The app will be updated to use the Azure OpenAI resource, Azure AI Search index (if you're using Azure OpenAI on your data), and model settings selected in the [Azure AI Foundry portal](https://ai.azure.com/) without any change to the appearance or functionality. 
+          Your app code won't be overwritten when you update your app. The app will be updated to use the Azure OpenAI resource, Azure AI Search index (if you're using Azure OpenAI on your data), and model settings selected in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) without any change to the appearance or functionality. 
   - name: Using your data
     questions:
       - question: |
@@ -316,15 +316,15 @@ sections:
       - question: |
           How can I access Azure OpenAI on your data?  
         answer:
-          All Azure OpenAI customers can use Azure OpenAI on your data via the [Azure AI Foundry portal](https://ai.azure.com/) and Rest API.
+          All Azure OpenAI customers can use Azure OpenAI on your data via the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and Rest API.
       - question: |
           What data sources does Azure OpenAI on your data support?
         answer:
           Azure OpenAI on your data supports ingestion from Azure AI Search, Azure Blob Storage, and uploading local files. You can learn more about Azure OpenAI on your data from the [conceptual article](./concepts/use-your-data.md) and [quickstart](./use-your-data-quickstart.md).
       - question: |
           How much does it cost to use Azure OpenAI on your data?
         answer:
-          When using Azure OpenAI on your data, you incur costs when you use Azure AI Search, Azure Blob Storage, Azure Web App Service, semantic search and OpenAI models. There's no additional cost for using the "your data" feature in the [Azure AI Foundry portal](https://ai.azure.com/).
+          When using Azure OpenAI on your data, you incur costs when you use Azure AI Search, Azure Blob Storage, Azure Web App Service, semantic search and OpenAI models. There's no additional cost for using the "your data" feature in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
       - question: |
           How can I customize or automate the index creation process?
         answer:
@@ -354,7 +354,7 @@ sections:
         answer:
           You must send queries in the same language of your data. Your data can be in any of the languages supported by [Azure AI Search](/azure/search/search-language-support).
       - question: |
-          If Semantic Search is enabled for my Azure AI Search resource, will it be automatically applied to Azure OpenAI on your data in the [Azure AI Foundry portal](https://ai.azure.com/)?
+          If Semantic Search is enabled for my Azure AI Search resource, will it be automatically applied to Azure OpenAI on your data in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)?
         answer:
           When you select "Azure AI Search" as the data source, you can choose to apply semantic search. 
           If you select "Azure Blob Container" or "Upload files" as the data source, you can create the index as usual. Afterwards you would reingest the data using the "Azure AI Search" option to select the same index and apply Semantic Search. You will then be ready to chat on your data with semantic search applied.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Azure AI Foundry Portal Links with Tracking Parameters"
}
```

### Explanation
The code diff shows a minor update to the 'faq.yml' file that contains frequently asked questions about Azure OpenAI. The modification involves adding a tracking parameter (`?cid=learnDocs`) to several links pointing to the Azure AI Foundry portal. 

This tracking parameter is designed to improve analytics capabilities by allowing the documentation team to better monitor user engagement and interactions with the portal. Each link that refers to the Azure AI Foundry portal has been updated to include this parameter, ensuring that users still have clear access to the resources while enhancing the documentation's performance tracking. Overall, the change does not alter the meaning or functionality of the FAQs but instead aims to provide better insights into how users access and utilize the guidance provided.

## articles/ai-services/openai/how-to/batch.md{#item-a131d5}

<details>
<summary>Diff</summary>
````diff
@@ -91,7 +91,7 @@ The following aren't currently supported:
 ### Batch deployment
 
 > [!NOTE]
-> In the [Azure AI Foundry portal](https://ai.azure.com/) the batch deployment types will appear as `Global-Batch` and `Data Zone Batch`. To learn more about Azure OpenAI deployment types, see our [deployment types guide](../how-to/deployment-types.md).
+> In the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) the batch deployment types will appear as `Global-Batch` and `Data Zone Batch`. To learn more about Azure OpenAI deployment types, see our [deployment types guide](../how-to/deployment-types.md).
 
 :::image type="content" source="../media/how-to/global-batch/global-batch.png" alt-text="Screenshot that shows the model deployment dialog in Azure AI Foundry portal with Global-Batch deployment type highlighted." lightbox="../media/how-to/global-batch/global-batch.png":::
 
@@ -163,7 +163,7 @@ Yes. Similar to other deployment types, you can create content filters and assoc
 
 ### Can I request additional quota?
 
-Yes, from the quota page in the [Azure AI Foundry portal](https://ai.azure.com/). Default quota allocation can be found in the [quota and limits article](../quotas-limits.md#batch-quota).
+Yes, from the quota page in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). Default quota allocation can be found in the [quota and limits article](../quotas-limits.md#batch-quota).
 
 ### What happens if the API doesn't complete my request within the 24 hour time frame?
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Update Azure AI Foundry Portal Links with Tracking Parameters"
}
```

### Explanation
The code diff represents a minor update to the 'batch.md' file, which provides instructions on batch deployment for Azure OpenAI. The primary change involves adding a tracking parameter (`?cid=learnDocs`) to links referencing the Azure AI Foundry portal.

This addition is intended to enhance tracking capabilities, enabling the documentation team to analyze user engagement more effectively. Both instances of the Azure AI Foundry portal links have been adjusted to include this parameter, allowing users to access the relevant resources while also contributing to better data collection regarding portal usage. The content and context of the document remain unchanged, focusing on batch deployment types and quota requests, while the tracking updates aim to optimize the documentation's analytical insights.

## articles/ai-services/openai/how-to/completions.md{#item-79f39a}

<details>
<summary>Diff</summary>
````diff
@@ -19,7 +19,7 @@ Azure OpenAI in Azure AI Foundry Models provides a **completion endpoint** that
 > [!IMPORTANT]
 > Unless you have a specific use case that requires the completions endpoint, we recommend instead using the [responses API](./responses.md) of [chat completions endpoint](./chatgpt.md) which allows you to take advantage of the latest models like GPT-4o, GPT-4o mini, and GPT-4 Turbo. 
 
-The best way to start exploring completions is through the playground in [Azure AI Foundry](https://ai.azure.com). It's a simple text box where you enter a prompt to generate a completion. You can start with a simple prompt like this one:
+The best way to start exploring completions is through the playground in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs). It's a simple text box where you enter a prompt to generate a completion. You can start with a simple prompt like this one:
 
 ```console
 write a tagline for an ice cream shop
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Link"
}
```

### Explanation
The code diff showcases a minor update to the 'completions.md' file, which explains how to use the completion endpoint in Azure OpenAI. The change consists of adding a tracking parameter (`?cid=learnDocs`) to a link that points to the Azure AI Foundry portal.

This parameter enhances the ability to monitor user engagement with the link, allowing the documentation team to gather insights on how users are accessing and utilizing the completions feature. The rest of the content remains the same, promoting the playground tool in the Azure AI Foundry for experimenting with completions. This modification does not alter the functionality or information provided but improves the documentation's analytical capabilities regarding usage patterns.

## articles/ai-services/openai/how-to/dall-e.md{#item-ac9616}

<details>
<summary>Diff</summary>
````diff
@@ -237,7 +237,7 @@ The format in which DALL-E 3 generated images are returned. Must be one of `url`
 
 ## Call the Image Edit API
 
-The Image Edit API allows you to modify existing images based on text prompts you provide. The API call is similar to the image generation API call, but you also need to provide an image URL or base 64-encoded image data.
+The Image Edit API allows you to modify existing images based on text prompts you provide. The API call is similar to the image generation API call, but you also need to provide an input image (base64-encoded image data).
 
 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Clarification on Input Image Format for Image Edit API"
}
```

### Explanation
The code diff indicates a minor update to the 'dall-e.md' file, which describes the functionalities of the DALL-E 3 Image Edit API. The specific change involves refining the language used to describe the required input for the API call. 

Originally, the text stated that an image URL or base64-encoded image data needs to be provided for the Image Edit API. The update clarifies this by changing the wording to specify that the API requires an "input image" in the form of "base64-encoded image data." 

This adjustment helps eliminate ambiguity regarding the expected input format, ensuring that users understand they should provide base64-encoded data rather than just a URL. Overall, the change enhances the accuracy and clarity of the documentation without altering any functionality.

## articles/ai-services/openai/how-to/evaluations.md{#item-dfaa1c}

<details>
<summary>Diff</summary>
````diff
@@ -135,7 +135,7 @@ When you click into each testing criteria, you will see different types of grade
 
 ## Getting started
 
-1. Select the **Azure OpenAI Evaluation (PREVIEW)** within [Azure AI Foundry portal](https://ai.azure.com/). To see this view as an option may need to first select an existing Azure OpenAI resource in a supported region.
+1. Select the **Azure OpenAI Evaluation (PREVIEW)** within [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). To see this view as an option may need to first select an existing Azure OpenAI resource in a supported region.
 2. Select **+ New evaluation**
 
     :::image type="content" source="../media/how-to/evaluations/new-evaluation.png" alt-text="Screenshot of the Azure OpenAI evaluation UX with new evaluation selected." lightbox="../media/how-to/evaluations/new-evaluation.png":::
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Link"
}
```

### Explanation
The code diff presents a minor update to the 'evaluations.md' file, which provides instructions for working with the Azure OpenAI Evaluation feature in the Azure AI Foundry portal. The change specifically adds a tracking parameter (`?cid=learnDocs`) to the URL linking to the Azure AI Foundry portal.

This modification aims to enhance the documentation's tracking capabilities, allowing the team to monitor user engagement with the link more effectively. The rest of the content remains unchanged, providing clear instructions on how to access the evaluation feature after selecting an existing Azure OpenAI resource in a supported region. This adjustment does not affect the functionality or usability of the documentation, but it improves analytics on user interactions with the portal link.

## articles/ai-services/openai/how-to/fine-tune-test.md{#item-48f1b6}

<details>
<summary>Diff</summary>
````diff
@@ -146,7 +146,7 @@ az cognitiveservices account deployment create
 
 ## [Portal](#tab/portal)
 
-After your custom model deploys, you can use it like any other deployed model. You can use the **Playgrounds** in the [Azure AI Foundry portal](https://ai.azure.com) to experiment with your new deployment. You can continue to use the same parameters with your custom model, such as `temperature` and `max_tokens`, as you can with other deployed models.
+After your custom model deploys, you can use it like any other deployed model. You can use the **Playgrounds** in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) to experiment with your new deployment. You can continue to use the same parameters with your custom model, such as `temperature` and `max_tokens`, as you can with other deployed models.
 
 :::image type="content" source="../media/fine-tuning/chat-playground.png" alt-text="Screenshot of the Playground pane in Azure AI Foundry portal, with sections highlighted." lightbox="../media/fine-tuning/chat-playground.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Link"
}
```

### Explanation
The code diff reflects a minor update made to the 'fine-tune-test.md' file, which guides users on utilizing custom models in the Azure AI Foundry portal. The change involves adding a tracking parameter (`?cid=learnDocs`) to the URL that links to the Azure AI Foundry portal.

This adjustment is intended to improve the documentation's tracking of user interactions with the link, allowing for better insights into how users engage with the resource. The rest of the content remains intact, continuing to provide instructions on using the **Playgrounds** feature for experimenting with custom model deployments, including instructions regarding parameters such as `temperature` and `max_tokens`. This update enhances analytics capabilities without changing the functionality or usability of the documentation.

## articles/ai-services/openai/how-to/fine-tuning-deploy.md{#item-286d57}

<details>
<summary>Diff</summary>
````diff
@@ -305,7 +305,7 @@ az cognitiveservices account deployment create
 
 ## [Portal](#tab/portal)
 
-After your custom model deploys, you can use it like any other deployed model. You can use the **Playgrounds** in the [Azure AI Foundry portal](https://ai.azure.com) to experiment with your new deployment. You can continue to use the same parameters with your custom model, such as `temperature` and `max_tokens`, as you can with other deployed models.
+After your custom model deploys, you can use it like any other deployed model. You can use the **Playgrounds** in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) to experiment with your new deployment. You can continue to use the same parameters with your custom model, such as `temperature` and `max_tokens`, as you can with other deployed models.
 
 :::image type="content" source="../media/quickstarts/playground-load-new.png" alt-text="Screenshot of the Playground pane in Azure AI Foundry portal, with sections highlighted." lightbox="../media/quickstarts/playground-load-new.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Link"
}
```

### Explanation
The code diff shows a minor update to the 'fine-tuning-deploy.md' file, which outlines how to deploy custom AI models in the Azure AI Foundry portal. The update specifically adds a tracking parameter (`?cid=learnDocs`) to the URL leading to the Azure AI Foundry portal.

This modification is intended to enhance tracking and analytics capabilities regarding user interactions with the link, allowing the documentation team to gain better insights into user engagement. The rest of the text remains unchanged, continuing to provide guidance on using the **Playgrounds** feature for experimentation with deployed models, while also mentioning the parameters such as `temperature` and `max_tokens`. This change serves to improve documentation effectiveness without altering the existing instructions or functionality.

## articles/ai-services/openai/how-to/model-router.md{#item-eebd7e}

<details>
<summary>Diff</summary>
````diff
@@ -32,7 +32,7 @@ Model router is packaged as a single Azure AI Foundry model that you deploy. Fol
 
 You can use model router through the [chat completions API](/azure/ai-services/openai/chatgpt-quickstart) in the same way you'd use other OpenAI chat models. Set the `model` parameter to the name of our model router deployment, and set the `messages` parameter to the messages you want to send to the model.
 
-In the [Azure AI Foundry portal](https://ai.azure.com/), you can navigate to your model router deployment on the **Models + endpoints** page and select it to enter the model playground. In the playground experience, you can enter messages and see the model's responses. Each response message shows which underlying model was selected to respond.
+In the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you can navigate to your model router deployment on the **Models + endpoints** page and select it to enter the model playground. In the playground experience, you can enter messages and see the model's responses. Each response message shows which underlying model was selected to respond.
 
 
 > [!IMPORTANT]
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Link"
}
```

### Explanation
The code diff presents a minor update to the 'model-router.md' file, which provides information on using the model router feature within the Azure AI Foundry environment. The modification involves adding a tracking parameter (`?cid=learnDocs`) to the link directing users to the Azure AI Foundry portal.

This adjustment aims to enhance the tracking of user interactions with the documentation, providing insights into how users engage with the portal link. The remainder of the content remains largely unchanged, continuing to explain how to use the model router through the chat completions API, including navigation instructions to the model playground where users can input messages and receive responses. By implementing this change, the documentation improves its analytics capabilities while maintaining clarity and usability for the users.

## articles/ai-services/openai/how-to/monitor-openai.md{#item-fcba4d}

<details>
<summary>Diff</summary>
````diff
@@ -74,7 +74,7 @@ After you configure the diagnostic settings, you can work with metrics and log d
 
 [!INCLUDE [horz-monitor-kusto-queries](~/reusable-content/ce-skilling/azure/includes/azure-monitor/horizontals/horz-monitor-kusto-queries.md)]
 
-After you deploy an Azure OpenAI model, you can send some completions calls by using the **playground** environment in [Azure AI Foundry](https://ai.azure.com/).
+After you deploy an Azure OpenAI model, you can send some completions calls by using the **playground** environment in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs).
 
 Any text that you enter in the **Completions playground** or the **Chat completions playground** generates metrics and log data for your Azure OpenAI resource. In the Log Analytics workspace for your resource, you can query the monitoring data by using the [Kusto](/azure/data-explorer/kusto/query/) query language.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Link"
}
```

### Explanation
The code diff reflects a minor update to the 'monitor-openai.md' file, which provides guidance on monitoring Azure OpenAI models. The specific change involves the addition of a tracking parameter (`?cid=learnDocs`) to the link that directs users to the Azure AI Foundry portal.

This enhancement is aimed at improving the tracking of user interactions with the documentation, thereby providing better insights into how frequently the portal link is accessed. The rest of the content retains its original instructional purpose, explaining how to use the **playground** environment to send completion calls after deploying an Azure OpenAI model. Additionally, it highlights the generation of metrics and log data from user interactions in the playground and discusses querying this data using the Kusto query language in the Log Analytics workspace. Overall, this modification enhances tracking capabilities while preserving the clarity of the documentation.

## articles/ai-services/openai/how-to/on-your-data-configuration.md{#item-4875d3}

<details>
<summary>Diff</summary>
````diff
@@ -164,7 +164,7 @@ This step can be skipped only if you have a [shared private link](#create-shared
 
 You can disable public network access of your Azure OpenAI resource in the Azure portal. 
 
-To allow access to your Azure OpenAI from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/), you need to create [private endpoint connections](/azure/ai-services/cognitive-services-virtual-networks?tabs=portal#use-private-endpoints) that connect to your Azure OpenAI resource.
+To allow access to your Azure OpenAI from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you need to create [private endpoint connections](/azure/ai-services/cognitive-services-virtual-networks?tabs=portal#use-private-endpoints) that connect to your Azure OpenAI resource.
 
 
 ## Configure Azure AI Search
@@ -188,7 +188,7 @@ For more information, see the [Azure AI Search RBAC article](/azure/search/searc
 
 You can disable public network access of your Azure AI Search resource in the Azure portal. 
 
-To allow access to your Azure AI Search resource from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/), you need to create [private endpoint connections](/azure/search/service-create-private-endpoint) that connect to your Azure AI Search resource.
+To allow access to your Azure AI Search resource from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you need to create [private endpoint connections](/azure/search/service-create-private-endpoint) that connect to your Azure AI Search resource.
 
 
 ### Enable trusted service
@@ -242,7 +242,7 @@ In the Azure portal, navigate to your storage account networking tab, choose "Se
 
 You can disable public network access of your Storage Account in the Azure portal. 
 
-To allow access to your Storage Account from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/), you need to create [private endpoint connections](/azure/storage/common/storage-private-endpoints) that connect to your blob storage.
+To allow access to your Storage Account from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), you need to create [private endpoint connections](/azure/storage/common/storage-private-endpoints) that connect to your blob storage.
 
 
 
@@ -271,9 +271,9 @@ To enable the developers to use these resources to build applications, the admin
 
 |Role| Resource | Description |
 |--|--|--|
-| `Cognitive Services OpenAI Contributor` | Azure OpenAI | Call public ingestion API from [Azure AI Foundry portal](https://ai.azure.com/). The `Contributor` role is not enough, because if you only have `Contributor` role, you cannot call data plane API via Microsoft Entra ID authentication, and Microsoft Entra ID authentication is required in the secure setup described in this article. |
-| `Contributor` | Azure AI Search | List API-Keys to list indexes from [Azure AI Foundry portal](https://ai.azure.com/).|
-| `Contributor` | Storage Account | List Account SAS to upload files from [Azure AI Foundry portal](https://ai.azure.com/).|
+| `Cognitive Services OpenAI Contributor` | Azure OpenAI | Call public ingestion API from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). The `Contributor` role is not enough, because if you only have `Contributor` role, you cannot call data plane API via Microsoft Entra ID authentication, and Microsoft Entra ID authentication is required in the secure setup described in this article. |
+| `Contributor` | Azure AI Search | List API-Keys to list indexes from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).|
+| `Contributor` | Storage Account | List Account SAS to upload files from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).|
 | `Contributor` | The resource group or Azure subscription where the developer need to deploy the web app to | Deploy web app to the developer's Azure subscription.|
 | `Role Based Access Control Administrator` | Azure OpenAI | Permission to configure the necessary role assignment on the Azure OpenAI resource. Enables the web app to call Azure OpenAI. |
 
@@ -297,7 +297,7 @@ Configure your local machine `hosts` file to point your resources host names to
 
 ## Azure AI Foundry portal
 
-You should be able to use all [Azure AI Foundry portal](https://ai.azure.com/) features, including both ingestion and inference, from your on-premises client machines.
+You should be able to use all [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) features, including both ingestion and inference, from your on-premises client machines.
 
 ## Web app
 The web app communicates with your Azure OpenAI resource. Since your Azure OpenAI resource has public network disabled, the web app needs to be set up to use the private endpoint in your virtual network to access your Azure OpenAI resource.
@@ -308,7 +308,7 @@ The web app needs to resolve your Azure OpenAI host name to the private IP of th
 1. [Add a DNS record](/azure/dns/private-dns-getstarted-portal#create-an-additional-dns-record). The IP is the private IP of the private endpoint for your Azure OpenAI resource, and you can get the IP address from the network interface associated with the private endpoint for your Azure OpenAI.
 1. [Link the private DNS zone to your virtual network](/azure/dns/private-dns-getstarted-portal#link-the-virtual-network) so the web app integrated in this virtual network can use this private DNS zone.
 
-When deploying the web app from [Azure AI Foundry portal](https://ai.azure.com/), select the same location with the virtual network, and select a proper SKU, so it can support the [virtual network integration feature](/azure/app-service/overview-vnet-integration). 
+When deploying the web app from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), select the same location with the virtual network, and select a proper SKU, so it can support the [virtual network integration feature](/azure/app-service/overview-vnet-integration). 
 
 After the web app is deployed, from the Azure portal networking tab, configure the web app outbound traffic virtual network integration, choose the third subnet that you reserved for web app.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Links"
}
```

### Explanation
The code diff represents a minor update to the 'on-your-data-configuration.md' file, which outlines the necessary configurations for securely accessing Azure AI resources. The key change involves the addition of a tracking parameter (`?cid=learnDocs`) to various links directing users to the Azure AI Foundry portal throughout the document.

This modification enhances the ability to track user engagement with the documentation, allowing for better analysis of how frequently these links are accessed. The context of the document remains intact, providing guidance on setting up private endpoint connections for Azure OpenAI, Azure AI Search, and Storage Accounts to enable access from client machines while maintaining security.

Additionally, the update affects references to roles and responsibilities when utilizing these services, ensuring users have the correct permissions when accessing features through the Azure AI Foundry portal. Overall, the modification aims to improve tracking capabilities for the documentation while ensuring that the instructional content remains clear and relevant for users.

## articles/ai-services/openai/how-to/provisioned-get-started.md{#item-c8df1c}

<details>
<summary>Diff</summary>
````diff
@@ -36,7 +36,7 @@ Creating a new deployment requires available (unused) quota to cover the desired
 
 Then 200 PTUs of quota are considered used, and there are 300 PTUs available for use to create new deployments. 
 
-A default amount of global, data zone, and regional provisioned quota is assigned to eligible subscriptions in several regions. You can view the quota available to you in a region by visiting the Quotas pane in [Azure AI Foundry portal](https://ai.azure.com/) and selecting the desired subscription and region. For example, the screenshot below shows a quota limit of 500 PTUs in West US for the selected subscription. Note that you might see lower values of available default quotas. 
+A default amount of global, data zone, and regional provisioned quota is assigned to eligible subscriptions in several regions. You can view the quota available to you in a region by visiting the Quotas pane in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and selecting the desired subscription and region. For example, the screenshot below shows a quota limit of 500 PTUs in West US for the selected subscription. Note that you might see lower values of available default quotas. 
 
 :::image type="content" source="../media/provisioned/available-quota.png" alt-text="A screenshot of the available quota in Azure AI Foundry portal." lightbox="../media/provisioned/available-quota.png":::
 
@@ -57,7 +57,7 @@ Once you have verified your quota, you can create a deployment. To create a prov
 
 
 
-1. Sign into the [Azure AI Foundry portal](https://ai.azure.com).
+1. Sign into the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 1. Choose the subscription that was enabled for provisioned deployments & select the desired resource in a region where you have the quota.
 1. Under **Management** in the left-nav select **Deployments**.
 1. Select Create new deployment and configure the following fields. Expand the **advanced options** drop-down menu.
@@ -106,7 +106,7 @@ REST, ARM template, Bicep, and Terraform can also be used to create deployments.
 
 Due to the dynamic nature of capacity availability, it is possible that the region of your selected resource might not have the service capacity to create the deployment of the specified model, version, and number of PTUs. 
 
-In this event, the wizard in [Azure AI Foundry portal](https://ai.azure.com/) will direct you to other regions with available quota and capacity to create a deployment of the desired model. If this happens, the deployment dialog will look like this: 
+In this event, the wizard in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) will direct you to other regions with available quota and capacity to create a deployment of the desired model. If this happens, the deployment dialog will look like this: 
 
 :::image type="content" source="../media/provisioned/deployment-screen-2.png" alt-text="Screenshot of the Azure AI Foundry portal deployment page for a provisioned deployment with no capacity available." lightbox="../media/provisioned/deployment-screen-2.png":::
 
@@ -164,7 +164,7 @@ The inferencing code for provisioned deployments is the same a standard deployme
 
 ## Understanding expected throughput
 The amount of throughput that you can achieve on the endpoint is a factor of the number of PTUs deployed, input size, output size, and call rate. The number of concurrent calls and total tokens processed can vary based on these values. Our recommended way for determining the throughput for your deployment is as follows:
-1. Use the Capacity calculator for a sizing estimate. You can find the capacity calculator in [Azure AI Foundry portal](https://ai.azure.com/) under the quotas page and Provisioned tab.  
+1. Use the Capacity calculator for a sizing estimate. You can find the capacity calculator in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) under the quotas page and Provisioned tab.  
 1. Benchmark the load using real traffic workload. For more information about benchmarking, see the [benchmarking](#run-a-benchmark) section.
 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Links"
}
```

### Explanation
The code diff indicates a minor update to the 'provisioned-get-started.md' file, which provides guidance on getting started with provisioned deployments in Azure OpenAI. The primary change involves the addition of a tracking parameter (`?cid=learnDocs`) to a series of hyperlinks directing users to the Azure AI Foundry portal.

This update allows for improved tracking of user engagement with the documentation, helping to analyze how frequently users access the portal through the provided links. The content remains focused on explaining how to verify quota, create a deployment, and understand expected throughput associated with provisioned deployments, while also reminding users of the capacity calculator available in the portal.

Overall, this modification subtly enhances the documentation's ability to track user interactions without altering the instructional clarity of the existing content.

## articles/ai-services/openai/how-to/provisioned-throughput-onboarding.md{#item-3eb72b}

<details>
<summary>Diff</summary>
````diff
@@ -119,7 +119,7 @@ Choose a model, and click **Confirm**. Select a provision-managed deployment typ
 
 :::image type="content" source="../media/provisioned/deployment-ptu-capacity-calculator.png" alt-text="A screenshot of deployment workflow PTU capacity calculator." lightbox="../media/provisioned/deployment-ptu-capacity-calculator.png":::
 
-To estimate provisioned capacity using request level data, open the capacity planner in the [Azure AI Foundry](https://ai.azure.com). The capacity calculator is under **Shared resources** > **Model Quota** > **Azure OpenAI Provisioned**.
+To estimate provisioned capacity using request level data, open the capacity planner in the [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs). The capacity calculator is under **Shared resources** > **Model Quota** > **Azure OpenAI Provisioned**.
 
 The **Provisioned** option and the capacity planner are only available in certain regions within the Quota pane, if you don't see this option setting the quota region to *Sweden Central* will make this option available. Enter the following parameters based on your workload.
 
@@ -144,7 +144,7 @@ The values in the output column are the estimated value of PTU units required fo
 
 Discounts on top of the hourly usage price can be obtained by purchasing an Azure Reservation for Azure OpenAI Provisioned, Data Zone Provisioned, and Global Provisioned. An Azure Reservation is a term-discounting mechanism shared by many Azure products. For example, Compute and Cosmos DB. For Azure OpenAI Provisioned, Data Zone Provisioned, and Global Provisioned, the reservation provides a discount in exchange for committing to payment for fixed number of PTUs for a one-month or one-year period.  
 
-* Azure Reservations are purchased via the Azure portal, not the [Azure AI Foundry portal](https://ai.azure.com/) Link to Azure reservation portal.
+* Azure Reservations are purchased via the Azure portal, not the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) Link to Azure reservation portal.
 
 * Reservations are purchased regionally and can be flexibly scoped to cover usage from a group of deployments. Reservation scopes include: 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Links"
}
```

### Explanation
The code diff showcases a minor update to the 'provisioned-throughput-onboarding.md' document, which guides users on how to estimate and manage provisioned throughput in Azure OpenAI. The main change entails the addition of a tracking parameter (`?cid=learnDocs`) to hyperlinks that lead to the Azure AI Foundry portal.

This update improves the ability to track user engagement with the documentation, enabling better insights into how frequently users access the portal via these links. The document continues to provide essential information, such as instructions on using the capacity planner to estimate provisioned capacity and details about Azure Reservations.

By enhancing the tracking of user interaction without changing the instructional content, this modification aims to foster improved analytics regarding user behavior and engagement with the documentation resources.

## articles/ai-services/openai/how-to/quota.md{#item-9440c2}

<details>
<summary>Diff</summary>
````diff
@@ -42,11 +42,11 @@ The flexibility to distribute TPM globally within a subscription and region has
 
 When you create a model deployment, you have the option to assign Tokens-Per-Minute (TPM) to that deployment. TPM can be modified in increments of 1,000, and will map to the TPM and RPM rate limits enforced on your deployment, as discussed above.
 
-To create a new deployment from within the [Azure AI Foundry portal](https://ai.azure.com/) select **Deployments** > **Deploy model** > **Deploy base model** > **Select Model** > **Confirm**.
+To create a new deployment from within the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) select **Deployments** > **Deploy model** > **Deploy base model** > **Select Model** > **Confirm**.
 
 :::image type="content" source="../media/quota/deployment-new.png" alt-text="Screenshot of the deployment UI of Azure AI Foundry" lightbox="../media/quota/deployment-new.png":::
 
-Post deployment you can adjust your TPM allocation by selecting and editing your model from the **Deployments** page in [Azure AI Foundry portal](https://ai.azure.com/). You can also modify this setting from the **Management** > **Model quota** page.
+Post deployment you can adjust your TPM allocation by selecting and editing your model from the **Deployments** page in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). You can also modify this setting from the **Management** > **Model quota** page.
 
 > [!IMPORTANT]
 > Quotas and limits are subject to change, for the most up-date-information consult our [quotas and limits article](../quotas-limits.md).
@@ -66,7 +66,7 @@ All other model classes have a common max TPM value.
 
 ## View and request quota
 
-For an all up view of your quota allocations across deployments in a given region, select **Management** > **Quota** in [Azure AI Foundry portal](https://ai.azure.com/):
+For an all up view of your quota allocations across deployments in a given region, select **Management** > **Quota** in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs):
 
 :::image type="content" source="../media/quota/quota-new.png" alt-text="Screenshot of the quota UI of Azure AI Foundry" lightbox="../media/quota/quota-new.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Links"
}
```

### Explanation
The code diff presents a minor update to the 'quota.md' document, which provides guidance on managing quotas and deployments in Azure OpenAI. This update primarily involves the addition of a tracking parameter (`?cid=learnDocs`) to the hyperlinks directing users to the Azure AI Foundry portal.

The changes enhance the tracking of user interactions, offering insights into how often users access the portal through these links. The document continues to detail how to create model deployments, adjust Tokens-Per-Minute (TPM) allocations, and view quota allocations across deployments.

By incorporating the tracking parameter, the modification aims to improve the analytical capabilities of user engagement with the documentation, while maintaining the clarity and instructional value of the content. The overall functionality and guidance provided in the document remain unchanged.

## articles/ai-services/openai/how-to/reinforcement-fine-tuning.md{#item-e8028c}

<details>
<summary>Diff</summary>
````diff
@@ -176,11 +176,11 @@ Models which we're supporting as grader models are:
     "model": string,
     "pass_threshold": number,
     "range": number[],
-    "sampling_parameters": {
+    "sampling_params": {
         "seed": number,
         "top_p": number,
         "temperature": number,
-        "max_completion_tokens": number,
+        "max_completions_tokens": number,
         "reasoning_effort": "low" | "medium" | "high"
     }
 }
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Rename Fields in Grader Model Parameters"
}
```

### Explanation
The code diff reflects a minor update to the 'reinforcement-fine-tuning.md' document, which serves as a guide for fine-tuning reinforcement learning models in Azure OpenAI. The modification involves renaming certain fields within the grader model parameters section of the document.

Specifically, the field `sampling_parameters` has been changed to `sampling_params`, and `max_completion_tokens` has been renamed to `max_completions_tokens`. These adjustments likely aim to improve consistency and clarity in the parameter naming conventions used in the documentation.

By making these updates, the document enhances its accuracy and usability for users seeking to fine-tune models, while ensuring that the corresponding parameters are clearly defined and understood. The overall guidance provided in the document remains intact.

## articles/ai-services/openai/how-to/risks-safety-monitor.md{#item-b2be0b}

<details>
<summary>Diff</summary>
````diff
@@ -14,13 +14,13 @@ manager: nitinme
 
 When you use an Azure OpenAI model deployment with a content filter, you might want to check the results of the filtering activity. You can use that information to further adjust your [filter configuration](/azure/ai-services/openai/how-to/content-filters) to serve your specific business needs and Responsible AI principles.  
 
-[Azure AI Foundry](https://ai.azure.com/) provides a Risks & Safety monitoring dashboard for each of your deployments that uses a content filter configuration.
+[Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) provides a Risks & Safety monitoring dashboard for each of your deployments that uses a content filter configuration.
 
 ## Access Risks & Safety monitoring
 
 To access Risks & Safety monitoring, you need an Azure OpenAI resource in one of the supported Azure regions: East US, Switzerland North, France Central, Sweden Central, Canada East. You also need a model deployment that uses a content filter configuration.
 
-Go to [Azure AI Foundry](https://ai.azure.com/) and sign in with the credentials associated with your Azure OpenAI resource. Select a project. Then select the **Models + endpoints** tab on the left and then select your model deployment from the list. On the deployment's page, select the **Monitoring** tab at the top. Then select **Open in Azure Monitor** to view the full report in the Azure portal.
+Go to [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) and sign in with the credentials associated with your Azure OpenAI resource. Select a project. Then select the **Models + endpoints** tab on the left and then select your model deployment from the list. On the deployment's page, select the **Monitoring** tab at the top. Then select **Open in Azure Monitor** to view the full report in the Azure portal.
 
 ## Configure metrics   
 
@@ -56,7 +56,7 @@ To use Potentially abusive user detection, you need:
 ### Set up your Azure Data Explorer database
 
 In order to protect the data privacy of user information and manage the permission of the data, we support the option for our customers to bring their own storage to get the detailed potentially abusive user detection insights (including user GUID and statistics on harmful request by category) stored in a compliant way and with full control. Follow these steps to enable it:
-1. In [Azure AI Foundry](https://ai.azure.com/), navigate to the model deployment that you'd like to set up user abuse analysis with, and select **Add a data store**. 
+1. In [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs), navigate to the model deployment that you'd like to set up user abuse analysis with, and select **Add a data store**. 
 1. Fill in the required information and select **Save**. We recommend you create a new database to store the analysis results.
 1. After you connect the data store, take the following steps to grant permission to write analysis results to the connected database:
     1. Go to your Azure OpenAI resource's page in the Azure portal, and choose the **Identity** tab.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Links"
}
```

### Explanation
The code diff showcases a minor update to the 'risks-safety-monitor.md' document, which outlines how to monitor risks and safety when utilizing Azure OpenAI model deployments with content filtering. The changes mainly consist of the addition of a tracking parameter (`?cid=learnDocs`) to various hyperlinks directing users to the Azure AI Foundry portal.

This adjustment enhances tracking capabilities, providing insights into how users interact with the documentation and access the Azure portal. Specifically, the instructions on accessing Risks & Safety monitoring have been updated to incorporate this tracking parameter in the links, maintaining the functionality while potentially improving user analysis.

The document continues to provide essential guidance on monitoring and configuring metrics for Azure OpenAI models, ensuring clarity and accessibility for users looking to manage their deployments effectively. Overall, the core content and instructions remain unchanged, while this modification adds a layer of analytical tracking.

## articles/ai-services/openai/how-to/role-based-access-control.md{#item-4b9817}

<details>
<summary>Diff</summary>
````diff
@@ -48,8 +48,8 @@ If a user were granted role-based access to only this role for an Azure OpenAI r
 
 ✅ View the resource in [Azure portal](https://portal.azure.com) <br>
 ✅ View the resource endpoint under **Keys and Endpoint** <br>
-✅ Ability to view the resource and associated model deployments in [Azure AI Foundry portal](https://ai.azure.com/). <br>
-✅ Ability to view what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/). <br>
+✅ Ability to view the resource and associated model deployments in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). <br>
+✅ Ability to view what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). <br>
 ✅ Use the Chat, Completions, and DALL-E (preview) playground experiences to generate text and images with any models that have already been deployed to this Azure OpenAI resource. <br>
 ✅ Make inference API calls with Microsoft Entra ID.
 
@@ -91,7 +91,7 @@ This role is typically granted access at the resource group level for a user in
 ✅ View resources in the assigned resource group in the [Azure portal](https://portal.azure.com). <br>
 ✅ View the resource endpoint under **Keys and Endpoint** <br>
 ✅ View/Copy/Regenerate keys under **Keys and Endpoint** <br>
-✅ Ability to view what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/) <br>
+✅ Ability to view what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) <br>
 ✅ Use the Chat, Completions, and DALL-E (preview) playground experiences to generate text and images with any models that have already been deployed to this Azure OpenAI resource <br>
 ✅ Create customized content filters <br>
 ✅ Add data sources to Azure OpenAI On Your Data. **You must also have the [Cognitive Services OpenAI Contributor](#cognitive-services-openai-contributor) role as well**.
@@ -112,27 +112,27 @@ Viewing quota requires the **Cognitive Services Usages Reader** role. This role
 
 This role can be found in the Azure portal under **Subscriptions** > ***Access control (IAM)** > **Add role assignment** > search for **Cognitive Services Usages Reader**. The role must be applied at the subscription level, it does not exist at the resource level.
 
-If you don't wish to use this role, the subscription **Reader** role provides equivalent access, but it also grants read access beyond the scope of what is needed for viewing quota. Model deployment via the [Azure AI Foundry portal](https://ai.azure.com/) is also partially dependent on the presence of this role.
+If you don't wish to use this role, the subscription **Reader** role provides equivalent access, but it also grants read access beyond the scope of what is needed for viewing quota. Model deployment via the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) is also partially dependent on the presence of this role.
 
 This role provides little value by itself and is instead typically assigned in combination with one or more of the previously described roles.
 
 #### Cognitive Services Usages Reader + Cognitive Services OpenAI User
 
 All the capabilities of Cognitive Services OpenAI User plus the ability to:
 
-✅ View quota allocations in [Azure AI Foundry portal](https://ai.azure.com/)
+✅ View quota allocations in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)
 
 #### Cognitive Services Usages Reader + Cognitive Services OpenAI Contributor
 
 All the capabilities of Cognitive Services OpenAI Contributor plus the ability to:
 
-✅ View quota allocations in [Azure AI Foundry portal](https://ai.azure.com/)
+✅ View quota allocations in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)
 
 #### Cognitive Services Usages Reader + Cognitive Services Contributor
 
 All the capabilities of Cognitive Services Contributor plus the ability to:
 
-✅ View & edit quota allocations in [Azure AI Foundry portal](https://ai.azure.com/) <br>
+✅ View & edit quota allocations in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) <br>
 ✅ Create new model deployments or edit existing model deployments (via Azure AI Foundry) <br>
 
 ## Summary
@@ -141,8 +141,8 @@ All the capabilities of Cognitive Services Contributor plus the ability to:
 |-------------|--------------------|------------------------|------------------|-------------------------|
 |View the resource in Azure portal |✅|✅|✅| ➖ |
 |View the resource endpoint under “Keys and Endpoint” |✅|✅|✅| ➖ |
-|View the resource and associated model deployments in [Azure AI Foundry portal](https://ai.azure.com/) |✅|✅|✅| ➖ |
-|View what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/)|✅|✅|✅| ➖ |
+|View the resource and associated model deployments in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) |✅|✅|✅| ➖ |
+|View what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs)|✅|✅|✅| ➖ |
 |Use the Chat, Completions, and DALL-E (preview) playground experiences with any models that have already been deployed to this Azure OpenAI resource.|✅|✅|✅| ➖ |
 |Create or edit model deployments|❌|✅|✅| ➖ |
 |Create or deploy custom fine-tuned models|❌|✅|✅| ➖ |
@@ -160,7 +160,7 @@ All the capabilities of Cognitive Services Contributor plus the ability to:
 
 **Issue:**
 
-When selecting an existing Azure Cognitive Search resource the search indices don't load, and the loading wheel spins continuously. In [Azure AI Foundry portal](https://ai.azure.com/), go to **Playground Chat** > **Add your data (preview)** under Assistant setup. Selecting **Add a data source** opens a modal that allows you to add a data source through either Azure Cognitive Search or Blob Storage. Selecting the Azure Cognitive Search option and an existing Azure Cognitive Search resource should load the available Azure Cognitive Search indices to select from.
+When selecting an existing Azure Cognitive Search resource the search indices don't load, and the loading wheel spins continuously. In [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), go to **Playground Chat** > **Add your data (preview)** under Assistant setup. Selecting **Add a data source** opens a modal that allows you to add a data source through either Azure Cognitive Search or Blob Storage. Selecting the Azure Cognitive Search option and an existing Azure Cognitive Search resource should load the available Azure Cognitive Search indices to select from.
 
 **Root cause** 
 
@@ -186,7 +186,7 @@ For this API call, you need a **subscription-level scope** role. You can use the
 
 **Root cause:**
 
-Insufficient subscription-level access for the user attempting to access the blob storage in [Azure AI Foundry portal](https://ai.azure.com/). The user may **not** have the necessary permissions to call the Azure Management API endpoint: ```https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{accountName}/listAccountSas?api-version=2022-09-01```
+Insufficient subscription-level access for the user attempting to access the blob storage in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). The user may **not** have the necessary permissions to call the Azure Management API endpoint: ```https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{accountName}/listAccountSas?api-version=2022-09-01```
 
 Public access to the blob storage is disabled by the owner of the Azure subscription for security reasons.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Links"
}
```

### Explanation
The code diff represents a minor update to the 'role-based-access-control.md' document, which provides guidance on managing role-based access controls for Azure OpenAI resources. The primary change involves the addition of a tracking parameter (`?cid=learnDocs`) to several hyperlinks directing users to the Azure AI Foundry portal.

This update is likely implemented to facilitate better tracking and analysis of user interactions with the documentation and portal. Each instance where a link to the Azure AI Foundry portal is provided has been modified to include the tracking parameter, ensuring that the access metrics can be captured more effectively.

Despite these changes, the document maintains its original intent and information regarding role descriptions and their respective capabilities within the Azure ecosystem. The clarity and structure of the instructions remain unaffected, allowing users to continue to work with role-based access control while potentially improving insights into how the documentation is utilized.

## articles/ai-services/openai/how-to/stored-completions.md{#item-ccc7e6}

<details>
<summary>Diff</summary>
````diff
@@ -245,7 +245,7 @@ curl $AZURE_OPENAI_ENDPOINT/openai/deployments/gpt-4o/chat/completions?api-versi
 
 ---
 
-Once stored completions are enabled for an Azure OpenAI deployment, they'll begin to show up in the [Azure AI Foundry portal](https://ai.azure.com) in the **Stored Completions** pane.
+Once stored completions are enabled for an Azure OpenAI deployment, they'll begin to show up in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) in the **Stored Completions** pane.
 
 :::image type="content" source="../media/stored-completions/stored-completions.png" alt-text="Screenshot of the stored completions User Experience." lightbox="../media/stored-completions/stored-completions.png":::
 
@@ -255,7 +255,7 @@ Distillation allows you to turn your stored completions into a fine-tuning datas
 
 Distillation requires a minimum of 10 stored completions, though it's recommended to provide hundreds to thousands of stored completions for the best results.
 
-1. From the **Stored Completions** pane in the [Azure AI Foundry portal](https://ai.azure.com) use the **Filter** options to select the completions you want to train your model with.
+1. From the **Stored Completions** pane in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) use the **Filter** options to select the completions you want to train your model with.
 
 2. To begin distillation, select **Distill**
 
@@ -284,7 +284,7 @@ The [evaluation](./evaluations.md) of large language models is a critical step i
 
 Stored completions can be used as a dataset for running evaluations.
 
-1. From the **Stored Completions** pane in the [Azure AI Foundry portal](https://ai.azure.com) use the **Filter** options to select the completions you want to be part of your evaluation dataset.
+1. From the **Stored Completions** pane in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) use the **Filter** options to select the completions you want to be part of your evaluation dataset.
 
 2. To configure the evaluation, select **Evaluate**
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Links"
}
```

### Explanation
The code diff reflects a minor update to the 'stored-completions.md' document, which covers the use of stored completions for Azure OpenAI deployments. The key change involves the addition of a tracking parameter (`?cid=learnDocs`) to several hyperlinks pointing to the Azure AI Foundry portal.

This adjustment aims to enhance the tracking of user interactions with the documentation and the Azure AI Foundry interface, allowing for better analysis of how users are accessing and using the resources. The addition of this tracking parameter occurs in multiple instances where users are directed to the Azure AI Foundry portal, specifically within context describing the **Stored Completions** pane.

Despite these changes, the explanatory content and instructions about functionality related to stored completions remain intact, ensuring that users can still follow the guidance effectively. The update serves to better monitor user engagement without altering the operational instructions provided in the documentation.

## articles/ai-services/openai/how-to/use-blocklists.md{#item-e99db7}

<details>
<summary>Diff</summary>
````diff
@@ -62,7 +62,7 @@ The response code should be `201` (created a new list) or `200` (updated an exis
 
 ### Apply a blocklist to a content filter
 
-If you haven't yet created a content filter, you can do so in [Azure AI Foundry](https://ai.azure.com/). See [Content filtering](/azure/ai-services/openai/how-to/content-filters#create-a-content-filter-in-azure-ai-foundry).
+If you haven't yet created a content filter, you can do so in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs). See [Content filtering](/azure/ai-services/openai/how-to/content-filters#create-a-content-filter-in-azure-ai-foundry).
 
 To apply a **completion** blocklist to a content filter, use the following cURL command: 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Link"
}
```

### Explanation
The code diff showcases a minor update to the 'use-blocklists.md' document, which guides users on how to utilize blocklists within content filters for Azure OpenAI. The specific change is the inclusion of a tracking parameter (`?cid=learnDocs`) in the hyperlink directing users to the Azure AI Foundry portal.

This modification aims to enhance the tracking and analytics of user interactions with the documentation and the Azure AI Foundry interface. The revised link ensures that any traffic directed to the Azure AI Foundry can be more effectively monitored, allowing for better insights into user engagement.

While this update updates the hyperlink, the document's content and the instructions surrounding the creation of a content filter remain unchanged, preserving the clarity and usability of the guidance provided to users.

## articles/ai-services/openai/how-to/use-web-app.md{#item-802413}

<details>
<summary>Diff</summary>
````diff
@@ -17,7 +17,7 @@ recommendations: false
 > [!NOTE]
 > The web app and its [source code](https://github.com/microsoft/sample-app-aoai-chatGPT) are provided "as is" and as a sample only. Customers are responsible for all customization and implementation of their web apps. See the support section for the web app on [GitHub](https://github.com/microsoft/sample-app-aoai-chatGPT/blob/main/SUPPORT.md) for more information.
 
-Along with [Azure AI Foundry portal](https://ai.azure.com/), APIs, and SDKs, you can use the customizable standalone web app to interact with Azure OpenAI models by using a graphical user interface. Key features include:
+Along with [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), APIs, and SDKs, you can use the customizable standalone web app to interact with Azure OpenAI models by using a graphical user interface. Key features include:
 * Connectivity with multiple data sources to support rich querying and retrieval-augmented generation, including Azure AI Search, Prompt Flow, and more.
 * Conversation history and user feedback collection through Cosmos DB.
 * Authentication with role-based access control via Microsoft Entra ID.
@@ -119,7 +119,7 @@ To modify the application user interface, follow the instructions in the previou
 
 You can turn on chat history for your users of the web app. When you turn on the feature, users have access to their individual previous queries and responses.
 
-To turn on chat history, deploy or redeploy your model as a web app by using [Azure AI Foundry portal](https://ai.azure.com/) and select **Enable chat history and user feedback in the web app**.
+To turn on chat history, deploy or redeploy your model as a web app by using [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and select **Enable chat history and user feedback in the web app**.
 
 :::image type="content" source="../media/use-your-data/enable-chat-history.png" alt-text="Screenshot of the checkbox for enabling chat history in Azure OpenAI or Azure AI Foundry." lightbox="../media/use-your-data/enable-chat-history.png":::
 
@@ -191,15 +191,15 @@ To connect to Azure AI Search without redeploying your app, you can modify the f
 - `AZURE_SEARCH_ENABLE_IN_DOMAIN`: Limits responses to queries related only to your data.
     - Data type: boolean, should be set to `True`.
 - `AZURE_SEARCH_CONTENT_COLUMNS`: Specifies the list of fields in your Azure AI Search index that contain the text content of your documents, used when formulating a bot response.
-    - Data type: text, defaults to `content` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
+    - Data type: text, defaults to `content` if deployed from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs),
 - `AZURE_SEARCH_FILENAME_COLUMN`: Specifies the field from your Azure AI Search index that provides a unique identifier of the source data to display in the UI.
-    - Data type: text, defaults to `filepath` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
+    - Data type: text, defaults to `filepath` if deployed from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs),
 - `AZURE_SEARCH_TITLE_COLUMN`: Specifies the field from your Azure AI Search index that provides a relevant title or header for your data content to display in the UI.
-    - Data type: text, defaults to `title` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
+    - Data type: text, defaults to `title` if deployed from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs),
 - `AZURE_SEARCH_URL_COLUMN`: Specifies the field from your Azure AI Search index that contains a URL for the document.
-    - Data type: text, defaults to `url` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
+    - Data type: text, defaults to `url` if deployed from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs),
 - `AZURE_SEARCH_VECTOR_COLUMNS`: Specifies the list of fields in your Azure AI Search index that contain vector embeddings of your documents, used when formulating a bot response.
-    - Data type: text, defaults to `contentVector` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
+    - Data type: text, defaults to `contentVector` if deployed from [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs),
 - `AZURE_SEARCH_QUERY_TYPE`: Specifies the query type to use: `simple`, `semantic`, `vector`, `vectorSimpleHybrid`, or `vectorSemanticHybrid`. This setting takes precedence over `AZURE_SEARCH_USE_SEMANTIC_SEARCH`.
     - Data type: text, we recommend testing with `vectorSemanticHybrid`.
 - `AZURE_SEARCH_PERMITTED_GROUPS_COLUMN`: Specifies the field from your Azure AI Search index that contains Microsoft Entra group IDs, determining document-level access control.
@@ -294,7 +294,7 @@ The JSON to paste in the Advanced edit JSON editor is:
 
 ### Creating and deploying your prompt flow in Azure AI Foundry portal
 
-Follow [this tutorial](../../../ai-foundry/how-to/flow-deploy.md) to create, test, and deploy an inferencing endpoint for your prompt flow in [Azure AI Foundry portal](https://ai.azure.com/).
+Follow [this tutorial](../../../ai-foundry/how-to/flow-deploy.md) to create, test, and deploy an inferencing endpoint for your prompt flow in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 
 ### Enable underlying citations from your prompt flow
 
@@ -404,7 +404,7 @@ If you customized or changed the app's source code, you need to update your app'
 
 ## Deleting your Cosmos DB instance
 
-Deleting your web app doesn't delete your Cosmos DB instance automatically. To delete your Cosmos DB instance along with all stored chats, you need to go to the associated resource in the [Azure portal](https://portal.azure.com) and delete it. If you delete the Cosmos DB resource but keep the chat history option selected on subsequent updates from the [Azure AI Foundry portal](https://ai.azure.com/), the application notifies the user of a connection error. However, the user can continue to use the web app without access to the chat history.
+Deleting your web app doesn't delete your Cosmos DB instance automatically. To delete your Cosmos DB instance along with all stored chats, you need to go to the associated resource in the [Azure portal](https://portal.azure.com) and delete it. If you delete the Cosmos DB resource but keep the chat history option selected on subsequent updates from the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), the application notifies the user of a connection error. However, the user can continue to use the web app without access to the chat history.
 
 ## Enabling Microsoft Entra ID authentication between services
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Links"
}
```

### Explanation
The code diff introduces a minor update to the 'use-web-app.md' document, which provides instructions on utilizing a customizable web app to interact with Azure OpenAI models. The main modification consists of adding a tracking parameter (`?cid=learnDocs`) to various hyperlinks that direct users to the Azure AI Foundry portal.

This change is aimed at enhancing the ability to track user engagement and interactions with the document and the Azure AI Foundry. By including this tracking parameter, it allows the Azure team to collect data on how users access resources and follow the instructions provided.

Apart from this hyperlink update, the content and instructions within the document regarding the functionalities of the web app and its features remain unchanged. Thus, users can continue to access the information without any disruption, while the management team can gain improved insights into the documentation's usage.

## articles/ai-services/openai/how-to/weights-and-biases-integration.md{#item-8ae868}

<details>
<summary>Diff</summary>
````diff
@@ -87,7 +87,7 @@ Give your Azure OpenAI resource the **Key Vault Secrets Officer** role.
 
 ## Link Weights & Biases with Azure OpenAI
 
-1. Navigate to the [Azure AI Foundry portal](https://ai.azure.com) and select your Azure OpenAI fine-tuning resource.
+1. Navigate to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and select your Azure OpenAI fine-tuning resource.
 
     :::image type="content" source="../media/how-to/weights-and-biases/manage-integrations.png" alt-text="Screenshot of the manage integrations button." lightbox="../media/how-to/weights-and-biases/manage-integrations.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Link"
}
```

### Explanation
The code diff reflects a minor update in the 'weights-and-biases-integration.md' document, which guides users on integrating Weights & Biases with Azure OpenAI. The specific change is the inclusion of a tracking parameter (`?cid=learnDocs`) in the hyperlink that directs users to the Azure AI Foundry portal.

This addition is intended to facilitate tracking user engagement with the documentation and the Azure AI Foundry resources. By appending this parameter, the Azure team can gather insights on how users access the portal and follow the associated instructions.

Other than this modification to the hyperlink, the content of the document remains the same, ensuring that users can continue to retrieve guidance without any interruptions, while providing the Azure team with improved analytics capabilities regarding usage patterns.

## articles/ai-services/openai/how-to/work-with-code.md{#item-b193c2}

<details>
<summary>Diff</summary>
````diff
@@ -27,7 +27,7 @@ You can use Codex for a variety of tasks including:
 
 ## How to use completions models with code
 
-Here are a few examples of using completion models that can be tested in the [Azure AI Foundry](https://ai.azure.com) playground with a deployment of `gpt-35-turbo-instruct`.
+Here are a few examples of using completion models that can be tested in the [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) playground with a deployment of `gpt-35-turbo-instruct`.
 
 ### Saying "Hello" (Python)
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Playground Link"
}
```

### Explanation
The code diff showcases a minor update to the 'work-with-code.md' document, which provides guidance on how to utilize completion models with Azure OpenAI. The modification involves adding a tracking parameter (`?cid=learnDocs`) to the hyperlink leading to the Azure AI Foundry playground.

This update aims to enhance the tracking capabilities for user interactions with the documentation and the playground environment. By incorporating this parameter, the Azure team can better analyze how users engage with the resources provided.

Aside from this change to the hyperlink, the content in the document remains intact, ensuring that users still have access to the same examples and instructions without any disruption. This update allows for improved insights into user behavior while maintaining the educational value of the documentation.

## articles/ai-services/openai/how-to/working-with-models.md{#item-7ec098}

<details>
<summary>Diff</summary>
````diff
@@ -20,7 +20,7 @@ You can get a list of models that are available for both inference and fine-tuni
 
 ## Model updates
 
-Azure OpenAI now supports automatic updates for select model deployments. On models where automatic update support is available, a model version drop-down is visible in [Azure AI Foundry portal](https://ai.azure.com/) under **Deployments** and **Edit**:
+Azure OpenAI now supports automatic updates for select model deployments. On models where automatic update support is available, a model version drop-down is visible in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) under **Deployments** and **Edit**:
 
 :::image type="content" source="../media/models/auto-update-new.png" alt-text="Screenshot of the deploy model UI in the Azure AI Foundry portal." lightbox="../media/models/auto-update-new.png":::
 
@@ -43,13 +43,13 @@ When you select a specific model version for a deployment, this version remains
 
 ## Viewing retirement dates
 
-For currently deployed models, in the [Azure AI Foundry portal](https://ai.azure.com/) select **Deployments**:
+For currently deployed models, in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) select **Deployments**:
 
 :::image type="content" source="../media/models/deployments-new.png" alt-text="Screenshot of the deployment UI of the Azure AI Foundry portal." lightbox="../media/models/deployments-new.png":::
 
 ## Model deployment upgrade configuration
 
-You can check what model upgrade options are set for previously deployed models in the [Azure AI Foundry portal](https://ai.azure.com). Select **Deployments** > Under the deployment name column select one of the deployment names that are highlighted in blue.
+You can check what model upgrade options are set for previously deployed models in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs). Select **Deployments** > Under the deployment name column select one of the deployment names that are highlighted in blue.
 
 Selecting a deployment name opens the **Properties** for the model deployment. You can view what upgrade options are set for your deployment under **Version update policy**:
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Links"
}
```

### Explanation
The code diff indicates a minor update to the 'working-with-models.md' document, which outlines the functionality and management of models in Azure OpenAI. This modification includes the addition of a tracking parameter (`?cid=learnDocs`) in multiple hyperlinks that direct users to the Azure AI Foundry portal.

The purpose of this update is to enhance the ability to track user interactions with the documentation and the associated portal. By appending this parameter to the links, the Azure team can obtain analytical data regarding how users access and engage with the Azure AI Foundry.

The specific areas impacted include sections on model updates, viewing retirement dates, and model deployment upgrade configuration, all of which now have links that support tracking. The overall content of the document remains unchanged, ensuring the existing guidance and examples are still valid while improving the capability for usage monitoring.

## articles/ai-services/openai/includes/audio-completions-ai-foundry.md{#item-748538}

<details>
<summary>Diff</summary>
````diff
@@ -15,10 +15,10 @@ ms.date: 1/7/2025
 
 ## Use GPT-4o audio generation
 
-To chat with your deployed `gpt-4o-mini-audio-preview` model in the **Chat** playground of [Azure AI Foundry portal](https://ai.azure.com), follow these steps:
+To chat with your deployed `gpt-4o-mini-audio-preview` model in the **Chat** playground of [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), follow these steps:
 
-1. Go to the [Azure AI Foundry portal](https://ai.azure.com) and select your project that has your deployed `gpt-4o-mini-audio-preview` model.
-1. Go to your project in [Azure AI Foundry](https://ai.azure.com). 
+1. Go to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and select your project that has your deployed `gpt-4o-mini-audio-preview` model.
+1. Go to your project in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs). 
 1. Select **Playgrounds** from the left pane.
 1. Select **Audio playground** > **Try the Chat playground**. 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Links"
}
```

### Explanation
The code diff reflects a minor update to the 'audio-completions-ai-foundry.md' document, which details how to utilize the GPT-4o audio generation model within the Azure AI Foundry. The main change involves the addition of a tracking parameter (`?cid=learnDocs`) to the links directing users to the Azure AI Foundry portal.

This enhancement is aimed at improving the ability to track user engagement with the documentation and the corresponding portal resources. By appending this parameter, the Azure team can gather more insights on how users are interacting with the links provided in the document.

The specific changes were made within the instructional steps for chatting with the deployed model in the **Chat** playground. The overall guidance and content remain the same, ensuring that users still have clear and actionable steps while benefiting from improved tracking capabilities.

## articles/ai-services/openai/includes/audio-completions-deploy-model.md{#item-c5a63e}

<details>
<summary>Diff</summary>
````diff
@@ -8,7 +8,7 @@ ms.date: 5/23/2025
 ---
 
 To deploy the `gpt-4o-mini-audio-preview` model in the Azure AI Foundry portal:
-1. Go to the [Azure AI Foundry portal](https://ai.azure.com) and create or select your project. 
+1. Go to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and create or select your project. 
 1. Select **Models + endpoints** from under **My assets** in the left pane.
 1. Select **+ Deploy model** > **Deploy base model** to open the deployment window. 
 1. Search for and select the `gpt-4o-mini-audio-preview` model and then select **Confirm**.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Link"
}
```

### Explanation
The code diff showcases a minor update to the 'audio-completions-deploy-model.md' document, which instructs users on how to deploy the GPT-4o mini audio preview model within the Azure AI Foundry portal. The principal change made is the addition of a tracking parameter (`?cid=learnDocs`) to the link directing users to the Azure AI Foundry portal.

This modification aims to enhance the tracking of user interactions with the documentation and the corresponding portal resources. By adding this parameter, the Azure team can obtain valuable analytics on how users navigate to the portal after consulting the documentation.

The update occurs in the initial step of the deployment instructions, ensuring that while the action items remain clear and accurate, the opportunity for improved engagement tracking is introduced. Users can continue to follow the established guidelines to effectively deploy their models, now benefiting from insights into their interaction with the content.

## articles/ai-services/openai/includes/batch/batch-studio.md{#item-d4822e}

<details>
<summary>Diff</summary>
````diff
@@ -74,7 +74,7 @@ For this article, we'll create a file named `test.jsonl` and will copy the conte
 Once your input file is prepared, you first need to upload the file to then be able to initiate a batch job. File upload can be done both programmatically or via the Azure AI Foundry portal. This example demonstrates uploading a file directly to your Azure OpenAI resource. Alternatively, you can [configure Azure Blob Storage for Azure OpenAI Batch](../../how-to/batch-blob-storage.md). 
 
 
-1. Sign in to [Azure AI Foundry portal](https://ai.azure.com).
+1. Sign in to [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 2. Select the Azure OpenAI resource where you have a global batch model deployment available.
 3. Select **Batch jobs** > **+Create batch jobs**.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Link"
}
```

### Explanation
The code diff indicates a minor update to the 'batch-studio.md' document, which provides guidance on using batch processing with the Azure OpenAI service. The key change is the addition of a tracking parameter (`?cid=learnDocs`) to the link that directs users to the Azure AI Foundry portal.

This modification is intended to optimize user engagement tracking by enabling the Azure team to analyze how users interact with the documentation and the portal. By including this tracking parameter, insights can be gained on user navigation patterns when accessing the Azure AI Foundry portal through the instructions provided.

The change appears in the first step of the instructions for uploading a file to initiate a batch job, ensuring that while the core instructions remain intact and clear, there is now an enhanced capability to monitor the effectiveness of the documentation in directing users to the appropriate resources. Users can continue to follow the specified steps seamlessly while benefiting from improved analytics on their actions.

## articles/ai-services/openai/includes/chatgpt-studio.md{#item-ab43f3}

<details>
<summary>Diff</summary>
````diff
@@ -15,7 +15,7 @@ ms.date: 09/19/2024
 
 ## Go to Azure AI Foundry
 
-Navigate to the [Azure AI Foundry portal](https://ai.azure.com/) and sign-in with credentials that have access to your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
+Navigate to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and sign-in with credentials that have access to your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
 
 From Azure AI Foundry, select **Chat playground**.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Link"
}
```

### Explanation
The code diff presents a minor update to the 'chatgpt-studio.md' document, which guides users on how to access the ChatGPT features within the Azure AI Foundry portal. The primary change involves the addition of a tracking parameter (`?cid=learnDocs`) to the link directing users to the Azure AI Foundry portal.

This modification is made to enhance the ability to track user interactions with the documentation and the associated Azure resources. By incorporating this link parameter, the Azure team can gather analytics to better understand how users navigate to the portal from the documentation.

The update occurs in the introductory instruction for navigating to the Azure AI Foundry portal. This ensures that the essence and clarity of the guidance remain unchanged while also improving the potential for gathering insights into user behavior. Users will continue to find the same steps for accessing and utilizing the ChatGPT features, now with the added capability of tracking engagement more effectively.

## articles/ai-services/openai/includes/connect-your-data-studio.md{#item-c34da8}

<details>
<summary>Diff</summary>
````diff
@@ -16,7 +16,7 @@ recommendations: false
 > [!TIP]
 > You can [use the Azure Developer CLI](../how-to/azure-developer-cli.md) to programmatically create the resources needed for Azure OpenAI On Your Data 
 
-Navigate to [Azure AI Foundry portal](https://ai.azure.com/) and sign-in with credentials that have access to your Azure OpenAI resource. 
+Navigate to [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and sign-in with credentials that have access to your Azure OpenAI resource. 
 
 1. You can either [create an Azure AI Foundry project](../../../ai-foundry/how-to/create-projects.md) by clicking **Create project**, or continue directly by clicking the button on the **Focused on Azure OpenAI in Azure AI Foundry Models** tile.  
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Link"
}
```

### Explanation
The code diff highlights a minor update to the 'connect-your-data-studio.md' document, which explains how to connect data with Azure OpenAI services. The significant change involves the addition of a tracking parameter (`?cid=learnDocs`) to the link that directs users to the Azure AI Foundry portal.

This enhancement aims to facilitate improved tracking of how users engage with the documentation and the Azure platform. By utilizing this tracking parameter, the Azure team can gather valuable analytics to understand user behavior and the effectiveness of their guidance.

The change applies to the instruction for navigating to the Azure AI Foundry portal, ensuring users are still presented with clear instructions to access their Azure OpenAI resources. The overall workflow remains unchanged while incorporating better analytics capabilities, allowing for insight into user interaction with the documentation and services. Users will find the same steps to connect their data to Azure OpenAI, now benefiting from enhanced tracking features.

## articles/ai-services/openai/includes/create-resource-portal.md{#item-cb2503}

<details>
<summary>Diff</summary>
````diff
@@ -96,7 +96,7 @@ Before you can generate text or inference, you need to deploy a model. You can s
 
 To deploy a model, follow these steps:
 
-1. Sign in to [Azure AI Foundry portal](https://ai.azure.com).
+1. Sign in to [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 
 2. Choose the subscription and the Azure OpenAI resource to work with, and select **Use resource**.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Portal Link"
}
```

### Explanation
The code diff indicates a minor update to the 'create-resource-portal.md' document, which provides guidance on deploying models within the Azure AI Foundry portal. The key modification consists of adding a tracking parameter (`?cid=learnDocs`) to the link that directs users to the Azure AI Foundry portal.

This update is intended to enhance the tracking of user interactions with the documentation and the Azure services. By incorporating this parameter, the Azure team can gain insights into how users are accessing the portal from the documentation, thereby improving user experience and documentation efficiency.

The change specifically affects the instruction for signing in to the Azure AI Foundry portal. While the steps for deploying a model remain unchanged, this minor update allows for better data collection on how users engage with the content. Users will access the same resources and follow the same steps to deploy a model, but now the Azure team can track engagement more effectively with this improvement.

## articles/ai-services/openai/includes/dall-e-studio.md{#item-439729}

<details>
<summary>Diff</summary>
````diff
@@ -20,7 +20,7 @@ Use this guide to get started generating images with Azure OpenAI in your browse
 
 ## Go to Azure AI Foundry
 
-Browse to [Azure AI Foundry](https://ai.azure.com/) and sign in with the credentials associated with your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
+Browse to [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) and sign in with the credentials associated with your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
 
 From the Azure AI Foundry landing page, create or select a new project. Navigate to the **Models + endpoints** page on the left nav. Select **Deploy model** and then choose one of the DALL-E models from the list. Complete the deployment process. 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Link"
}
```

### Explanation
The code diff reflects a minor update to the 'dall-e-studio.md' document, which serves as a guide for users on generating images using Azure OpenAI through the Azure AI Foundry. The modification includes the addition of a tracking parameter (`?cid=learnDocs`) to the link directing users to the Azure AI Foundry.

This change is aimed at improving the tracking of user engagement with Azure documentation and services. By including this parameter, the Azure team seeks to gather data on how users are accessing the Azure portal from the documentation, facilitating better analytics around user behavior.

The instruction for navigating to the Azure AI Foundry remains fundamentally the same, with users still directed to sign in with their Azure OpenAI resource credentials. However, the new tracking parameter aims to provide insights that can enhance the documentation experience and inform future improvements. Overall, this update helps maintain the same functional user experience while enabling better monitoring of usage statistics.

## articles/ai-services/openai/includes/fine-tuning-openai-in-ai-studio.md{#item-723c8d}

<details>
<summary>Diff</summary>
````diff
@@ -98,7 +98,7 @@ In general, doubling the dataset size can lead to a linear increase in model qua
 
 To fine-tune an Azure OpenAI model in an existing Azure AI Foundry project, follow these steps:
 
-1. Sign in to [Azure AI Foundry](https://ai.azure.com) and select your project. If you don't have a project already, first [create a project](../../../ai-foundry/how-to/create-projects.md).
+1. Sign in to [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) and select your project. If you don't have a project already, first [create a project](../../../ai-foundry/how-to/create-projects.md).
 
 1. From the collapsible left menu, select **Fine-tuning** > **+ Fine-tune model**.
 
@@ -212,7 +212,7 @@ You can monitor the progress of your deployment on the **Deployments** page in A
 
 ### Use a deployed fine-tuned model
 
-After your fine-tuned model deploys, you can use it like any other deployed model. You can use the **Playground** in [Azure AI Foundry](https://ai.azure.com) to experiment with your new deployment. You can also use the REST API to call your fine-tuned model from your own application. You can even begin to use this new fine-tuned model in your prompt flow to build your generative AI application.
+After your fine-tuned model deploys, you can use it like any other deployed model. You can use the **Playground** in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) to experiment with your new deployment. You can also use the REST API to call your fine-tuned model from your own application. You can even begin to use this new fine-tuned model in your prompt flow to build your generative AI application.
 
 > [!NOTE]
 > For chat models, the [system message that you use to guide your fine-tuned model](../concepts/system-message.md) (whether it's deployed or available for testing in the playground) must be the same as the system message you used for training. If you use a different system message, the model might not perform as expected.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Links"
}
```

### Explanation
The code diff shows a minor update to the 'fine-tuning-openai-in-ai-studio.md' document, which instructs users on how to fine-tune an Azure OpenAI model within Azure AI Foundry. The main change involves adding a tracking parameter (`?cid=learnDocs`) to links directing users to the Azure AI Foundry portal.

This addition is intended to enhance tracking of user interaction with the documentation, providing the Azure team with valuable insights into how users engage with the links provided. By understanding engagement patterns, the Azure team can make informed decisions to improve user experience and documentation quality.

The modified instructions prompt users to sign in to Azure AI Foundry while selecting their project and provide the same guidance as before for fine-tuning models. The update does not alter the overall content or steps required for fine-tuning but rather improves analytics regarding user access to the portal via the documentation. Consequently, users can still follow the established steps while benefiting from improved tracking efforts put forth by the Azure team.

## articles/ai-services/openai/includes/fine-tuning-studio.md{#item-439f1e}

<details>
<summary>Diff</summary>
````diff
@@ -245,7 +245,7 @@ If you're ready to deploy for production or have particular data residency needs
 
 ### Use a deployed fine-tuned model
 
-After your fine-tuned model deploys, you can use it like any other deployed model. You can use the **Playground** in [Azure AI Foundry](https://ai.azure.com) to experiment with your new deployment. You can also use the REST API to call your fine-tuned model from your own application. You can even begin to use this new fine-tuned model in your prompt flow to build your generative AI application.
+After your fine-tuned model deploys, you can use it like any other deployed model. You can use the **Playground** in [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) to experiment with your new deployment. You can also use the REST API to call your fine-tuned model from your own application. You can even begin to use this new fine-tuned model in your prompt flow to build your generative AI application.
 
 > [!NOTE]
 > For chat models, the [system message that you use to guide your fine-tuned model](../concepts/system-message.md) (whether it's deployed or available for testing in the playground) must be the same as the system message you used for training. If you use a different system message, the model might not perform as expected.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Link"
}
```

### Explanation
The code diff indicates a minor update to the 'fine-tuning-studio.md' document, which provides guidance on how to use fine-tuned models within Azure AI Foundry. The key change is the addition of a tracking parameter (`?cid=learnDocs`) to the link directing users to the Azure AI Foundry platform.

This update is intended to facilitate improved tracking of user engagement with the documentation. By incorporating this parameter, the Azure team aims to collect valuable analytics regarding how users are accessing the Azure AI Foundry, enabling better insights into user behavior.

The content explaining how to use a deployed fine-tuned model remains consistent with previous instructions, reiterating that users can utilize the **Playground** and the REST API with their newly deployed models. This change does not affect the steps or functionalities described; rather, it enhances the documentation by allowing the Azure team to gain insights into user traffic, which can inform future updates and improvements. Overall, users can continue to follow the established procedures while benefiting from the enhanced tracking capabilities introduced by this update.

## articles/ai-services/openai/includes/fine-tuning-unified.md{#item-718336}

<details>
<summary>Diff</summary>
````diff
@@ -14,7 +14,7 @@ ms.custom:
 
 There are two unique fine-tuning experiences in the Azure AI Foundry portal:
 
-* [Hub/Project view](https://ai.azure.com) - supports fine-tuning models from multiple providers including Azure OpenAI, Meta Llama, Microsoft Phi, etc.
+* [Hub/Project view](https://ai.azure.com/?cid=learnDocs) - supports fine-tuning models from multiple providers including Azure OpenAI, Meta Llama, Microsoft Phi, etc.
 * [Azure OpenAI centric view](https://ai.azure.com/resource/overview) - only supports fine-tuning Azure OpenAI models, but has support for additional features like the [Weights & Biases (W&B) preview integration](../how-to/weights-and-biases-integration.md). 
 
 If you are only fine-tuning Azure OpenAI models, we recommend the Azure OpenAI centric fine-tuning experience which is available by navigating to [https://ai.azure.com/resource/overview](https://ai.azure.com/resource/overview). 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Hub/Project View Link"
}
```

### Explanation
The code diff reflects a minor update to the 'fine-tuning-unified.md' document, which discusses the various fine-tuning options available in the Azure AI Foundry portal. The primary change is the addition of a tracking parameter (`?cid=learnDocs`) to the link for the Hub/Project view.

This enhancement is aimed at improving the ability to track user interactions with the Azure AI Foundry. By appending the tracking parameter to the link, the Azure team can gather insights into how often users engage with this particular page, thereby informing future documentation and platform improvements.

The document retains its original informative content, clearly distinguishing between two unique fine-tuning experiences: the general Hub/Project view, which supports models from various providers, and the Azure OpenAI-centric view, which is tailored for fine-tuning Azure OpenAI models. Users are still advised to utilize the Azure OpenAI-centric experience if they are solely working with Azure OpenAI models. The revised link does not change the functionality or steps outlined in the document but does enhance analytics capabilities for the Azure team.

## articles/ai-services/openai/includes/gpt-v-studio.md{#item-dcd50e}

<details>
<summary>Diff</summary>
````diff
@@ -10,7 +10,7 @@ ms.custom: references_regions, ignite-2024
 ms.date: 01/29/2025
 ---
 
-Use this article to get started using [Azure AI Foundry](https://ai.azure.com) to deploy and test a chat completion model with image understanding. 
+Use this article to get started using [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) to deploy and test a chat completion model with image understanding. 
 
 
 ## Prerequisites
@@ -28,7 +28,7 @@ You need an image to complete this quickstart. You can use this sample image or
 
 ## Go to Azure AI Foundry
 
-1. Browse to [Azure AI Foundry](https://ai.azure.com/) and sign in with the credentials associated with your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
+1. Browse to [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) and sign in with the credentials associated with your Azure OpenAI resource. During or after the sign-in workflow, select the appropriate directory, Azure subscription, and Azure OpenAI resource.
 1. Select the project you'd like to work in.
 1. On the left nav menu, select **Models + endpoints** and select **+ Deploy model**.
 1. Choose an image-capable deployment by selecting model name: **gpt-4o** or **gpt-4o-mini**. In the window that appears, select a name and deployment type. Make sure your Azure OpenAI resource is connected. For more information about model deployment, see the [resource deployment guide](/azure/ai-services/openai/how-to/create-resource).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Links"
}
```

### Explanation
The code diff presents a minor update to the 'gpt-v-studio.md' document, which serves as a guide for deploying and testing a chat completion model with image understanding in Azure AI Foundry. The changes include the addition of a tracking parameter (`?cid=learnDocs`) to the hyperlinks that direct users to the Azure AI Foundry.

This adjustment is aimed at improving tracking capabilities, allowing the Azure team to analyze user engagement with documentation more effectively. By incorporating this parameter into both the introductory link and the step-by-step instructions, the documentation team can gather useful data regarding how users interact with these resources.

The essential content and instructions within the document remain unchanged. Users are still guided on how to access and configure their Azure AI Foundry settings, including selecting the appropriate project and deploying image-capable models. The main goal of this modification is to enhance the analytics for user traffic without altering the functionality or procedural information presented in the document.

## articles/ai-services/openai/includes/realtime-deploy-model.md{#item-21f911}

<details>
<summary>Diff</summary>
````diff
@@ -8,7 +8,7 @@ ms.date: 1/21/2025
 ---
 
 To deploy the `gpt-4o-mini-realtime-preview` model in the Azure AI Foundry portal:
-1. Go to the [Azure AI Foundry portal](https://ai.azure.com) and create or select your project. 
+1. Go to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and create or select your project. 
 1. Select **Models + endpoints** from under **My assets** in the left pane.
 1. Select **+ Deploy model** > **Deploy base model** to open the deployment window. 
 1. Search for and select the `gpt-4o-mini-realtime-preview` model and then select **Confirm**.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Link"
}
```

### Explanation
The code diff indicates a minor update to the 'realtime-deploy-model.md' document, which provides instructions for deploying the `gpt-4o-mini-realtime-preview` model in the Azure AI Foundry portal. The change involves adding a tracking parameter (`?cid=learnDocs`) to the hyperlink that directs users to the Azure AI Foundry portal.

By including this tracking parameter, the Azure documentation team aims to better analyze and understand user engagement with the documentation. This small modification enhances the ability to track how often users visit the Azure AI Foundry portal through the documentation, which can help inform future updates and improvements.

The overall content and instructional steps remain intact, allowing users to seamlessly follow the procedures for selecting their project, accessing the model deployment options, and deploying the specified model. This change is primarily focused on enhancing analytics without affecting the functionality or clarity of the instructions provided in the document.

## articles/ai-services/openai/includes/realtime-portal.md{#item-1b81a2}

<details>
<summary>Diff</summary>
````diff
@@ -13,9 +13,9 @@ ms.date: 3/20/2025
 
 ## Use the GPT-4o real-time audio
 
-To chat with your deployed `gpt-4o-mini-realtime-preview` model in the [Azure AI Foundry](https://ai.azure.com) **Real-time audio** playground, follow these steps:
+To chat with your deployed `gpt-4o-mini-realtime-preview` model in the [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) **Real-time audio** playground, follow these steps:
 
-1. Go to the [Azure AI Foundry portal](https://ai.azure.com) and select your project that has your deployed `gpt-4o-mini-realtime-preview` model.
+1. Go to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and select your project that has your deployed `gpt-4o-mini-realtime-preview` model.
 1. Select **Playgrounds** from the left pane.
 1. Select **Audio playground** > **Try the Audio playground**. 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Links in Real-time Portal"
}
```

### Explanation
The code diff showcases a minor update to the 'realtime-portal.md' document, which guides users on interacting with the `gpt-4o-mini-realtime-preview` model in the Azure AI Foundry's **Real-time audio** playground. The change consists of appending a tracking parameter (`?cid=learnDocs`) to the links directing users to the Azure AI Foundry portal.

This addition serves to enhance the documentation team's ability to monitor user engagement and interactions with the portal. By implementing this tracking parameter, the Azure team can better analyze traffic generated through the documentation, allowing them to make informed decisions on future content and improvements.

Despite the link modifications, the core instructions and content within the document remain unchanged. Users are still guided through the necessary steps to access their project and utilize the audio playground for chatting with the deployed model. The primary focus of this update is to improve tracking capabilities without impacting the functionality or clarity of the information provided in the guide.

## articles/ai-services/openai/includes/studio.md{#item-eeeaff}

<details>
<summary>Diff</summary>
````diff
@@ -39,7 +39,7 @@ In the Completions playground you can also view Python and curl code samples pre
 
 To use the Azure OpenAI for text summarization in the Completions playground, follow these steps:
 
-1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com).
+1. Sign in to the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 1. Select the subscription and OpenAI resource to work with. 
 1. Select **Completions playground** on the landing page.
 1. Select your deployment from the **Deployments** dropdown. If your resource doesn't have a deployment, select **Create a deployment** and then revisit this step.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Link in Studio Guide"
}
```

### Explanation
The code diff represents a minor update to the 'studio.md' document, which outlines the procedures for using Azure OpenAI for text summarization within the Completions playground. The change involves the addition of a tracking parameter (`?cid=learnDocs`) to the link that directs users to the Azure AI Foundry portal.

This tracking parameter is intended to improve the ability of the documentation team to analyze user traffic and interactions with the Azure portal, enabling better insights into user engagement and potentially guiding future content adjustments.

While the addition is mainly administrative, the essential instructions for users remain unchanged. The document still provides a step-by-step process for signing into the Azure AI Foundry, selecting the appropriate subscription and resource, and navigating to the Completions playground. The primary focus of this update is to enhance tracking without altering the clarity or functionality of the instructional content provided in the guide.

## articles/ai-services/openai/overview.md{#item-97d507}

<details>
<summary>Diff</summary>
````diff
@@ -24,7 +24,7 @@ Azure OpenAI provides REST API access to OpenAI's powerful language models inclu
 | Price | [Available here](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) <br> For details on vision-enabled chat models, see the [special pricing information](../openai/concepts/gpt-with-vision.md#special-pricing-information).|
 | Virtual network support & private link support | Yes.  |
 | Managed Identity| Yes, via Microsoft Entra ID | 
-| UI experience | [Azure portal](https://portal.azure.com) for account & resource management, <br> [Azure AI Foundry](https://ai.azure.com) for model exploration and fine-tuning |
+| UI experience | [Azure portal](https://portal.azure.com) for account & resource management, <br> [Azure AI Foundry](https://ai.azure.com/?cid=learnDocs) for model exploration and fine-tuning |
 | Model regional availability | [Model availability](./concepts/models.md) |
 | Content filtering | Prompts and completions are evaluated against our content policy with automated systems. High severity content is filtered. |
 
@@ -41,7 +41,7 @@ Start with the [Create and deploy an Azure OpenAI resource](./how-to/create-reso
 1. When you have an Azure OpenAI resource, you can deploy a model such as GPT-4o.
 1. When you have a deployed model, you can:
 
-    - Try out the [Azure AI Foundry portal](https://ai.azure.com/) playgrounds to explore the capabilities of the models. 
+    - Try out the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) playgrounds to explore the capabilities of the models. 
     - You can also just start making API calls to the service using the REST API or SDKs.
     
     For example, you can try [real-time audio](./realtime-audio-quickstart.md) and [assistants](./assistants-quickstart.md) in the playgrounds or via code.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Links in Overview Document"
}
```

### Explanation
The code diff reflects a minor update to the 'overview.md' document that provides an overview of the Azure OpenAI service. This update includes the addition of a tracking parameter (`?cid=learnDocs`) to links that direct users to the Azure AI Foundry portal. 

The primary purpose of this modification is to enhance tracking capabilities, enabling the documentation team to analyze user engagement with the Azure AI Foundry. By appending this parameter, they can better understand how users are interacting with the provided resources.

The document still contains essential information regarding the Azure OpenAI service, such as the UI experience related to account management and resource exploration. The minor alterations facilitate improved tracking without compromising the clarity or utility of the overall content. Users are still guided on where to explore the capabilities of Azure OpenAI models through the playgrounds, ensuring that the core instructional value remains intact while benefiting from improved analytics.

## articles/ai-services/openai/quotas-limits.md{#item-06c6f9}

<details>
<summary>Diff</summary>
````diff
@@ -45,8 +45,8 @@ The following sections provide you with a quick guide to the default quotas and
 | Max number of `/chat/completions` functions | 128 |
 | Max number of `/chat completions` tools | 128 |
 | Maximum number of Provisioned throughput units per deployment | 100,000 |
-| Max files per Assistant/thread | 10,000 when using the API or [Azure AI Foundry portal](https://ai.azure.com/).|
-| Max file size for Assistants & fine-tuning | 512 MB<br/><br/>200 MB via [Azure AI Foundry portal](https://ai.azure.com/) |
+| Max files per Assistant/thread | 10,000 when using the API or [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).|
+| Max file size for Assistants & fine-tuning | 512 MB<br/><br/>200 MB via [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) |
 | Max size for all uploaded files for Assistants |200 GB |
 | Assistants token limit | 2,000,000 token limit |
 | GPT-4o max images per request (# of images in the messages array/conversation history) | 50 |
@@ -197,7 +197,7 @@ M = million | K = thousand
 
 ### gpt-4o audio
 
-The rate limits for each `gpt-4o` audio model deployment are 100 K TPM and 1 K RPM. During the preview, [Azure AI Foundry portal](https://ai.azure.com/) and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit is 100 K TPM and 1 K RPM.
+The rate limits for each `gpt-4o` audio model deployment are 100 K TPM and 1 K RPM. During the preview, [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit is 100 K TPM and 1 K RPM.
 
 | Model|Tier| Quota Limit in tokens per minute (TPM) | Requests per minute |
 |---|---|:---:|:---:|
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Links in Quotas and Limits Document"
}
```

### Explanation
The code diff shows a minor update to the 'quotas-limits.md' document, which outlines the default quotas and limits for the Azure OpenAI service. This modification includes the addition of a tracking parameter (`?cid=learnDocs`) in the links directing users to the Azure AI Foundry portal.

The purpose of this change is to enhance tracking analytics, allowing the documentation team to better understand user interactions with the portal. By including this parameter, they can effectively gather data on user engagement that can lead to improved content evaluation and adjustments in the future.

The sections impacted by this change pertain to the maximum number of files per Assistant/thread and the maximum file size for Assistants and fine-tuning, which have remained consistent in terms of content. The instructional and informational value of the document remains intact, while the modifications facilitate better data collection efforts, ultimately benefiting users by guiding the enhancements made to the service or documentation.

## articles/ai-services/openai/tutorials/fine-tune.md{#item-8f87b5}

<details>
<summary>Diff</summary>
````diff
@@ -34,7 +34,7 @@ In this tutorial you learn how to:
 - [Jupyter Notebooks](https://jupyter.org/)
 - An Azure OpenAI resource in a [region where `gpt-4o-mini-2024-07-18` fine-tuning is available](../concepts/models.md). If you don't have a resource the process of creating one is documented in our resource [deployment guide](../how-to/create-resource.md).
 - Fine-tuning access requires **Cognitive Services OpenAI Contributor**.
-- If you don't already have access to view quota and deploy models in [Azure AI Foundry portal](https://ai.azure.com/), then you need [more permissions](../how-to/role-based-access-control.md).
+- If you don't already have access to view quota and deploy models in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), then you need [more permissions](../how-to/role-based-access-control.md).
 
 > [!IMPORTANT]
 > We recommend reviewing the [pricing information](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/#pricing) for fine-tuning to familiarize yourself with the associated costs. Testing of this tutorial resulted in 48,000 tokens being billed (4,800 training tokens * 10 epochs of training). Training costs are in addition to the costs that are associated with fine-tuning inference, and the hourly hosting costs of having a fine-tuned model deployed. Once you have completed the tutorial, you should delete your fine-tuned model deployment otherwise you continue to incur the hourly hosting cost.
@@ -694,7 +694,7 @@ fine_tuned_model = response.fine_tuned_model
 
 Unlike the previous Python SDK commands in this tutorial, since the introduction of the quota feature, model deployment must be done using the [REST API](/rest/api/aiservices/accountmanagement/deployments/create-or-update?tabs=HTTP), which requires separate authorization, a different API path, and a different API version.
 
-Alternatively, you can deploy your fine-tuned model using any of the other common deployment methods like [Azure AI Foundry portal](https://ai.azure.com/), or [Azure CLI](/cli/azure/cognitiveservices/account/deployment#az-cognitiveservices-account-deployment-create()).
+Alternatively, you can deploy your fine-tuned model using any of the other common deployment methods like [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), or [Azure CLI](/cli/azure/cognitiveservices/account/deployment#az-cognitiveservices-account-deployment-create()).
 
 |variable      | Definition|
 |--------------|-----------|
@@ -745,13 +745,13 @@ print(r.reason)
 print(r.json())
 ```
 
-You can check on your deployment progress in the [Azure AI Foundry portal](https://ai.azure.com/).
+You can check on your deployment progress in the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs).
 
 It isn't uncommon for this process to take some time to complete when dealing with deploying fine-tuned models.
 
 ## Use a deployed customized model
 
-After your fine-tuned model is deployed, you can use it like any other deployed model in either the [Chat Playground of Azure AI Foundry portal](https://ai.azure.com), or via the chat completion API. For example, you can send a chat completion call to your deployed model, as shown in the following Python example. You can continue to use the same parameters with your customized model, such as temperature and max_tokens, as you can with other deployed models.
+After your fine-tuned model is deployed, you can use it like any other deployed model in either the [Chat Playground of Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), or via the chat completion API. For example, you can send a chat completion call to your deployed model, as shown in the following Python example. You can continue to use the same parameters with your customized model, such as temperature and max_tokens, as you can with other deployed models.
 
 ```python
 # Use the deployed customized model
@@ -784,7 +784,7 @@ Unlike other types of Azure OpenAI models, fine-tuned/customized models have [an
 
 Deleting the deployment won't affect the model itself, so you can re-deploy the fine-tuned model that you trained for this tutorial at any time.
 
-You can delete the deployment in [Azure AI Foundry portal](https://ai.azure.com/), via [REST API](/rest/api/aiservices/accountmanagement/deployments/delete?tabs=HTTP), [Azure CLI](/cli/azure/cognitiveservices/account/deployment#az-cognitiveservices-account-deployment-delete()), or other supported deployment methods.
+You can delete the deployment in [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), via [REST API](/rest/api/aiservices/accountmanagement/deployments/delete?tabs=HTTP), [Azure CLI](/cli/azure/cognitiveservices/account/deployment#az-cognitiveservices-account-deployment-delete()), or other supported deployment methods.
 
 ## Troubleshooting
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Azure AI Foundry Links in Fine-Tuning Tutorial"
}
```

### Explanation
The code diff introduces a minor update to the 'fine-tune.md' tutorial document, which provides guidance on how to fine-tune models using Azure OpenAI. The changes involve the addition of a tracking parameter (`?cid=learnDocs`) to several links that direct users to the Azure AI Foundry portal.

The purpose of this change is to facilitate better tracking of user engagement with the Fine-Tuning Tutorial, which helps the documentation team analyze how users interact with the resources provided. By incorporating this tracking parameter, the organization can gather insights about user activity that can assist in improving both the documentation and the services offered.

While the main instructional content of the tutorial remains unchanged—covering critical steps such as accessing the AI Foundry portal, the model deployment process, and troubleshooting—these links have been updated to include the tracking functionality. This enhancement does not disrupt the flow of information but rather supports the ongoing evaluation and optimization of the documentation and its offerings.

## articles/ai-services/openai/whats-new.md{#item-53303b}

<details>
<summary>Diff</summary>
````diff
@@ -141,7 +141,7 @@ The `gpt-4o-realtime-preview` model version 2024-12-17 is available for global d
 
 - Added support for [prompt caching](./how-to/prompt-caching.md) with the `gpt-4o-realtime-preview` model.
 - Added support for new voices. The `gpt-4o-realtime-preview` models now support the following voices: "alloy", "ash", "ballad", "coral", "echo", "sage", "shimmer", "verse".
-- Rate limits are no longer based on connections per minute. Rate limiting is now based on RPM (requests per minute) and TPM (tokens per minute) for the `gpt-4o-realtime-preview` model. The rate limits for each `gpt-4o-realtime-preview` model deployment are 100K TPM and 1K RPM. During the preview, [Azure AI Foundry portal](https://ai.azure.com/) and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit will be 100K TPM and 1K RPM.
+- Rate limits are no longer based on connections per minute. Rate limiting is now based on RPM (requests per minute) and TPM (tokens per minute) for the `gpt-4o-realtime-preview` model. The rate limits for each `gpt-4o-realtime-preview` model deployment are 100K TPM and 1K RPM. During the preview, [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit will be 100K TPM and 1K RPM.
 
 For more information, see the [GPT-4o real-time audio quickstart](realtime-audio-quickstart.md) and the [how-to guide](./how-to/realtime-audio.md).
 
@@ -271,7 +271,7 @@ Global batch now supports GPT-4o (2024-08-06). See the [global batch getting sta
 
 ### Azure OpenAI Studio UX updates
 
-As of September 19, 2024, when you go to the [Azure OpenAI Studio](https://oai.azure.com/) you no longer see the legacy Azure OpenAI Studio by default. If needed you'll still be able to go back to the previous experience by using the **Switch to the old look** toggle in the top bar of the UI for the next couple of weeks. If you switch back to legacy [Azure AI Foundry portal](https://ai.azure.com/), it helps if you fill out the feedback form to let us know why. We're actively monitoring this feedback to improve the new experience.
+As of September 19, 2024, when you go to the [Azure OpenAI Studio](https://oai.azure.com/) you no longer see the legacy Azure OpenAI Studio by default. If needed you'll still be able to go back to the previous experience by using the **Switch to the old look** toggle in the top bar of the UI for the next couple of weeks. If you switch back to legacy [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs), it helps if you fill out the feedback form to let us know why. We're actively monitoring this feedback to improve the new experience.
 
 
 ### GPT-4o 2024-08-06 provisioned deployments
@@ -314,7 +314,7 @@ OpenAI has incorporated additional safety measures into the `o1` models, includi
 
 ### Availability
 
-The `o1-preview` and `o1-mini` are available in the East US2 region for limited access through the [Azure AI Foundry portal](https://ai.azure.com) early access playground. Data processing for the `o1` models might occur in a different region than where they're available for use.
+The `o1-preview` and `o1-mini` are available in the East US2 region for limited access through the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) early access playground. Data processing for the `o1` models might occur in a different region than where they're available for use.
 
 To try the `o1-preview` and `o1-mini` models in the early access playground **registration is required, and access will be granted based on Microsoft’s eligibility criteria.**
 
@@ -372,7 +372,7 @@ On August 6, 2024, OpenAI [announced](https://openai.com/index/introducing-struc
 
 Azure customers can test out GPT-4o `2024-08-06` today in the new Azure AI Foundry early access playground (preview).
 
-Unlike the previous early access playground, the [Azure AI Foundry portal](https://ai.azure.com/) early access playground (preview) doesn't require you to have a resource in a specific region.
+Unlike the previous early access playground, the [Azure AI Foundry portal](https://ai.azure.com/?cid=learnDocs) early access playground (preview) doesn't require you to have a resource in a specific region.
 
 > [!NOTE]
 > Prompts and completions made through the early access playground (preview) might be processed in any Azure OpenAI region, and are currently subject to a 10 request per minute per Azure subscription limit. This limit might change in the future.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "Add Tracking Parameter to Links in 'What's New' Document"
}
```

### Explanation
The code diff indicates a minor update to the 'whats-new.md' document, which details the recent enhancements and changes within the Azure OpenAI services. The primary change involves adding a tracking parameter (`?cid=learnDocs`) to several links that direct users to the Azure AI Foundry portal.

This update serves the purpose of improving tracking analytics, allowing the documentation team to gain insights into how users interact with the provided links and content. By including this tracking mechanism, the organization can monitor user engagement more effectively, which ultimately aids in refining the documentation and service offerings.

The modifications do not alter the substantive content of the document, which highlights new features such as support for prompt caching, voice options for the `gpt-4o-realtime-preview` model, and updates related to rate limiting and availability. However, the addition of the tracking parameter enhances the ability to collect data for evaluation and improvement purposes. Overall, the integrity of the information presented remains intact while facilitating better user analytics.


