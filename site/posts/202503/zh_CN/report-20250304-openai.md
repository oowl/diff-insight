---
date: '2025-03-04'
permalink: https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:ab648e8...MicrosoftDocs:bf9270b
summary: 在本次文档更新中，多个文件经过小幅修改，主要旨在提升文档的可用性和用户体验。最大的变化是将所有涉及Azure AI Foundry门户的文本更新为可点击链接，以方便用户直接访问相关页面。这项改进涵盖API文档、指南和教程等多个文档，目的是提高用户的阅读体验和信息获取效率。此次更新未引入新的特性或破坏性更改，主要是格式上的改进。更新还包括添加关于REST
  API规范链接的更新，以确保文档指向最新版本。总体来看，这些小幅修改有效提升了文档的实用性和用户交互性。
title: '[zh_CN] Diff Insight Report - openai'

---

[View Diff on GitHub](https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:ab648e8...MicrosoftDocs:bf9270b){target="_blank"}

# Highlights

在本次文档更新中，多个文件进行了小幅的修改，主要集中在提升文档的可用性和用户体验方面。最大的变化是将涉及的所有Azure AI Foundry门户相关的文本更新为可点击链接。这一小幅更新在多个文档中展开，包括API文档、指南、教程等。这样的更改主要目的是为用户提供更加便利和快捷的访问路径，提升用户的阅读体验和信息获取效率。总体而言，本次更新在功能和结构上没有引入新的特性也不存在破坏性的更改，只是进行了格式上的改进。

## 新特性
- 全文档中涉及的Azure AI Foundry门户文本现已更新为可点击链接，便于用户直接跳转到相关页面。

## Breaking changes
- 此次更新没有引入任何破坏性更改，所有修改均为可用性改善。

## 其他更新
- 新增关于REST API规范链接的更新，确保文档指向最新的有效版本。

# Insights

在此次文档更新中，开发团队着重解决了用户在文档与服务平台之间跳转的便利性问题。通过将提到的Azure AI Foundry门户文本转换为可点击链接，用户不再需要手动复制和粘贴网址进行访问，这不仅提升了文档的交互性，也显著改善了用户的体验。这种小幅但有效的修改显示出团队在细节方面的关注，从而使文档更加实用。

此更新背后可能反映了用户反馈的一些常见问题，用户在访问关联资源时经常面临的挑战得到了缓解。通过保留文档原有内容和结构，该更新确保了信息的一致性和可靠性，同时提升了获取信息的速度和准确性。

此外，通过更新REST API规范的链接，将文档指向最新的版本，显示了文档维护人员保持信息最新和精确的意图。这对于开发者尤为重要，因为API的最新规范能够直接影响到其使用效果和开发进程。

总的来说，本次更新虽然不显眼，但却非常实用，显示了通过改善用户体验来增进整个平台使用便捷性的思路。

# Summary Table
|  Filename  | Type |    Title    | Status | A  | D  | M  |
|------------|------|-------------|--------|----|----|----|
| [assistants.md](#item-eab970) | minor update | 更新Assistants API文档中的链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [content-filter.md](#item-dfc7e7) | minor update | 更新内容过滤器文档中的超链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [customizing-llms.md](#item-067bef) | minor update | 更新自定义LLMs文档中的链接格式. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [gpt-with-vision.md](#item-991388) | minor update | 更新GPT视觉功能文档中的链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [provisioned-migration.md](#item-68e143) | minor update | 更新已配置迁移文档中的链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [use-your-data.md](#item-455d6e) | minor update | 更新使用您的数据文档中的链接. Locale: zh_CN | modified | 14 | 14 | 28 | 
| [faq.yml](#item-6deb71) | minor update | 更新常见问题文档中的链接. Locale: zh_CN | modified | 8 | 8 | 16 | 
| [batch.md](#item-a131d5) | minor update | 更新批处理文档中的链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [evaluations.md](#item-dfaa1c) | minor update | 更新评估文档中的链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [fine-tuning.md](#item-5c0e85) | minor update | 更新微调文档中的链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [on-your-data-configuration.md](#item-4875d3) | minor update | 更新数据配置文档中的链接. Locale: zh_CN | modified | 8 | 8 | 16 | 
| [provisioned-get-started.md](#item-c8df1c) | minor update | 更新已配置入门文档中的链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [provisioned-throughput-onboarding.md](#item-3eb72b) | minor update | 更新已配置吞吐量入门文档中的链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [quota.md](#item-9440c2) | minor update | 更新配额文档中的链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [role-based-access-control.md](#item-4b9817) | minor update | 更新基于角色的访问控制文档中的链接. Locale: zh_CN | modified | 11 | 11 | 22 | 
| [use-web-app.md](#item-802413) | minor update | 更新使用 Web 应用文档中的链接. Locale: zh_CN | modified | 8 | 8 | 16 | 
| [working-with-models.md](#item-7ec098) | minor update | 更新与模型相关的文档链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [audio-completions-rest.md](#item-0ec305) | minor update | 更新REST API规范的链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [overview.md](#item-97d507) | minor update | 更新Azure AI Foundry门户的链接. Locale: zh_CN | modified | 1 | 1 | 2 | 
| [quotas-limits.md](#item-06c6f9) | minor update | 更新关于Azure AI Foundry门户的链接. Locale: zh_CN | modified | 3 | 3 | 6 | 
| [fine-tune.md](#item-8f87b5) | minor update | 更新Azure AI Foundry门户的链接. Locale: zh_CN | modified | 2 | 2 | 4 | 
| [whats-new.md](#item-53303b) | minor update | 增加关于Azure AI Foundry门户的链接. Locale: zh_CN | modified | 3 | 3 | 6 | 


# Modified Contents
## articles/ai-services/openai/concepts/assistants.md{#item-eab970}

<details>
<summary>Diff</summary>
````diff
@@ -33,7 +33,7 @@ Assistants API supports persistent automatically managed threads. This means tha
 > [!TIP]
 > There is no additional [pricing](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/) or [quota](../quotas-limits.md) for using Assistants unless you use the [code interpreter](../how-to/code-interpreter.md) or [file search](../how-to/file-search.md) tools.
 
-Assistants API is built on the same capabilities that power OpenAI’s GPT product. Some possible use cases range from AI-powered product recommender, sales analyst app, coding assistant, employee Q&A chatbot, and more. Start building on the no-code Assistants playground on the Azure AI Foundry portal or start building with the API.
+Assistants API is built on the same capabilities that power OpenAI’s GPT product. Some possible use cases range from AI-powered product recommender, sales analyst app, coding assistant, employee Q&A chatbot, and more. Start building on the no-code Assistants playground on the [Azure AI Foundry portal](https://ai.azure.com/) or start building with the API.
 
 > [!IMPORTANT]
 > Retrieving untrusted data using Function calling, Code Interpreter or File Search with file input, and Assistant Threads functionalities could compromise the security of your Assistant, or the application that uses the Assistant. Learn about mitigation approaches [here](https://aka.ms/oai/assistant-rai).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新Assistants API文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改对Assistants API文档进行了小幅更新。主要变更是在有关Assistants API的段落中添加了指向Azure AI Foundry门户的超链接。具体来说，文本中提到的“Azure AI Foundry portal”现在变成了一个可点击的链接，这样用户可以更方便地访问相关资源。此修改旨在提升文档的可用性和用户体验。总体来说，这是一项微小的更新，没有影响到文档的核心内容和结构。

## articles/ai-services/openai/concepts/content-filter.md{#item-dfc7e7}

<details>
<summary>Diff</summary>
````diff
@@ -881,15 +881,15 @@ Customers must understand that while the feature improves latency, it's a trade-
 
 **Customer Copyright Commitment**: Content that is retroactively flagged as protected material may not be eligible for Customer Copyright Commitment coverage. 
 
-To enable Asynchronous Filter in Azure AI Foundry portal, follow the [Content filter how-to guide](/azure/ai-services/openai/how-to/content-filters) to create a new content filtering configuration, and select **Asynchronous Filter** in the Streaming section.
+To enable Asynchronous Filter in [Azure AI Foundry portal](https://ai.azure.com/), follow the [Content filter how-to guide](/azure/ai-services/openai/how-to/content-filters) to create a new content filtering configuration, and select **Asynchronous Filter** in the Streaming section.
 
 ### Comparison of content filtering modes
 
 | Compare | Streaming - Default | Streaming - Asynchronous Filter |
 |---|---|---|
 |Status |GA |Public Preview |
 | Eligibility |All customers |Customers approved for modified content filtering |
-| How to enable | Enabled by default, no action needed |Customers approved for modified content filtering can configure it directly in Azure AI Foundry portal (as part of a content filtering configuration, applied at the deployment level) |
+| How to enable | Enabled by default, no action needed |Customers approved for modified content filtering can configure it directly in [Azure AI Foundry portal](https://ai.azure.com/) (as part of a content filtering configuration, applied at the deployment level) |
 |Modality and availability |Text; all GPT models |Text; all GPT models |
 |Streaming experience |Content is buffered and returned in chunks |Zero latency (no buffering, filters run asynchronously) |
 |Content filtering signal |Immediate filtering signal |Delayed filtering signal (in up to ~1,000-character increments) |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新内容过滤器文档中的超链接. Locale: zh_CN"
}
```

### Explanation
此次修改对内容过滤器文档进行了小幅更新，主要集中在提升超链接的可用性。具体而言，Azure AI Foundry门户的相关指向现在也被转换为可点击的链接，方便用户直接访问。更新的内容涉及启用异步过滤器的说明，以及在比较内容过滤模式表格中，增加了对Azure AI Foundry门户的链接。在这次修改中，虽然进行了两个添加和两个删除，但整体上未对文档的结构或功能造成实质性影响，只是增强了信息的可访问性。

## articles/ai-services/openai/concepts/customizing-llms.md{#item-067bef}

<details>
<summary>Diff</summary>
````diff
@@ -62,7 +62,7 @@ A corporate HR department is looking to provide an intelligent assistant that an
 
 ### Getting started
 
-- [Retrieval Augmented Generation in Azure AI Foundry portal - Azure AI Foundry | Microsoft Learn](../../../ai-studio/concepts/retrieval-augmented-generation.md)
+- [Retrieval Augmented Generation in [Azure AI Foundry portal](https://ai.azure.com/) - Azure AI Foundry | Microsoft Learn](../../../ai-studio/concepts/retrieval-augmented-generation.md)
 - [Retrieval Augmented Generation (RAG) in Azure AI Search](/azure/search/retrieval-augmented-generation-overview)
 - [Retrieval Augmented Generation using Azure Machine Learning prompt flow (preview)](/azure/machine-learning/concept-retrieval-augmented-generation)
 
@@ -99,4 +99,4 @@ They fine-tune GPT-4o mini with hundreds of requests and correct responses and p
 - [When to use Azure OpenAI fine-tuning](./fine-tuning-considerations.md)
 - [Customize a model with fine-tuning](../how-to/fine-tuning.md)
 - [Azure OpenAI GPT-4o Turbo fine-tuning tutorial](../tutorials/fine-tune.md)
-- [To fine-tune or not to fine-tune? (Video)](https://www.youtube.com/watch?v=0Jo-z-MFxJs)
\ No newline at end of file
+- [To fine-tune or not to fine-tune? (Video)](https://www.youtube.com/watch?v=0Jo-z-MFxJs)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新自定义LLMs文档中的链接格式. Locale: zh_CN"
}
```

### Explanation
此次修改对自定义LLMs文档进行了小幅更新，主要是对链接的格式进行了调整，提升了可访问性。具体来说，将指向Azure AI Foundry门户的链接修改为可点击的形式，使得用户可以更便捷地访问相关信息。此外，文档中的多个链接也经过了轻微的文本格式调整。在总体结构上，文档没有发生实质性的变化，依然保持其原有的内容和功能，但更新增强了用户在阅读文档时获取信息的体验。

## articles/ai-services/openai/concepts/gpt-with-vision.md{#item-991388}

<details>
<summary>Diff</summary>
````diff
@@ -78,14 +78,14 @@ This section describes the limitations of vision-enabled chat models.
 
 - **Maximum input image size**: The maximum size for input images is restricted to 20 MB.
 - **Low resolution accuracy**: When images are analyzed using the "low resolution" setting, it allows for faster responses and uses fewer input tokens for certain use cases. However, this could impact the accuracy of object and text recognition within the image.
-- **Image chat restriction**: When you upload images in Azure AI Foundry portal or the API, there is a limit of 10 images per chat call.
+- **Image chat restriction**: When you upload images in [Azure AI Foundry portal](https://ai.azure.com/) or the API, there is a limit of 10 images per chat call.
 
 <!--
 ### Video support
 
 - **Low resolution**: Video frames are analyzed using GPT-4 Turbo with Vision's "low resolution" setting, which may affect the accuracy of small object and text recognition in the video.
-- **Video file limits**: Both MP4 and MOV file types are supported. In Azure AI Foundry portal, videos must be less than 3 minutes long. When you use the API there is no such limitation.
-- **Prompt limits**: Video prompts only contain one video and no images. In Azure AI Foundry portal, you can clear the session to try another video or images.
+- **Video file limits**: Both MP4 and MOV file types are supported. In [Azure AI Foundry portal](https://ai.azure.com/), videos must be less than 3 minutes long. When you use the API there is no such limitation.
+- **Prompt limits**: Video prompts only contain one video and no images. In [Azure AI Foundry portal](https://ai.azure.com/), you can clear the session to try another video or images.
 - **Limited frame selection**: The service selects 20 frames from the entire video, which might not capture all the critical moments or details. Frame selection can be approximately evenly spread through the video or focused by a specific video retrieval query, depending on the prompt.
 - **Language support**: The service primarily supports English for grounding with transcripts. Transcripts don't provide accurate information on lyrics in songs.
 -->
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新GPT视觉功能文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改对GPT与视觉功能相关文档进行了小幅更新，主要是将涉及Azure AI Foundry门户的文本转变为可点击链接。这一更改发生在描述图像和视频限制的部分，使得用户在阅读相关限制时，可以方便地直接访问Azure AI Foundry门户。此外，更新还完善了关于图像和视频限制的说明，没有引入新的内容或删除关键性信息。整体而言，这次修改旨在提升用户的阅读体验和信息获取的便利性。

## articles/ai-services/openai/concepts/provisioned-migration.md{#item-68e143}

<details>
<summary>Diff</summary>
````diff
@@ -244,7 +244,7 @@ Customers must reach out to their account teams to schedule a managed migration.
 
 ## Managing Provisioned Throughput Commitments
 
-Provisioned throughput commitments are created and managed by selecting **Management center** in the Azure AI Foundry portal's navigation menu > **Quota** > **Manage Commitments**. 
+Provisioned throughput commitments are created and managed by selecting **Management center** in the [Azure AI Foundry portal](https://ai.azure.com/)'s navigation menu > **Quota** > **Manage Commitments**. 
 
 :::image type="content" source="../media/how-to/provisioned-onboarding/notifications.png" alt-text="Screenshot of commitment purchase UI with notifications." lightbox="../media/how-to/provisioned-onboarding/notifications.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新已配置迁移文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改针对已配置迁移文档进行了小幅更新，主要是在描述如何管理已配置的吞吐量承诺时，将Azure AI Foundry门户的相关描述修改为可点击链接。具体来说，文档中提到的"Azure AI Foundry portal"现已成为一个指向实际网页的链接，使用户能够方便地访问该平台。此外，其他内容未发生变化，依然保持原有的说明和结构。该更新旨在改善用户体验，使信息获取更加便捷和高效。

## articles/ai-services/openai/concepts/use-your-data.md{#item-455d6e}

<details>
<summary>Diff</summary>
````diff
@@ -26,7 +26,7 @@ Azure OpenAI On Your Data enables you to run advanced AI models such as GPT-35-T
 :::image type="content" source="../media/use-your-data/workflow-diagram.png" alt-text="A diagram showing an example workflow.":::
 
 Typically, the development process you'd use with Azure OpenAI On Your Data is:
-1. **Ingest**: Upload files using either Azure AI Foundry portal or the ingestion API. This enables your data to be cracked, chunked and embedded into an Azure AI Search instance that can be used by Azure OpenAI models. If you have an existing [supported data source](#supported-data-sources), you can also connect it directly.
+1. **Ingest**: Upload files using either [Azure AI Foundry portal](https://ai.azure.com/) or the ingestion API. This enables your data to be cracked, chunked and embedded into an Azure AI Search instance that can be used by Azure OpenAI models. If you have an existing [supported data source](#supported-data-sources), you can also connect it directly.
 
 1. **Develop**: After trying Azure OpenAI On Your Data, begin developing your application using the available REST API and SDKs, which are available in several languages. It will create prompts and search intents to pass to the Azure OpenAI service.
 
@@ -39,7 +39,7 @@ Typically, the development process you'd use with Azure OpenAI On Your Data is:
     
     1. **Response generation**: The resulting data is submitted along with other information like the system message to the Large Language Model (LLM) and the response is sent back to the application.
 
-To get started, [connect your data source](../use-your-data-quickstart.md) using Azure AI Foundry portal and start asking questions and chatting on your data.
+To get started, [connect your data source](../use-your-data-quickstart.md) using [Azure AI Foundry portal](https://ai.azure.com/) and start asking questions and chatting on your data.
 
 ## Azure Role-based access controls (Azure RBAC) for adding data sources
 
@@ -140,7 +140,7 @@ Azure OpenAI On Your Data lets you restrict the documents that can be used in re
 
 ### Index field mapping 
 
-If you're using your own index, you'll be prompted in the Azure AI Foundry portal to define which fields you want to map for answering questions when you add your data source. You can provide multiple fields for *Content data*, and should include all fields that have text pertaining to your use case. 
+If you're using your own index, you'll be prompted in the [Azure AI Foundry portal](https://ai.azure.com/) to define which fields you want to map for answering questions when you add your data source. You can provide multiple fields for *Content data*, and should include all fields that have text pertaining to your use case. 
 
 :::image type="content" source="../media/use-your-data/index-data-mapping.png" alt-text="A screenshot showing the index field mapping options in Azure AI Foundry portal." lightbox="../media/use-your-data/index-data-mapping.png":::
 
@@ -193,7 +193,7 @@ You might want to use Azure Blob Storage as a data source if you want to connect
 
 To keep your Azure AI Search index up-to-date with your latest data, you can schedule an automatic index refresh rather than manually updating it every time your data is updated. Automatic index refresh is only available when you choose **Azure Blob Storage** as the data source. To enable an automatic index refresh:
 
-1. [Add a data source](../quickstart.md) using Azure AI Foundry portal.
+1. [Add a data source](../quickstart.md) using [Azure AI Foundry portal](https://ai.azure.com/).
 1. Under **Select or add data source** select **Indexer schedule** and choose the refresh cadence you would like to apply.
 
     :::image type="content" source="../media/use-your-data/indexer-schedule.png" alt-text="A screenshot of the indexer schedule in Azure AI Foundry portal." lightbox="../media/use-your-data/indexer-schedule.png":::
@@ -225,7 +225,7 @@ To modify the schedule, you can use the [Azure portal](https://portal.azure.com/
 
 # [Upload files (preview)](#tab/file-upload)
 
-Using Azure AI Foundry portal, you can upload files from your machine to try Azure OpenAI On Your Data. You also have the option to create a new Azure Blob Storage account and Azure AI Search resource. The service then stores the files to an Azure storage container and performs ingestion from the container. You can use the [quickstart](../use-your-data-quickstart.md) article to learn how to use this data source option.
+Using [Azure AI Foundry portal](https://ai.azure.com/), you can upload files from your machine to try Azure OpenAI On Your Data. You also have the option to create a new Azure Blob Storage account and Azure AI Search resource. The service then stores the files to an Azure storage container and performs ingestion from the container. You can use the [quickstart](../use-your-data-quickstart.md) article to learn how to use this data source option.
 
 :::image type="content" source="../media/quickstarts/add-your-data-source.png" alt-text="A screenshot showing options for selecting a data source in Azure AI Foundry portal." lightbox="../media/quickstarts/add-your-data-source.png":::
 
@@ -309,11 +309,11 @@ Mapping these fields correctly helps ensure the model has better response and ci
 
 ### Use Elasticsearch as a data source via API  
 
-Along with using Elasticsearch databases in Azure AI Foundry portal, you can also use your Elasticsearch database using the [API](../references/elasticsearch.md). 
+Along with using Elasticsearch databases in [Azure AI Foundry portal](https://ai.azure.com/), you can also use your Elasticsearch database using the [API](../references/elasticsearch.md). 
 
 # [MongoDB Atlas (preview)](#tab/mongo-db-atlas)
 
-You can connect your MongoDB Atlas vector index with Azure OpenAI On Your Data for inferencing. You can use it through the Azure AI Foundry portal, API and SDK.
+You can connect your MongoDB Atlas vector index with Azure OpenAI On Your Data for inferencing. You can use it through the [Azure AI Foundry portal](https://ai.azure.com/), API and SDK.
 
 ### Prerequisites 
 
@@ -364,15 +364,15 @@ When you add your MongoDB Atlas data source, you can specify data fields to prop
 
 ## Deploy to a copilot (preview), Teams app (preview), or web app 
 
-After you connect Azure OpenAI to your data, you can deploy it using the **Deploy to** button in Azure AI Foundry portal.
+After you connect Azure OpenAI to your data, you can deploy it using the **Deploy to** button in [Azure AI Foundry portal](https://ai.azure.com/).
 
 :::image type="content" source="../media/use-your-data/deploy-model.png" alt-text="A screenshot showing the model deployment button in Azure AI Foundry portal." lightbox="../media/use-your-data/deploy-model.png":::
 
 This gives you multiple options for deploying your solution.
 
 #### [Copilot (preview)](#tab/copilot)
 
-You can deploy to a copilot in [Copilot Studio](/microsoft-copilot-studio/fundamentals-what-is-copilot-studio) (preview) directly from Azure AI Foundry portal, enabling you to bring conversational experiences to various channels such as: Microsoft Teams, websites, Dynamics 365, and other [Azure Bot Service channels](/microsoft-copilot-studio/publication-connect-bot-to-azure-bot-service-channels). The tenant used in the Azure OpenAI service and Copilot Studio (preview) should be the same. For more information, see [Use a connection to Azure OpenAI On Your Data](/microsoft-copilot-studio/nlu-generative-answers-azure-openai).
+You can deploy to a copilot in [Copilot Studio](/microsoft-copilot-studio/fundamentals-what-is-copilot-studio) (preview) directly from [Azure AI Foundry portal](https://ai.azure.com/), enabling you to bring conversational experiences to various channels such as: Microsoft Teams, websites, Dynamics 365, and other [Azure Bot Service channels](/microsoft-copilot-studio/publication-connect-bot-to-azure-bot-service-channels). The tenant used in the Azure OpenAI service and Copilot Studio (preview) should be the same. For more information, see [Use a connection to Azure OpenAI On Your Data](/microsoft-copilot-studio/nlu-generative-answers-azure-openai).
 
 > [!NOTE]
 > Deploying to a copilot in Copilot Studio (preview) is only available in US regions.
@@ -394,15 +394,15 @@ A Teams app lets you bring conversational experience to your users in Teams to i
 - Your Azure account has been assigned **Cognitive Services OpenAI user** or **Cognitive Services OpenAI Contributor** role of the Azure OpenAI resource you're using, allowing your account to make Azure OpenAI API calls. For more information, see [Azure OpenAI On Your data configuration](../how-to/on-your-data-configuration.md#using-the-api) and [Add role assignment to an Azure OpenAI resource](/azure/ai-services/openai/how-to/role-based-access-control#add-role-assignment-to-an-azure-openai-resource) for instructions on setting this role in the Azure portal. 
 
 
-You can deploy to a standalone Teams app directly from Azure AI Foundry portal. Follow the steps below: 
+You can deploy to a standalone Teams app directly from [Azure AI Foundry portal](https://ai.azure.com/). Follow the steps below: 
 
 1. After you've added your data to the chat model, select **Deploy** and then **a new Teams app (preview)**. 
 
 1. Enter the name of your Teams app and download the resulting .zip file.
 
 1. Extract the .zip file and open the folder in Visual Studio Code.
 
-1. If you chose **API key** in the data connection step, manually copy and paste your Azure AI Search key into the `src\prompts\chat\config.json` file. Your Azure AI Search Key can be found in Azure AI Foundry portal Playground by selecting the **View code** button with the key located under Azure Search Resource Key. If you chose **System assigned managed identity**, you can skip this step. Learn more about different data connection options in the [Data connection](/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search#data-connection) section.
+1. If you chose **API key** in the data connection step, manually copy and paste your Azure AI Search key into the `src\prompts\chat\config.json` file. Your Azure AI Search Key can be found in [Azure AI Foundry portal](https://ai.azure.com/) Playground by selecting the **View code** button with the key located under Azure Search Resource Key. If you chose **System assigned managed identity**, you can skip this step. Learn more about different data connection options in the [Data connection](/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search#data-connection) section.
 
 1. Open the Visual Studio Code terminal and log into Azure CLI, selecting the account that you assigned **Cognitive Service OpenAI User** role to. Use the `az login` command in the terminal to log in.
 
@@ -468,7 +468,7 @@ A small chunk size like 256 produces more granular chunks. This size also means
 
 ### Runtime parameters
 
-You can modify the following additional settings in the **Data parameters** section in Azure AI Foundry portal and [the API](../references/on-your-data.md). You don't need to reingest your data when you update these parameters. 
+You can modify the following additional settings in the **Data parameters** section in [Azure AI Foundry portal](https://ai.azure.com/) and [the API](../references/on-your-data.md). You don't need to reingest your data when you update these parameters. 
 
 
 |Parameter name  | Description  |
@@ -485,7 +485,7 @@ It's possible for the model to return `"TYPE":"UNCITED_REFERENCE"` instead of `"
 
 You can define a system message to steer the model's reply when using Azure OpenAI On Your Data. This message allows you to customize your replies on top of the retrieval augmented generation (RAG) pattern that Azure OpenAI On Your Data uses. The system message is used in addition to an internal base prompt to provide the experience. To support this, we truncate the system message after a specific [number of tokens](#token-usage-estimation-for-azure-openai-on-your-data) to ensure the model can answer questions using your data. If you are defining extra behavior on top of the default experience, ensure that your system prompt is detailed and explains the exact expected customization. 
 
-Once you select add your dataset, you can use the **System message** section in the Azure AI Foundry portal, or the `role_information` [parameter in the API](../references/on-your-data.md).
+Once you select add your dataset, you can use the **System message** section in the [Azure AI Foundry portal](https://ai.azure.com/), or the `role_information` [parameter in the API](../references/on-your-data.md).
 
 :::image type="content" source="../media/use-your-data/system-message.png" alt-text="A screenshot showing the system message option in Azure AI Foundry portal." lightbox="../media/use-your-data/system-message.png":::
 
@@ -680,7 +680,7 @@ token_output = TokenEstimator.estimate_tokens(input_text)
 
 ## Troubleshooting 
 
-To troubleshoot failed operations, always look out for errors or warnings specified either in the API response or Azure AI Foundry portal. Here are some of the common errors and warnings: 
+To troubleshoot failed operations, always look out for errors or warnings specified either in the API response or [Azure AI Foundry portal](https://ai.azure.com/). Here are some of the common errors and warnings: 
 
 ### Failed ingestion jobs
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新使用您的数据文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改对“使用您的数据”文档进行了小幅更新，主要是将涉及Azure AI Foundry门户的文本替换为可点击链接。这一更新出现在多个部分，使得指向Azure AI Foundry门户的引用更加显眼并方便用户访问。此外，文档的主要内容和结构未发生变化，依然保留原有的信息和说明。此项更新的目的是改善用户体验，使用户能够更容易获取所需的信息。

## articles/ai-services/openai/faq.yml{#item-6deb71}

<details>
<summary>Diff</summary>
````diff
@@ -127,7 +127,7 @@ sections:
         answer: |
           A Limited Access registration form is not required to access most Azure OpenAI models. Learn more on the [Azure OpenAI Limited Access page](/legal/cognitive-services/openai/limited-access?context=/azure/ai-services/openai/context/context).
       - question: |
-          My guest account has been given access to an Azure OpenAI resource, but I'm unable to access that resource in the Azure AI Foundry portal. How do I enable access?
+          My guest account has been given access to an Azure OpenAI resource, but I'm unable to access that resource in the [Azure AI Foundry portal](https://ai.azure.com/). How do I enable access?
         answer: | 
           This is expected behavior when using the default sign-in experience for the [Azure AI Foundry](https://ai.azure.com).
           
@@ -139,7 +139,7 @@ sections:
           4. Enter the domain name of the organization that granted your guest account access to the Azure OpenAI resource. 
           5. Now sign-in with your guest account credentials. 
           
-          You should now be able to access the resource via the Azure AI Foundry portal.
+          You should now be able to access the resource via the [Azure AI Foundry portal](https://ai.azure.com/).
           
           Alternatively if you're signed into the [Azure portal](https://portal.azure.com) from the Azure OpenAI resource's Overview pane you can select **Go to Azure AI Foundry** to automatically sign in with the appropriate organizational context.   
   
@@ -177,7 +177,7 @@ sections:
         answer:
           We do offer an Availability SLA for all resources and a Latency SLA for Provisioned-Managed Deployments. For more information about the SLA for Azure OpenAI Service, see the [Service Level Agreements (SLA) for Online Services page](https://azure.microsoft.com/support/legal/sla/cognitive-services/v1_1/). 
       - question: |
-          How do I enable fine-tuning? Create a custom model is greyed out in Azure AI Foundry portal.  
+          How do I enable fine-tuning? Create a custom model is greyed out in [Azure AI Foundry portal](https://ai.azure.com/).  
         answer: |
           In order to successfully access fine-tuning, you need Cognitive Services OpenAI Contributor assigned. Even someone with high-level Service Administrator permissions would still need this account explicitly set in order to access fine-tuning. For more information, please review the [role-based access control guidance](/azure/ai-services/openai/how-to/role-based-access-control#cognitive-services-openai-contributor).
       - question: |
@@ -306,9 +306,9 @@ sections:
         answer:
           You can customize your published web app in the Azure portal. The source code for the published web app is [available on GitHub](https://go.microsoft.com/fwlink/?linkid=2244395), where you can find information on changing the app frontend, as well as instructions for building and deploying the app.
       - question: |
-          Will my web app be overwritten when I deploy the app again from the Azure AI Foundry portal?
+          Will my web app be overwritten when I deploy the app again from the [Azure AI Foundry portal](https://ai.azure.com/)?
         answer:
-          Your app code won't be overwritten when you update your app. The app will be updated to use the Azure OpenAI resource, Azure AI Search index (if you're using Azure OpenAI on your data), and model settings selected in the Azure AI Foundry portal without any change to the appearance or functionality. 
+          Your app code won't be overwritten when you update your app. The app will be updated to use the Azure OpenAI resource, Azure AI Search index (if you're using Azure OpenAI on your data), and model settings selected in the [Azure AI Foundry portal](https://ai.azure.com/) without any change to the appearance or functionality. 
   - name: Using your data
     questions:
       - question: |
@@ -318,15 +318,15 @@ sections:
       - question: |
           How can I access Azure OpenAI on your data?  
         answer:
-          All Azure OpenAI customers can use Azure OpenAI on your data via the Azure AI Foundry portal and Rest API.
+          All Azure OpenAI customers can use Azure OpenAI on your data via the [Azure AI Foundry portal](https://ai.azure.com/) and Rest API.
       - question: |
           What data sources does Azure OpenAI on your data support?
         answer:
           Azure OpenAI on your data supports ingestion from Azure AI Search, Azure Blob Storage, and uploading local files. You can learn more about Azure OpenAI on your data from the [conceptual article](./concepts/use-your-data.md) and [quickstart](./use-your-data-quickstart.md).
       - question: |
           How much does it cost to use Azure OpenAI on your data?
         answer:
-          When using Azure OpenAI on your data, you incur costs when you use Azure AI Search, Azure Blob Storage, Azure Web App Service, semantic search and OpenAI models. There's no additional cost for using the "your data" feature in the Azure AI Foundry portal.
+          When using Azure OpenAI on your data, you incur costs when you use Azure AI Search, Azure Blob Storage, Azure Web App Service, semantic search and OpenAI models. There's no additional cost for using the "your data" feature in the [Azure AI Foundry portal](https://ai.azure.com/).
       - question: |
           How can I customize or automate the index creation process?
         answer:
@@ -356,7 +356,7 @@ sections:
         answer:
           You must send queries in the same language of your data. Your data can be in any of the languages supported by [Azure AI Search](/azure/search/search-language-support).
       - question: |
-          If Semantic Search is enabled for my Azure AI Search resource, will it be automatically applied to Azure OpenAI on your data in the Azure AI Foundry portal?
+          If Semantic Search is enabled for my Azure AI Search resource, will it be automatically applied to Azure OpenAI on your data in the [Azure AI Foundry portal](https://ai.azure.com/)?
         answer:
           When you select "Azure AI Search" as the data source, you can choose to apply semantic search. 
           If you select "Azure Blob Container" or "Upload files" as the data source, you can create the index as usual. Afterwards you would reingest the data using the "Azure AI Search" option to select the same index and apply Semantic Search. You will then be ready to chat on your data with semantic search applied.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新常见问题文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改对常见问题（FAQ）文档进行了小幅更新，主要是在涉及Azure AI Foundry门户的条目中添加了可点击的链接。这一变化改善了用户对Azure AI Foundry门户的访问体验，在多个问题回答中，例如“我无法访问Azure AI Foundry门户”、“如何启用微调？”和“网页应用会被覆盖吗？”等，均做了相应的链接处理。此更新还包含其他相关内容，但整体结构没有变化。通过这一改进，用户可以更方便地访问相关页面，从而提升了文档的实用性和导航体验。

## articles/ai-services/openai/how-to/batch.md{#item-a131d5}

<details>
<summary>Diff</summary>
````diff
@@ -94,7 +94,7 @@ The following aren't currently supported:
 ### Batch deployment
 
 > [!NOTE]
-> In the Azure AI Foundry portal the batch deployment types will appear as `Global-Batch` and `Data Zone Batch`. To learn more about Azure OpenAI deployment types, see our [deployment types guide](../how-to/deployment-types.md).
+> In the [Azure AI Foundry portal](https://ai.azure.com/) the batch deployment types will appear as `Global-Batch` and `Data Zone Batch`. To learn more about Azure OpenAI deployment types, see our [deployment types guide](../how-to/deployment-types.md).
 
 :::image type="content" source="../media/how-to/global-batch/global-batch.png" alt-text="Screenshot that shows the model deployment dialog in Azure AI Foundry portal with Global-Batch deployment type highlighted." lightbox="../media/how-to/global-batch/global-batch.png":::
 
@@ -166,7 +166,7 @@ Yes. Similar to other deployment types, you can create content filters and assoc
 
 ### Can I request additional quota?
 
-Yes, from the quota page in the Azure AI Foundry portal. Default quota allocation can be found in the [quota and limits article](../quotas-limits.md#batch-quota).
+Yes, from the quota page in the [Azure AI Foundry portal](https://ai.azure.com/). Default quota allocation can be found in the [quota and limits article](../quotas-limits.md#batch-quota).
 
 ### What happens if the API doesn't complete my request within the 24 hour time frame?
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新批处理文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改对批处理（Batch）文档进行了小幅更新，主要是将提到Azure AI Foundry门户的文本更改为包含可点击链接。这一改动出现在关于批量部署类型和配额请求的说明中，使得用户能够更方便地直接访问Azure AI Foundry门户。此项更新改善了文档的可读性和导航性，确保用户在获取信息时能够更顺畅地跳转到相关页面，同时文档的结构和内容未发生重大变化，依然保留了原有的信息和指引。

## articles/ai-services/openai/how-to/evaluations.md{#item-dfaa1c}

<details>
<summary>Diff</summary>
````diff
@@ -104,7 +104,7 @@ Testing criteria is used to assess the effectiveness of each output generated by
 
 ## Getting started
 
-1. Select the **Azure OpenAI Evaluation (PREVIEW)** within Azure AI Foundry portal. To see this view as an option may need to first select an existing Azure OpenAI resource in a supported region.
+1. Select the **Azure OpenAI Evaluation (PREVIEW)** within [Azure AI Foundry portal](https://ai.azure.com/). To see this view as an option may need to first select an existing Azure OpenAI resource in a supported region.
 2. Select **New evaluation**
 
     :::image type="content" source="../media/how-to/evaluations/new-evaluation.png" alt-text="Screenshot of the Azure OpenAI evaluation UX with new evaluation selected." lightbox="../media/how-to/evaluations/new-evaluation.png":::
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新评估文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改对评估（Evaluations）文档进行了小幅更新，主要是在提到Azure AI Foundry门户的步骤中添加了可点击的链接。这一更新发生在用户获取启动评估的说明中，使用户可以直接访问Azure AI Foundry门户，以便更方便地了解相关功能。这一改动没有改变文档的核心内容或结构，仍然保留了原有的步骤描述，旨在增强文档的可用性和导航方便性。

## articles/ai-services/openai/how-to/fine-tuning.md{#item-5c0e85}

<details>
<summary>Diff</summary>
````diff
@@ -239,7 +239,7 @@ In order to successfully access fine-tuning, you need **Cognitive Services OpenA
 
 ### Why did my upload fail?
 
-If your file upload fails in Azure AI Foundry portal, you can view the error message under **Data files** in Azure AI Foundry portal. Hover your mouse over where it says “error” (under the status column) and an explanation of the failure will be displayed.
+If your file upload fails in [Azure AI Foundry portal](https://ai.azure.com/), you can view the error message under **Data files** in [Azure AI Foundry portal](https://ai.azure.com/). Hover your mouse over where it says “error” (under the status column) and an explanation of the failure will be displayed.
 
 :::image type="content" source="../media/fine-tuning/error.png" alt-text="Screenshot of fine-tuning error message." lightbox="../media/fine-tuning/error.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新微调文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改对微调（Fine-tuning）文档进行了小幅更新，涉及对Azure AI Foundry门户的描述中添加了可点击的链接。这一更改出现在关于文件上传失败的故障排除说明中，使得用户能够直接访问Azure AI Foundry门户，获取更详细的信息和相关功能。这一改动旨在提升文档的可用性和导航方便性，同时保持了原有内容的准确性和清晰度。

## articles/ai-services/openai/how-to/on-your-data-configuration.md{#item-4875d3}

<details>
<summary>Diff</summary>
````diff
@@ -169,7 +169,7 @@ This step can be skipped only if you have a [shared private link](#create-shared
 
 You can disable public network access of your Azure OpenAI resource in the Azure portal. 
 
-To allow access to your Azure OpenAI Service from your client machines, like using Azure AI Foundry portal, you need to create [private endpoint connections](/azure/ai-services/cognitive-services-virtual-networks?tabs=portal#use-private-endpoints) that connect to your Azure OpenAI resource.
+To allow access to your Azure OpenAI Service from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/), you need to create [private endpoint connections](/azure/ai-services/cognitive-services-virtual-networks?tabs=portal#use-private-endpoints) that connect to your Azure OpenAI resource.
 
 
 ## Configure Azure AI Search
@@ -193,7 +193,7 @@ For more information, see the [Azure AI Search RBAC article](/azure/search/searc
 
 You can disable public network access of your Azure AI Search resource in the Azure portal. 
 
-To allow access to your Azure AI Search resource from your client machines, like using Azure AI Foundry portal, you need to create [private endpoint connections](/azure/search/service-create-private-endpoint) that connect to your Azure AI Search resource.
+To allow access to your Azure AI Search resource from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/), you need to create [private endpoint connections](/azure/search/service-create-private-endpoint) that connect to your Azure AI Search resource.
 
 
 ### Enable trusted service
@@ -247,7 +247,7 @@ In the Azure portal, navigate to your storage account networking tab, choose "Se
 
 You can disable public network access of your Storage Account in the Azure portal. 
 
-To allow access to your Storage Account from your client machines, like using Azure AI Foundry portal, you need to create [private endpoint connections](/azure/storage/common/storage-private-endpoints) that connect to your blob storage.
+To allow access to your Storage Account from your client machines, like using [Azure AI Foundry portal](https://ai.azure.com/), you need to create [private endpoint connections](/azure/storage/common/storage-private-endpoints) that connect to your blob storage.
 
 
 
@@ -276,9 +276,9 @@ To enable the developers to use these resources to build applications, the admin
 
 |Role| Resource | Description |
 |--|--|--|
-| `Cognitive Services OpenAI Contributor` | Azure OpenAI | Call public ingestion API from Azure AI Foundry portal. The `Contributor` role is not enough, because if you only have `Contributor` role, you cannot call data plane API via Microsoft Entra ID authentication, and Microsoft Entra ID authentication is required in the secure setup described in this article. |
-| `Contributor` | Azure AI Search | List API-Keys to list indexes from Azure AI Foundry portal.|
-| `Contributor` | Storage Account | List Account SAS to upload files from Azure AI Foundry portal.|
+| `Cognitive Services OpenAI Contributor` | Azure OpenAI | Call public ingestion API from [Azure AI Foundry portal](https://ai.azure.com/). The `Contributor` role is not enough, because if you only have `Contributor` role, you cannot call data plane API via Microsoft Entra ID authentication, and Microsoft Entra ID authentication is required in the secure setup described in this article. |
+| `Contributor` | Azure AI Search | List API-Keys to list indexes from [Azure AI Foundry portal](https://ai.azure.com/).|
+| `Contributor` | Storage Account | List Account SAS to upload files from [Azure AI Foundry portal](https://ai.azure.com/).|
 | `Contributor` | The resource group or Azure subscription where the developer need to deploy the web app to | Deploy web app to the developer's Azure subscription.|
 | `Role Based Access Control Administrator` | Azure OpenAI | Permission to configure the necessary role assignment on the Azure OpenAI resource. Enables the web app to call Azure OpenAI. |
 
@@ -302,7 +302,7 @@ Configure your local machine `hosts` file to point your resources host names to
 
 ## Azure AI Foundry portal
 
-You should be able to use all Azure AI Foundry portal features, including both ingestion and inference, from your on-premises client machines.
+You should be able to use all [Azure AI Foundry portal](https://ai.azure.com/) features, including both ingestion and inference, from your on-premises client machines.
 
 ## Web app
 The web app communicates with your Azure OpenAI resource. Since your Azure OpenAI resource has public network disabled, the web app needs to be set up to use the private endpoint in your virtual network to access your Azure OpenAI resource.
@@ -313,7 +313,7 @@ The web app needs to resolve your Azure OpenAI host name to the private IP of th
 1. [Add a DNS record](/azure/dns/private-dns-getstarted-portal#create-an-additional-dns-record). The IP is the private IP of the private endpoint for your Azure OpenAI resource, and you can get the IP address from the network interface associated with the private endpoint for your Azure OpenAI.
 1. [Link the private DNS zone to your virtual network](/azure/dns/private-dns-getstarted-portal#link-the-virtual-network) so the web app integrated in this virtual network can use this private DNS zone.
 
-When deploying the web app from Azure AI Foundry portal, select the same location with the virtual network, and select a proper SKU, so it can support the [virtual network integration feature](/azure/app-service/overview-vnet-integration). 
+When deploying the web app from [Azure AI Foundry portal](https://ai.azure.com/), select the same location with the virtual network, and select a proper SKU, so it can support the [virtual network integration feature](/azure/app-service/overview-vnet-integration). 
 
 After the web app is deployed, from the Azure portal networking tab, configure the web app outbound traffic virtual network integration, choose the third subnet that you reserved for web app.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新数据配置文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改对数据配置文档进行了小幅更新，主要是在多个段落中添加了Azure AI Foundry门户的可点击链接。这些更改涉及文件上传、私有端点连接以及Web应用程序的配置等内容，使用户能够更方便地访问相关Portal。此外，所有提到的Azure AI Foundry门户的位置都被链接化，增强了文档的可用性。虽然更新了链接，文档的整体结构和内容保持不变，继续提供必要的指导。

## articles/ai-services/openai/how-to/provisioned-get-started.md{#item-c8df1c}

<details>
<summary>Diff</summary>
````diff
@@ -36,7 +36,7 @@ Creating a new deployment requires available (unused) quota to cover the desired
 
 Then 200 PTUs of quota are considered used, and there are 300 PTUs available for use to create new deployments. 
 
-A default amount of global, data zone, and regional provisioned quota is assigned to eligible subscriptions in several regions. You can view the quota available to you in a region by visiting the Quotas pane in Azure AI Foundry portal and selecting the desired subscription and region. For example, the screenshot below shows a quota limit of 500 PTUs in West US for the selected subscription. Note that you might see lower values of available default quotas. 
+A default amount of global, data zone, and regional provisioned quota is assigned to eligible subscriptions in several regions. You can view the quota available to you in a region by visiting the Quotas pane in [Azure AI Foundry portal](https://ai.azure.com/) and selecting the desired subscription and region. For example, the screenshot below shows a quota limit of 500 PTUs in West US for the selected subscription. Note that you might see lower values of available default quotas. 
 
 :::image type="content" source="../media/provisioned/available-quota.png" alt-text="A screenshot of the available quota in Azure AI Foundry portal." lightbox="../media/provisioned/available-quota.png":::
 
@@ -106,7 +106,7 @@ REST, ARM template, Bicep, and Terraform can also be used to create deployments.
 
 Due to the dynamic nature of capacity availability, it is possible that the region of your selected resource might not have the service capacity to create the deployment of the specified model, version, and number of PTUs. 
 
-In this event, the wizard in Azure AI Foundry portal will direct you to other regions with available quota and capacity to create a deployment of the desired model. If this happens, the deployment dialog will look like this: 
+In this event, the wizard in [Azure AI Foundry portal](https://ai.azure.com/) will direct you to other regions with available quota and capacity to create a deployment of the desired model. If this happens, the deployment dialog will look like this: 
 
 :::image type="content" source="../media/provisioned/deployment-screen-2.png" alt-text="Screenshot of the Azure AI Foundry portal deployment page for a provisioned deployment with no capacity available." lightbox="../media/provisioned/deployment-screen-2.png":::
 
@@ -165,7 +165,7 @@ The inferencing code for provisioned deployments is the same a standard deployme
 
 ## Understanding expected throughput
 The amount of throughput that you can achieve on the endpoint is a factor of the number of PTUs deployed, input size, output size, and call rate. The number of concurrent calls and total tokens processed can vary based on these values. Our recommended way for determining the throughput for your deployment is as follows:
-1. Use the Capacity calculator for a sizing estimate. You can find the capacity calculator in Azure AI Foundry portal under the quotas page and Provisioned tab.  
+1. Use the Capacity calculator for a sizing estimate. You can find the capacity calculator in [Azure AI Foundry portal](https://ai.azure.com/) under the quotas page and Provisioned tab.  
 1. Benchmark the load using real traffic workload. For more information about benchmarking, see the [benchmarking](#run-a-benchmark) section.
 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新已配置入门文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改对已配置入门文档进行了轻微更新，主要是将多个提到的Azure AI Foundry门户位置添加了可点击的链接。这些更改包括有关配额查看、部署向导以及计算容量的具体描述，确保用户可以方便地访问相关的门户页面。此更新旨在提升文档的可用性，方便用户获取必要的信息和功能，同时保持文档的原有结构和内容。

## articles/ai-services/openai/how-to/provisioned-throughput-onboarding.md{#item-3eb72b}

<details>
<summary>Diff</summary>
````diff
@@ -95,7 +95,7 @@ Customers that require long-term usage of provisioned, data zoned provisioned, a
 
 Discounts on top of the hourly usage price can be obtained by purchasing an Azure Reservation for Azure OpenAI Provisioned, Data Zone Provisioned, and Global Provisioned. An Azure Reservation is a term-discounting mechanism shared by many Azure products. For example, Compute and Cosmos DB. For Azure OpenAI Provisioned, Data Zone Provisioned, and Global Provisioned, the reservation provides a discount in exchange for committing to payment for fixed number of PTUs for a one-month or one-year period.  
 
-* Azure Reservations are purchased via the Azure portal, not the Azure AI Foundry portal Link to Azure reservation portal.
+* Azure Reservations are purchased via the Azure portal, not the [Azure AI Foundry portal](https://ai.azure.com/) Link to Azure reservation portal.
 
 * Reservations are purchased regionally and can be flexibly scoped to cover usage from a group of deployments. Reservation scopes include: 
 
@@ -147,4 +147,4 @@ After a reservation is created, it is a best practice monitor it to ensure it is
 
 - [Provisioned Throughput Units (PTU) getting started guide](./provisioned-get-started.md)
 - [Provisioned Throughput Units (PTU) concepts](../concepts/provisioned-throughput.md)
-- [Provisioned Throughput reservation documentation](https://aka.ms/oai/docs/ptum-reservations) 
\ No newline at end of file
+- [Provisioned Throughput reservation documentation](https://aka.ms/oai/docs/ptum-reservations) 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新已配置吞吐量入门文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次修改对已配置吞吐量入门文档进行了小幅更新，主要是在有关Azure预留的描述中，增加了对Azure AI Foundry门户的可点击链接。这一更改有助于用户更方便地访问相关的门户页面，确保他们能够快速找到购买Azure预留所需的资源。此外，文档末尾的链接格式也进行了小幅改动，以增强文本的一致性和链接的可读性。整体而言，这些改动提升了文档的易用性，而没有改变其主要内容。

## articles/ai-services/openai/how-to/quota.md{#item-9440c2}

<details>
<summary>Diff</summary>
````diff
@@ -44,11 +44,11 @@ The flexibility to distribute TPM globally within a subscription and region has
 
 When you create a model deployment, you have the option to assign Tokens-Per-Minute (TPM) to that deployment. TPM can be modified in increments of 1,000, and will map to the TPM and RPM rate limits enforced on your deployment, as discussed above.
 
-To create a new deployment from within the Azure AI Foundry portal select **Deployments** > **Deploy model** > **Deploy base model** > **Select Model** > **Confirm**.
+To create a new deployment from within the [Azure AI Foundry portal](https://ai.azure.com/) select **Deployments** > **Deploy model** > **Deploy base model** > **Select Model** > **Confirm**.
 
 :::image type="content" source="../media/quota/deployment-new.png" alt-text="Screenshot of the deployment UI of Azure AI Foundry" lightbox="../media/quota/deployment-new.png":::
 
-Post deployment you can adjust your TPM allocation by selecting and editing your model from the **Deployments** page in Azure AI Foundry portal. You can also modify this setting from the **Management** > **Model quota** page.
+Post deployment you can adjust your TPM allocation by selecting and editing your model from the **Deployments** page in [Azure AI Foundry portal](https://ai.azure.com/). You can also modify this setting from the **Management** > **Model quota** page.
 
 > [!IMPORTANT]
 > Quotas and limits are subject to change, for the most up-date-information consult our [quotas and limits article](../quotas-limits.md).
@@ -68,7 +68,7 @@ All other model classes have a common max TPM value.
 
 ## View and request quota
 
-For an all up view of your quota allocations across deployments in a given region, select **Management** > **Quota** in Azure AI Foundry portal:
+For an all up view of your quota allocations across deployments in a given region, select **Management** > **Quota** in [Azure AI Foundry portal](https://ai.azure.com/):
 
 :::image type="content" source="../media/quota/quota-new.png" alt-text="Screenshot of the quota UI of Azure AI Foundry" lightbox="../media/quota/quota-new.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新配额文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次对配额文档的修改包含了一些小的更新，特别在描述如何创建和调整模型部署的步骤中，添加了对Azure AI Foundry门户的可点击链接。这一更改旨在提升用户体验，使用户能够直接访问相关的平台进行操作。此外，文中提到的管理页面和配额页面也被更新了链接格式，从而保持一致性和清晰性。整体上，这些更新增强了文档的可用性，并确保读者能够轻松获取所需的资源和信息。

## articles/ai-services/openai/how-to/role-based-access-control.md{#item-4b9817}

<details>
<summary>Diff</summary>
````diff
@@ -50,8 +50,8 @@ If a user were granted role-based access to only this role for an Azure OpenAI r
 
 ✅ View the resource in [Azure portal](https://portal.azure.com) <br>
 ✅ View the resource endpoint under **Keys and Endpoint** <br>
-✅ Ability to view the resource and associated model deployments in Azure AI Foundry portal. <br>
-✅ Ability to view what models are available for deployment in Azure AI Foundry portal. <br>
+✅ Ability to view the resource and associated model deployments in [Azure AI Foundry portal](https://ai.azure.com/). <br>
+✅ Ability to view what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/). <br>
 ✅ Use the Chat, Completions, and DALL-E (preview) playground experiences to generate text and images with any models that have already been deployed to this Azure OpenAI resource. <br>
 ✅ Make inference API calls with Microsoft Entra ID.
 
@@ -93,7 +93,7 @@ This role is typically granted access at the resource group level for a user in
 ✅ View resources in the assigned resource group in the [Azure portal](https://portal.azure.com). <br>
 ✅ View the resource endpoint under **Keys and Endpoint** <br>
 ✅ View/Copy/Regenerate keys under **Keys and Endpoint** <br>
-✅ Ability to view what models are available for deployment in Azure AI Foundry portal <br>
+✅ Ability to view what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/) <br>
 ✅ Use the Chat, Completions, and DALL-E (preview) playground experiences to generate text and images with any models that have already been deployed to this Azure OpenAI resource <br>
 ✅ Create customized content filters <br>
 ✅ Add data sources to Azure OpenAI On Your Data. **You must also have the [Cognitive Services OpenAI Contributor](#cognitive-services-openai-contributor) role as well**.
@@ -114,27 +114,27 @@ Viewing quota requires the **Cognitive Services Usages Reader** role. This role
 
 This role can be found in the Azure portal under **Subscriptions** > ***Access control (IAM)** > **Add role assignment** > search for **Cognitive Services Usages Reader**. The role must be applied at the subscription level, it does not exist at the resource level.
 
-If you don't wish to use this role, the subscription **Reader** role provides equivalent access, but it also grants read access beyond the scope of what is needed for viewing quota. Model deployment via the Azure AI Foundry portal is also partially dependent on the presence of this role.
+If you don't wish to use this role, the subscription **Reader** role provides equivalent access, but it also grants read access beyond the scope of what is needed for viewing quota. Model deployment via the [Azure AI Foundry portal](https://ai.azure.com/) is also partially dependent on the presence of this role.
 
 This role provides little value by itself and is instead typically assigned in combination with one or more of the previously described roles.
 
 #### Cognitive Services Usages Reader + Cognitive Services OpenAI User
 
 All the capabilities of Cognitive Services OpenAI User plus the ability to:
 
-✅ View quota allocations in Azure AI Foundry portal
+✅ View quota allocations in [Azure AI Foundry portal](https://ai.azure.com/)
 
 #### Cognitive Services Usages Reader + Cognitive Services OpenAI Contributor
 
 All the capabilities of Cognitive Services OpenAI Contributor plus the ability to:
 
-✅ View quota allocations in Azure AI Foundry portal
+✅ View quota allocations in [Azure AI Foundry portal](https://ai.azure.com/)
 
 #### Cognitive Services Usages Reader + Cognitive Services Contributor
 
 All the capabilities of Cognitive Services Contributor plus the ability to:
 
-✅ View & edit quota allocations in Azure AI Foundry portal <br>
+✅ View & edit quota allocations in [Azure AI Foundry portal](https://ai.azure.com/) <br>
 ✅ Create new model deployments or edit existing model deployments (via Azure AI Foundry) <br>
 
 ## Summary
@@ -143,8 +143,8 @@ All the capabilities of Cognitive Services Contributor plus the ability to:
 |-------------|--------------------|------------------------|------------------|-------------------------|
 |View the resource in Azure portal |✅|✅|✅| ➖ |
 |View the resource endpoint under “Keys and Endpoint” |✅|✅|✅| ➖ |
-|View the resource and associated model deployments in Azure AI Foundry portal |✅|✅|✅| ➖ |
-|View what models are available for deployment in Azure AI Foundry portal|✅|✅|✅| ➖ |
+|View the resource and associated model deployments in [Azure AI Foundry portal](https://ai.azure.com/) |✅|✅|✅| ➖ |
+|View what models are available for deployment in [Azure AI Foundry portal](https://ai.azure.com/)|✅|✅|✅| ➖ |
 |Use the Chat, Completions, and DALL-E (preview) playground experiences with any models that have already been deployed to this Azure OpenAI resource.|✅|✅|✅| ➖ |
 |Create or edit model deployments|❌|✅|✅| ➖ |
 |Create or deploy custom fine-tuned models|❌|✅|✅| ➖ |
@@ -162,7 +162,7 @@ All the capabilities of Cognitive Services Contributor plus the ability to:
 
 **Issue:**
 
-When selecting an existing Azure Cognitive Search resource the search indices don't load, and the loading wheel spins continuously. In Azure AI Foundry portal, go to **Playground Chat** > **Add your data (preview)** under Assistant setup. Selecting **Add a data source** opens a modal that allows you to add a data source through either Azure Cognitive Search or Blob Storage. Selecting the Azure Cognitive Search option and an existing Azure Cognitive Search resource should load the available Azure Cognitive Search indices to select from.
+When selecting an existing Azure Cognitive Search resource the search indices don't load, and the loading wheel spins continuously. In [Azure AI Foundry portal](https://ai.azure.com/), go to **Playground Chat** > **Add your data (preview)** under Assistant setup. Selecting **Add a data source** opens a modal that allows you to add a data source through either Azure Cognitive Search or Blob Storage. Selecting the Azure Cognitive Search option and an existing Azure Cognitive Search resource should load the available Azure Cognitive Search indices to select from.
 
 **Root cause** 
 
@@ -188,7 +188,7 @@ For this API call, you need a **subscription-level scope** role. You can use the
 
 **Root cause:**
 
-Insufficient subscription-level access for the user attempting to access the blob storage in Azure AI Foundry portal. The user may **not** have the necessary permissions to call the Azure Management API endpoint: ```https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{accountName}/listAccountSas?api-version=2022-09-01```
+Insufficient subscription-level access for the user attempting to access the blob storage in [Azure AI Foundry portal](https://ai.azure.com/). The user may **not** have the necessary permissions to call the Azure Management API endpoint: ```https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.Storage/storageAccounts/{accountName}/listAccountSas?api-version=2022-09-01```
 
 Public access to the blob storage is disabled by the owner of the Azure subscription for security reasons.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新基于角色的访问控制文档中的链接. Locale: zh_CN"
}
```

### Explanation
此次对基于角色的访问控制文档进行了小幅更新，主要内容是为提到的Azure和Azure AI Foundry门户中的相关操作增加了可点击链接。所有重要步骤和信息均添加了指向相应门户的链接，便于用户更方便地导航和访问。修改的内容包括用户在Azure AI Foundry中的操作权限描述、相关设置和问题解决方案中的引用，以增强体验的连贯性和友好性。整体来说，这些更新提升了文档的可用性，并确保用户能够轻松找到所需的在线资源。

## articles/ai-services/openai/how-to/use-web-app.md{#item-802413}

<details>
<summary>Diff</summary>
````diff
@@ -17,7 +17,7 @@ recommendations: false
 > [!NOTE]
 > The web app and its [source code](https://github.com/microsoft/sample-app-aoai-chatGPT) are provided "as is" and as a sample only. Customers are responsible for all customization and implementation of their web apps. See the support section for the web app on [GitHub](https://github.com/microsoft/sample-app-aoai-chatGPT/blob/main/SUPPORT.md) for more information.
 
-Along with Azure AI Foundry portal, APIs, and SDKs, you can use the customizable standalone web app to interact with Azure OpenAI models by using a graphical user interface. Key features include:
+Along with [Azure AI Foundry portal](https://ai.azure.com/), APIs, and SDKs, you can use the customizable standalone web app to interact with Azure OpenAI models by using a graphical user interface. Key features include:
 * Connectivity with multiple data sources to support rich querying and retrieval-augmented generation, including Azure AI Search, Prompt Flow, and more.
 * Conversation history and user feedback collection through Cosmos DB.
 * Authentication with role-based access control via Microsoft Entra ID.
@@ -191,15 +191,15 @@ To connect to Azure AI Search without redeploying your app, you can modify the f
 - `AZURE_SEARCH_ENABLE_IN_DOMAIN`: Limits responses to queries related only to your data.
     - Data type: boolean, should be set to `True`.
 - `AZURE_SEARCH_CONTENT_COLUMNS`: Specifies the list of fields in your Azure AI Search index that contain the text content of your documents, used when formulating a bot response.
-    - Data type: text, defaults to `content` if deployed from Azure AI Foundry portal,
+    - Data type: text, defaults to `content` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
 - `AZURE_SEARCH_FILENAME_COLUMN`: Specifies the field from your Azure AI Search index that provides a unique identifier of the source data to display in the UI.
-    - Data type: text, defaults to `filepath` if deployed from Azure AI Foundry portal,
+    - Data type: text, defaults to `filepath` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
 - `AZURE_SEARCH_TITLE_COLUMN`: Specifies the field from your Azure AI Search index that provides a relevant title or header for your data content to display in the UI.
-    - Data type: text, defaults to `title` if deployed from Azure AI Foundry portal,
+    - Data type: text, defaults to `title` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
 - `AZURE_SEARCH_URL_COLUMN`: Specifies the field from your Azure AI Search index that contains a URL for the document.
-    - Data type: text, defaults to `url` if deployed from Azure AI Foundry portal,
+    - Data type: text, defaults to `url` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
 - `AZURE_SEARCH_VECTOR_COLUMNS`: Specifies the list of fields in your Azure AI Search index that contain vector embeddings of your documents, used when formulating a bot response.
-    - Data type: text, defaults to `contentVector` if deployed from Azure AI Foundry portal,
+    - Data type: text, defaults to `contentVector` if deployed from [Azure AI Foundry portal](https://ai.azure.com/),
 - `AZURE_SEARCH_QUERY_TYPE`: Specifies the query type to use: `simple`, `semantic`, `vector`, `vectorSimpleHybrid`, or `vectorSemanticHybrid`. This setting takes precedence over `AZURE_SEARCH_USE_SEMANTIC_SEARCH`.
     - Data type: text, we recommend testing with `vectorSemanticHybrid`.
 - `AZURE_SEARCH_PERMITTED_GROUPS_COLUMN`: Specifies the field from your Azure AI Search index that contains Microsoft Entra group IDs, determining document-level access control.
@@ -294,7 +294,7 @@ The JSON to paste in the Advanced edit JSON editor is:
 
 ### Creating and deploying your prompt flow in Azure AI Foundry portal
 
-Follow [this tutorial](/azure/ai-studio/tutorials/deploy-copilot-ai-studio) to create, test, and deploy an inferencing endpoint for your prompt flow in Azure AI Foundry portal.
+Follow [this tutorial](/azure/ai-studio/tutorials/deploy-copilot-ai-studio) to create, test, and deploy an inferencing endpoint for your prompt flow in [Azure AI Foundry portal](https://ai.azure.com/).
 
 ### Enable underlying citations from your prompt flow
 
@@ -404,7 +404,7 @@ If you customized or changed the app's source code, you need to update your app'
 
 ## Deleting your Cosmos DB instance
 
-Deleting your web app doesn't delete your Cosmos DB instance automatically. To delete your Cosmos DB instance along with all stored chats, you need to go to the associated resource in the [Azure portal](https://portal.azure.com) and delete it. If you delete the Cosmos DB resource but keep the chat history option selected on subsequent updates from the Azure AI Foundry portal, the application notifies the user of a connection error. However, the user can continue to use the web app without access to the chat history.
+Deleting your web app doesn't delete your Cosmos DB instance automatically. To delete your Cosmos DB instance along with all stored chats, you need to go to the associated resource in the [Azure portal](https://portal.azure.com) and delete it. If you delete the Cosmos DB resource but keep the chat history option selected on subsequent updates from the [Azure AI Foundry portal](https://ai.azure.com/), the application notifies the user of a connection error. However, the user can continue to use the web app without access to the chat history.
 
 ## Enabling Microsoft Entra ID authentication between services
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新使用 Web 应用文档中的链接. Locale: zh_CN"
}
```

### Explanation
在对使用Web应用文档的修改中，进行了多处小幅更新，主要是为提到的Azure门户和Azure AI Foundry门户添加了可点击链接。这些链接增强了文档的可用性和导航体验，使用户能轻松访问相关门户以获取更多信息。在文中涉及的关键功能描述、连接设置以及删除操作等部分都进行了链接更新，确保一致性并简化用户的操作。此外，相关的操作示例和教程也强调了使用这些门户的重要性，进一步提升了文档内容的清晰度和易用性。

## articles/ai-services/openai/how-to/working-with-models.md{#item-7ec098}

<details>
<summary>Diff</summary>
````diff
@@ -20,7 +20,7 @@ You can get a list of models that are available for both inference and fine-tuni
 
 ## Model updates
 
-Azure OpenAI now supports automatic updates for select model deployments. On models where automatic update support is available, a model version drop-down is visible in Azure AI Foundry portal under **Deployments** and **Edit**:
+Azure OpenAI now supports automatic updates for select model deployments. On models where automatic update support is available, a model version drop-down is visible in [Azure AI Foundry portal](https://ai.azure.com/) under **Deployments** and **Edit**:
 
 :::image type="content" source="../media/models/auto-update-new.png" alt-text="Screenshot of the deploy model UI in the Azure AI Foundry portal." lightbox="../media/models/auto-update-new.png":::
 
@@ -43,7 +43,7 @@ When you select a specific model version for a deployment, this version remains
 
 ## Viewing retirement dates
 
-For currently deployed models, in the Azure AI Foundry portal select **Deployments**:
+For currently deployed models, in the [Azure AI Foundry portal](https://ai.azure.com/) select **Deployments**:
 
 :::image type="content" source="../media/models/deployments-new.png" alt-text="Screenshot of the deployment UI of the Azure AI Foundry portal." lightbox="../media/models/deployments-new.png":::
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新与模型相关的文档链接. Locale: zh_CN"
}
```

### Explanation
此次对与模型相关的文档进行了小幅更新，主要是将提及的Azure AI Foundry门户的链接进行了增强。通过将多个提到的部分添加为可点击的链接，用户能够更方便地访问相关信息。例如，在讨论模型自动更新支持和查看退休日期时，提到了用户需前往Azure AI Foundry门户进行操作，这些提及均已更新为链接格式。这一修改不仅提高了文档的可读性和易用性，也使得用户导航至相关功能更加顺畅，确保获取更具体的信息。

## articles/ai-services/openai/includes/audio-completions-rest.md{#item-0ec305}

<details>
<summary>Diff</summary>
````diff
@@ -7,7 +7,7 @@ ms.topic: include
 ms.date: 1/21/2025
 ---
 
-[REST API Spec](https://github.com/Azure/azure-rest-api-specs/blob/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable/2024-11-01/inference.json?azure-portal=true) |
+[REST API Spec](https://github.com/Azure/azure-rest-api-specs/blob/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable/2024-10-21/inference.json) |
 
 [!INCLUDE [Audio completions introduction](audio-completions-intro.md)]
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新REST API规范的链接. Locale: zh_CN"
}
```

### Explanation
在对音频补全REST文档的修改中，更新了REST API规范的链接，将其从指向2024年11月1日的版本更改为指向2024年10月21日的版本。这一小幅更新确保文档中的API规范链接指向最新有效的版本，有助于用户获取准确的技术信息。这样的调整对于开发者在使用Azure OpenAI相关API时能够访问到最及时的资料尤为重要，从而提升了文档的准确性与实用性。

## articles/ai-services/openai/overview.md{#item-97d507}

<details>
<summary>Diff</summary>
````diff
@@ -42,7 +42,7 @@ Start with the [Create and deploy an Azure OpenAI Service resource](./how-to/cre
 1. When you have an Azure OpenAI Service resource, you can deploy a model such as GPT-4o.
 1. When you have a deployed model, you can:
 
-    - Try out the Azure AI Foundry portal playgrounds to explore the capabilities of the models. 
+    - Try out the [Azure AI Foundry portal](https://ai.azure.com/) playgrounds to explore the capabilities of the models. 
     - You can also just start making API calls to the service using the REST API or SDKs.
     
     For example, you can try [real-time audio](./realtime-audio-quickstart.md) and [assistants](./assistants-quickstart.md) in the playgrounds or via code.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新Azure AI Foundry门户的链接. Locale: zh_CN"
}
```

### Explanation
在对OpenAI概述文档的修改中，更新了关于Azure AI Foundry门户的描述，将其改为包含可点击的链接。这一小幅更新使得用户在提到尝试Azure AI Foundry门户时，可以直接点击链接以访问相关资源，而不必手动输入网址。这种改动增强了文档的可用性和用户体验，方便用户更快捷地探索模型的功能。通过这种方式，用户能够更顺利地进行部署和使用Azure的服务。

## articles/ai-services/openai/quotas-limits.md{#item-06c6f9}

<details>
<summary>Diff</summary>
````diff
@@ -44,8 +44,8 @@ The following sections provide you with a quick guide to the default quotas and
 | Max number of `/chat/completions` functions | 128 |
 | Max number of `/chat completions` tools | 128 |
 | Maximum number of Provisioned throughput units per deployment | 100,000 |
-| Max files per Assistant/thread | 10,000 when using the API or Azure AI Foundry portal. In Azure OpenAI Studio the limit was 20.|
-| Max file size for Assistants & fine-tuning | 512 MB<br/><br/>200 MB via Azure AI Foundry portal |
+| Max files per Assistant/thread | 10,000 when using the API or [Azure AI Foundry portal](https://ai.azure.com/). In Azure OpenAI Studio the limit was 20.|
+| Max file size for Assistants & fine-tuning | 512 MB<br/><br/>200 MB via [Azure AI Foundry portal](https://ai.azure.com/) |
 | Max size for all uploaded files for Assistants |100 GB |
 | Assistants token limit | 2,000,000 token limit |
 | GPT-4o max images per request (# of images in the messages array/conversation history) | 50 |
@@ -145,7 +145,7 @@ M = million | K = thousand
 
 ## gpt-4o audio
 
-The rate limits for each `gpt-4o` audio model deployment are 100K TPM and 1K RPM. During the preview, Azure AI Foundry portal and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit will be 100K TPM and 1K RPM.
+The rate limits for each `gpt-4o` audio model deployment are 100K TPM and 1K RPM. During the preview, [Azure AI Foundry portal](https://ai.azure.com/) and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit will be 100K TPM and 1K RPM.
 
 | Model|Tier| Quota Limit in tokens per minute (TPM) | Requests per minute |
 |---|---|:---:|:---:|
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新关于Azure AI Foundry门户的链接. Locale: zh_CN"
}
```

### Explanation
在对配额和限制文档的修改中，更新了与Azure AI Foundry门户相关的链接，使其变为可点击的形式。这一小幅更改主要体现在两个地方，分别是在提到最大文件数和最大文件大小的段落中，同时在提及`gpt-4o`音频模型部署的速率限制时也加上了链接。这些更新使得文档更加用户友好，用户可以方便地访问Azure AI Foundry门户，以获取更详细的信息和资源。这种改进可以提升用户的体验，使他们能够更轻松地理解和使用服务。

## articles/ai-services/openai/tutorials/fine-tune.md{#item-8f87b5}

<details>
<summary>Diff</summary>
````diff
@@ -35,7 +35,7 @@ In this tutorial you learn how to:
 - [Jupyter Notebooks](https://jupyter.org/)
 - An Azure OpenAI resource in a [region where `gpt-4o-mini-2024-07-18` fine-tuning is available](../concepts/models.md). If you don't have a resource the process of creating one is documented in our resource [deployment guide](../how-to/create-resource.md).
 - Fine-tuning access requires **Cognitive Services OpenAI Contributor**.
-- If you don't already have access to view quota and deploy models in Azure AI Foundry portal, then you need [more permissions](../how-to/role-based-access-control.md).
+- If you don't already have access to view quota and deploy models in [Azure AI Foundry portal](https://ai.azure.com/), then you need [more permissions](../how-to/role-based-access-control.md).
 
 > [!IMPORTANT]
 > We recommend reviewing the [pricing information](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/#pricing) for fine-tuning to familiarize yourself with the associated costs. Testing of this tutorial resulted in 48,000 tokens being billed (4,800 training tokens * 10 epochs of training). Training costs are in addition to the costs that are associated with fine-tuning inference, and the hourly hosting costs of having a fine-tuned model deployed. Once you have completed the tutorial, you should delete your fine-tuned model deployment otherwise you continue to incur the hourly hosting cost.
@@ -892,7 +892,7 @@ print(r.reason)
 print(r.json())
 ```
 
-You can check on your deployment progress in the Azure AI Foundry portal.
+You can check on your deployment progress in the [Azure AI Foundry portal](https://ai.azure.com/).
 
 It isn't uncommon for this process to take some time to complete when dealing with deploying fine-tuned models.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新Azure AI Foundry门户的链接. Locale: zh_CN"
}
```

### Explanation
在对精细调整教程文档的修改中，更新了关于Azure AI Foundry门户的描述，将其改为包含可直接点击的链接。此更改出现在提到权限和检查部署进度的段落中，让用户能够更方便地访问Azure AI Foundry门户。这种改进提升了文档的可用性，用户点击链接即可轻松浏览相关资源，从而获取更多信息。这些小幅更新不仅增强了文档的互动性，也改善了用户在进行模型部署和权限申请时的体验。

## articles/ai-services/openai/whats-new.md{#item-53303b}

<details>
<summary>Diff</summary>
````diff
@@ -70,7 +70,7 @@ The `gpt-4o-realtime-preview` model version 2024-12-17 is available for global d
 
 - Added support for [prompt caching](./how-to/prompt-caching.md) with the `gpt-4o-realtime-preview` model.
 - Added support for new voices. The `gpt-4o-realtime-preview` models now support the following voices: "alloy", "ash", "ballad", "coral", "echo", "sage", "shimmer", "verse".
-- Rate limits are no longer based on connections per minute. Rate limiting is now based on RPM (requests per minute) and TPM (tokens per minute) for the `gpt-4o-realtime-preview` model. The rate limits for each `gpt-4o-realtime-preview` model deployment are 100K TPM and 1K RPM. During the preview, Azure AI Foundry portal and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit will be 100K TPM and 1K RPM.
+- Rate limits are no longer based on connections per minute. Rate limiting is now based on RPM (requests per minute) and TPM (tokens per minute) for the `gpt-4o-realtime-preview` model. The rate limits for each `gpt-4o-realtime-preview` model deployment are 100K TPM and 1K RPM. During the preview, [Azure AI Foundry portal](https://ai.azure.com/) and APIs might inaccurately show different rate limits. Even if you try to set a different rate limit, the actual rate limit will be 100K TPM and 1K RPM.
 
 For more information, see the [GPT-4o real-time audio quickstart](realtime-audio-quickstart.md) and the [how-to guide](./how-to/realtime-audio.md).
 
@@ -200,7 +200,7 @@ Global batch now supports GPT-4o (2024-08-06). See the [global batch getting sta
 
 ### Azure OpenAI Studio UX updates
 
-As of September 19, 2024, when you go to the [Azure OpenAI Studio](https://oai.azure.com/) you no longer see the legacy Azure OpenAI Studio by default. If needed you'll still be able to go back to the previous experience by using the **Switch to the old look** toggle in the top bar of the UI for the next couple of weeks. If you switch back to legacy Azure AI Foundry portal, it helps if you fill out the feedback form to let us know why. We're actively monitoring this feedback to improve the new experience.
+As of September 19, 2024, when you go to the [Azure OpenAI Studio](https://oai.azure.com/) you no longer see the legacy Azure OpenAI Studio by default. If needed you'll still be able to go back to the previous experience by using the **Switch to the old look** toggle in the top bar of the UI for the next couple of weeks. If you switch back to legacy [Azure AI Foundry portal](https://ai.azure.com/), it helps if you fill out the feedback form to let us know why. We're actively monitoring this feedback to improve the new experience.
 
 
 ### GPT-4o 2024-08-06 provisioned deployments
@@ -301,7 +301,7 @@ On August 6, 2024, OpenAI [announced](https://openai.com/index/introducing-struc
 
 Azure customers can test out GPT-4o `2024-08-06` today in the new Azure AI Foundry early access playground (preview).
 
-Unlike the previous early access playground, the Azure AI Foundry portal early access playground (preview) doesn't require you to have a resource in a specific region.
+Unlike the previous early access playground, the [Azure AI Foundry portal](https://ai.azure.com/) early access playground (preview) doesn't require you to have a resource in a specific region.
 
 > [!NOTE]
 > Prompts and completions made through the early access playground (preview) might be processed in any Azure OpenAI region, and are currently subject to a 10 request per minute per Azure subscription limit. This limit might change in the future.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "增加关于Azure AI Foundry门户的链接. Locale: zh_CN"
}
```

### Explanation
在对“最新消息”文档的修改中，重要信息的部分增加了指向Azure AI Foundry门户的超链接，从而提高了文档的交互性和可访问性。这一更新主要体现在多个段落中，例如在描述速率限制、新增声音支持以及早期访问游乐场的功能时，加入了Azure AI Foundry门户的可点击链接。这样的修改使得用户在阅读时能够方便地获取更多信息，进一步了解与模型部署和服务相关的细节。同时，更新内容明确了不同的限制原则，有助于用户更好地理解相关的技术背景。这些改动不仅增强了文档的清晰度，也改善了用户在使用服务时的体验。


