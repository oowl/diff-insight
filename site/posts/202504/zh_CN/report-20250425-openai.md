---
date: '2025-04-25'
permalink: https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:57b3ac1...MicrosoftDocs:869fffd
summary: 此次更新对多个文档进行了小幅度修改，旨在提升描述的精准性和一致性，并引入新功能。主要内容包括引入新的图像生成模型GPT-image-1及相关文档更新，更新了《最新推理预览》文档以增加图像生成和编辑功能。此外，文档术语得到了统一，DALL-E的描述被更新为更广泛的“图像生成模型”，并修正了多个文件中的术语和格式，以增强用户的阅读体验。总体来说，这些修改有助于为用户提供清晰的导航和使用说明。
title: '[zh_CN] Diff Insight Report - openai'

---

[View Diff on GitHub](https://github.com/MicrosoftDocs/azure-ai-docs/compare/MicrosoftDocs:57b3ac1...MicrosoftDocs:869fffd){target="_blank"}

<format>
# Highlights
此更新对多个文档进行了小幅度修改，主要是为了提升描述的精准性和一致性，并引入了新的功能。其中包括对内容凭据、内容过滤系统、默认安全策略、模型文档等内容的更新，以及对图像生成模型使用指南的新功能添加。

## New features
- 引入了新的图像生成模型GPT-image-1，并增加了该模型的相关文档和使用指南。
- 更新了《最新推理预览》文档，增加了图像生成和编辑功能。

## Breaking changes
无重大破坏性变更，所有修改都是围绕文档术语更新和功能添加而进行的微调。

## Other updates
- 多个文档中进行了关于DALL-E描述的统一性调整，将其更新为更广泛的“图像生成模型”。
- 更新了配额和限制文档以包含新模型的信息。
- 修正和统一多个文件中的术语和格式，以提升阅读体验。

# Insights
在此次文档更新中，主要目的是让描述更加统一和全面，涵盖了最新推出的模型功能。以前的DALL-E模型参考已经逐步转换为更通用的“图像生成模型”术语，突出Azure OpenAI服务的多样性和最新功能，如GPT-image-1。

尤其值得注意的是，新增了关于GPT-image-1的详细介绍和用户指南文档。这不仅显示了服务在模型开发上的持续进展，也为用户提供了详细的说明，以帮助他们更快上手新功能。

在配额和限制文档以及相关API文档中，引入了新模型的支持与限制，确保用户获取准确的使用信息。这种统一和更新对于保持文档的前沿性和用户体验的提升至关重要。

此外，文档中一些小规模的编辑、大量术语的一致性调整显示出开发团队对于用户体验的关注，帮助用户在学习和应用Azure OpenAI服务时能够有清晰明确的导航和指引。

</format>

# Summary Table
|  Filename  | Type |    Title    | Status | A  | D  | M  |
|------------|------|-------------|--------|----|----|----|
| [content-credentials.md](#item-a23b50) | minor update | 内容凭据的更新 | modified | 8 | 8 | 16 | 
| [content-filter.md](#item-dfc7e7) | minor update | 内容过滤系统的更新 | modified | 1 | 1 | 2 | 
| [default-safety-policies.md](#item-39b6a0) | minor update | 默认安全策略的更新 | modified | 1 | 1 | 2 | 
| [model-retirements.md](#item-03fc2e) | minor update | 模型退役日期的更新 | modified | 8 | 8 | 16 | 
| [models.md](#item-db2c37) | minor update | 模型文档更新 | modified | 21 | 5 | 26 | 
| [prompt-transformation.md](#item-21e047) | minor update | 提示转化文档的更新 | modified | 5 | 5 | 10 | 
| [faq.yml](#item-6deb71) | minor update | 常见问题更新 | modified | 1 | 1 | 2 | 
| [content-filters.md](#item-6f0627) | minor update | 内容过滤系统描述更新 | modified | 1 | 1 | 2 | 
| [dall-e.md](#item-ac9616) | new feature | 新增图像生成模型使用指南 | modified | 197 | 23 | 220 | 
| [evaluations.md](#item-dfaa1c) | minor update | ROUGE指标描述格式化更新 | modified | 8 | 6 | 14 | 
| [reasoning.md](#item-a54b2f) | minor update | 更新推理模型支持文档 | modified | 9 | 7 | 16 | 
| [responses.md](#item-b9757d) | minor update | 新增图像生成模型支持信息 | modified | 1 | 0 | 1 | 
| [latest-inference-preview.md](#item-24bf0f) | new feature | 引入图像生成和编辑功能 | modified | 150 | 9 | 159 | 
| [dall-e-dotnet.md](#item-755f0a) | minor update | 更新图像API相关描述 | modified | 2 | 2 | 4 | 
| [dall-e-go.md](#item-132707) | minor update | 更新图像API相关说明 | modified | 2 | 2 | 4 | 
| [dall-e-java.md](#item-373f89) | minor update | 更新图像API的相关说明 | modified | 2 | 2 | 4 | 
| [dall-e-javascript.md](#item-6cffcf) | minor update | 更新图像API的相关表述 | modified | 2 | 2 | 4 | 
| [dall-e-powershell.md](#item-97878b) | minor update | 更新图像API的描述内容 | modified | 2 | 2 | 4 | 
| [dall-e-python.md](#item-c91824) | minor update | 更新图像API的相关术语 | modified | 2 | 2 | 4 | 
| [dall-e-rest.md](#item-4bac64) | minor update | 更新API相关术语以确保一致性 | modified | 2 | 2 | 4 | 
| [dall-e-studio.md](#item-439729) | minor update | 更新术语以提升一致性 | modified | 2 | 2 | 4 | 
| [dall-e-typescript.md](#item-57b205) | minor update | 修正术语以提高文档一致性 | modified | 2 | 2 | 4 | 
| [dotnet.md](#item-46e881) | minor update | 更新快速入门指南的标题 | modified | 1 | 1 | 2 | 
| [global-batch.md](#item-929e6a) | minor update | 删除部分区域的支持信息 | modified | 0 | 2 | 2 | 
| [structured-outputs-python.md](#item-2734f0) | minor update | 在示例代码中添加了对os模块的导入 | modified | 2 | 0 | 2 | 
| [index.yml](#item-0adb87) | minor update | 更新模型和文档描述中的名称 | modified | 3 | 3 | 6 | 
| [overview.md](#item-97d507) | minor update | 更新文档中模型名称及描述 | modified | 2 | 2 | 4 | 
| [quotas-limits.md](#item-06c6f9) | minor update | 更新配额和限制文档以包含新模型 | modified | 2 | 1 | 3 | 
| [toc.yml](#item-c945af) | minor update | 更新目录以反映图像生成模型的名称变更 | modified | 2 | 2 | 4 | 
| [whats-new.md](#item-53303b) | new feature | 新增GPT-image-1模型的介绍 | modified | 11 | 0 | 11 | 


# Modified Contents
## articles/ai-services/openai/concepts/content-credentials.md{#item-a23b50}

<details>
<summary>Diff</summary>
````diff
@@ -6,7 +6,7 @@ author: PatrickFarley
 ms.author: pafarley
 ms.service: azure-ai-openai
 ms.topic: conceptual 
-ms.date: 02/20/2025
+ms.date: 04/23/2025
 manager: nitinme
 ---
 
@@ -16,14 +16,14 @@ With the improved quality of content from generative AI models, there is an incr
 
 ## What are Content Credentials? 
 
-Content Credentials in the Azure OpenAI Service provide customers with information about the origin of an image generated by the DALL-E series models. This information is represented by a manifest attached to the image. The manifest is cryptographically signed by a certificate that traces back to Azure OpenAI Service.
+Content Credentials in the Azure OpenAI Service provide customers with information about the origin of an image generated by the image generation models. This information is represented by a manifest attached to the image. The manifest is cryptographically signed by a certificate that traces back to Azure OpenAI Service.
 
 The manifest contains several key pieces of information: 
 
 | Field name | Field content |
 | ---| ---|
-| `"description"` | This field has a value of `"AI Generated Image"` for all DALL-E model generated images, attesting to the AI-generated nature of the image. |
-| `"softwareAgent"` | This field has a value of `"Azure OpenAI DALL-E"` for all images generated by DALL-E series models in Azure OpenAI Service. |
+| `"description"` | This field has a value of `"AI Generated Image"` for all generated images, attesting to the AI-generated nature of the image. |
+| `"softwareAgent"` | This field has a value of `"Azure OpenAI DALL-E"` or `"Azure OpenAI ImageGen"` for all images generated by DALL-E series models or GPT-image-1 models in Azure OpenAI Service. |
 |`"when"` |The timestamp of when the Content Credentials were created. | 
 
 
@@ -32,12 +32,12 @@ Content Credentials in the Azure OpenAI Service can help people understand when
 ## How do I use Content Credentials in my solution today?
 
 Customers may use Content Credentials by:
-- Ensuring that their AI generated images contain Content Credentials
-    No additional set-up is necessary. Content Credentials are automatically applied to all generated images from DALL·E in the Azure OpenAI Service. 
+- Ensuring that their AI-generated images contain Content Credentials
+    No additional set-up is necessary. Content Credentials are automatically applied to all generated images from DALL·E and GPT-image-1 in the Azure OpenAI Service. 
 - Verifying that an image has Content Credentials
-    There are two recommended ways today to check the credential of an image generated by Azure OpenAI DALL-E models:
+    There are two recommended ways today to check the credential of an image generated by Azure OpenAI models:
 
-    - **Content Credentials Verify webpage (contentcredentials.org/verify)**: This is a tool that allows users to inspect the Content Credentials of a piece of content. If an image was generated by DALL-E in Azure OpenAI, the tool will display that its Content Credentials were issued by Microsoft Corporation alongside the date and time of issuance.
+    - **Content Credentials Verify webpage (contentcredentials.org/verify)**: This is a tool that allows users to inspect the Content Credentials of a piece of content. If an image was generated by an Azure OpenAI image generation model, the tool will display that its Content Credentials were issued by Microsoft Corporation alongside the date and time of issuance.
        :::image type="content" source="../media/encryption/credential-check.png" alt-text="Screenshot of the content credential verification website.":::
     
        This page shows that an image generated by Azure OpenAI DALL-E has Content Credentials issued by Microsoft.
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "内容凭据的更新"
}
```

### Explanation
此修改主要涉及对《内容凭据》文档的内容进行更新和调整。具体而言，增加了生成图像模型的多样性，更新了日期，修正了一些措辞，从而使其更准确地反映当前的技术状态。文档中提到的生成模型已经扩展到了包括GPT-image-1模型，同时更改了相关的描述，使得其表述更加清晰。此外，所有相关的内容凭据部分都已进行了相应的一致性和准确性改进，以帮助客户更好地理解和使用Azure OpenAI服务。

## articles/ai-services/openai/concepts/content-filter.md{#item-dfc7e7}

<details>
<summary>Diff</summary>
````diff
@@ -16,7 +16,7 @@ manager: nitinme
 > [!IMPORTANT]
 > The content filtering system isn't applied to prompts and completions processed by the audio models such as Whisper in Azure OpenAI Service. Learn more about the [Audio models in Azure OpenAI](models.md?tabs=standard-audio#standard-deployment-regional-models-by-endpoint).
 
-Azure OpenAI Service includes a content filtering system that works alongside core models, including DALL-E image generation models. This system works by running both the prompt and completion through an ensemble of classification models designed to detect and prevent the output of harmful content. The content filtering system detects and takes action on specific categories of potentially harmful content in both input prompts and output completions. Variations in API configurations and application design might affect completions and thus filtering behavior.
+Azure OpenAI Service includes a content filtering system that works alongside core models, including image generation models. This system works by running both the prompt and completion through an ensemble of classification models designed to detect and prevent the output of harmful content. The content filtering system detects and takes action on specific categories of potentially harmful content in both input prompts and output completions. Variations in API configurations and application design might affect completions and thus filtering behavior.
 
 The text content filtering models for the hate, sexual, violence, and self-harm categories have been specifically trained and tested on the following languages: English, German, Japanese, Spanish, French, Italian, Portuguese, and Chinese. However, the service can work in many other languages, but the quality might vary. In all cases, you should do your own testing to ensure that it works for your application.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "内容过滤系统的更新"
}
```

### Explanation
此次修改主要是对《内容过滤》文档中的部分文本进行细微调整。具体来说，删除了针对“DALL-E”生成模型的特定提及，将描述中的“DALL-E图像生成模型”更新为“图像生成模型”，使其更具一般性。此外，文件的整体结构和内容保留不变，文中强调了该内容过滤系统的工作机制及其在各种语言中的适用性。这些更改旨在使文档描述更加精准和适应不同的生成模型。

## articles/ai-services/openai/concepts/default-safety-policies.md{#item-39b6a0}

<details>
<summary>Diff</summary>
````diff
@@ -65,4 +65,4 @@ Text models in the Azure OpenAI Service can take in and generate both text and c
 | Profanity                                         | Prompts                | N/A                 |
 
 
-In addition to the above safety configurations, Azure OpenAI DALL-E also comes with [prompt transformation](./prompt-transformation.md) by default. This transformation occurs on all prompts to enhance the safety of your original prompt, specifically in the risk categories of diversity, deceptive generation of political candidates, depictions of public figures, protected material, and others. 
\ No newline at end of file
+In addition to the above safety configurations, the latest image generation models also come with [prompt transformation](./prompt-transformation.md) by default. This transformation occurs on all prompts to enhance the safety of your original prompt, specifically in the risk categories of diversity, deceptive generation of political candidates, depictions of public figures, protected material, and others. 
\ No newline at end of file
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "默认安全策略的更新"
}
```

### Explanation
此次修改对《默认安全策略》文档进行了小幅更新。主要变化在于将“Azure OpenAI DALL-E”更新为“最新的图像生成模型”，以反映当前技术的进展。这一调整使得文档内容更加通用，适用于所有最新的图像生成模型，而不仅限于DALL-E。此外，文中对提示转化功能的描述保持不变，仍强调其在多样性、政治候选人误导生成、公共人物的描绘、受保护材料等风险类别中的安全增强作用。这些更新旨在确保文档内容准确，符合最新的服务特性。

## articles/ai-services/openai/concepts/model-retirements.md{#item-03fc2e}

<details>
<summary>Diff</summary>
````diff
@@ -4,7 +4,7 @@ titleSuffix: Azure OpenAI
 description: Learn about the model deprecations and retirements in Azure OpenAI.
 ms.service: azure-ai-openai
 ms.topic: conceptual
-ms.date: 04/17/2025
+ms.date: 04/23/2025
 ms.custom: 
 manager: nitinme
 author: mrbullwinkle
@@ -95,25 +95,24 @@ These models are currently available for use in Azure OpenAI Service.
 | ---- | ---- | ---- | --- |
 | `dall-e-3` | 3 | No earlier than June 30, 2025 | |
 | `gpt-35-turbo-16k`| 0613 | April, 30, 2025 | `gpt-35-turbo` (0125) <br><br> `gpt-4o-mini`|
-| `gpt-35-turbo` | 1106 | No earlier than May 31, 2025 <br><br> Deployments set to [**Auto-update to default**](/azure/ai-services/openai/how-to/working-with-models?tabs=powershell#auto-update-to-default) will be automatically upgraded to version: `0125`, starting on January 21, 2025. | `gpt-35-turbo` (0125) <br><br> `gpt-4o-mini` |
-| `gpt-35-turbo` | 0125 | No earlier than May 31, 2025 | `gpt-4o-mini` |
+| `gpt-35-turbo` | 1106 | July 16, 2025 <br><br> Deployments set to [**Auto-update to default**](/azure/ai-services/openai/how-to/working-with-models?tabs=powershell#auto-update-to-default) will be automatically upgraded to version: `0125`, starting on January 21, 2025. | `gpt-35-turbo` (0125) <br><br> `gpt-4o-mini` |
+| `gpt-35-turbo` | 0125 | July 16, 2025 | `gpt-4o-mini` |
 | `gpt-4`<br>`gpt-4-32k` | 0314 | June 6, 2025 | `gpt-4o` |
 | `gpt-4`<br>`gpt-4-32k` | 0613 | June 6, 2025 | `gpt-4o` |
 | `gpt-4` | turbo-2024-04-09 | No earlier than June 6, 2025 | `gpt-4o`|
 | `gpt-4` | 1106-preview | To be upgraded to **`gpt-4o` version: `2024-11-20`**, starting no sooner than April 17, 2025 **<sup>1</sup>** <br>Retirement date: May 1, 2025  | `gpt-4o`|
 | `gpt-4` | 0125-preview |To be upgraded to **`gpt-4o` version: `2024-11-20`**, starting no sooner than April 17, 2025 **<sup>1</sup>** <br>Retirement date: May 1, 2025  | `gpt-4o` |
-| `gpt-4` | vision-preview | To be upgraded to **`gpt-4o` version: `2024-11-20`**, starting no sooner than April 17, 2025  **<sup>1</sup>** <br>Retirement date: May 1, 2025 | `gpt-4o`|
+| `gpt-4` | vision-preview | To be upgraded to **`gpt-4o` version: `2024-11-20`**, starting no sooner than April 17, 2025  **<sup>1</sup>** <br>Retirement date: May 15, 2025 | `gpt-4o`|
 | `gpt-4.5-preview` | 2025-02-27 | July 14, 2025 | `gpt-4.1` |
 | `gpt-4.1` | 2025-04-14 | No earlier than April 11, 2026 | |
 | `gpt-4.1-mini` | 2025-04-14 | No earlier than April 11, 2026 |
 | `gpt-4.1-nano` | 2025-04-14 | No earlier than April 11, 2026 |
 | `gpt-4o` | 2024-05-13 | No earlier than June 30, 2025 <br><br>Deployments set to [**Auto-update to default**](/azure/ai-services/openai/how-to/working-with-models?tabs=powershell#auto-update-to-default) will be automatically upgraded to version: `2024-08-06`, starting on March 17, 2025. | |
 | `gpt-4o` | 2024-08-06 | No earlier than August 6, 2025  | |
-| `gpt-4o` | 2024-11-20 | No earlier than November 20, 2025  | |
-| `gpt-4o-mini` | 2024-07-18 | No earlier than July 18, 2025  | |
-| `gpt-4o-realtime-preview` | 2024-10-01 | **Deprecated:** February 25, 2025<br>**Retirement:** No earlier than March 26, 2025 | `gpt-4o-realtime-preview` (version 2024-12-17) or `gpt-4o-mini-realtime-preview` (version 2024-12-17) |
+| `gpt-4o` | 2024-11-20 | January 30, 2026  | |
+| `gpt-4o-mini` | 2024-07-18 | August 16, 2025  | |
 | `gpt-3.5-turbo-instruct` | 0914 | No earlier than May 31, 2025 |  |
-| `o1-preview` | 2024-09-12 | No earlier than April 2, 2025 | `o1` |
+| `o1-preview` | 2024-09-12 | May 29, 2025 | `o1` |
 | `o1` | 2024-12-17 | No earlier than December 17, 2025 | |
 | `o4-mini` | 2025-04-16 | No earlier than April 11, 2026 | |
 | `o3` | 2025-04-16 | No earlier than April 11, 2026 | |
@@ -149,6 +148,7 @@ If you're an existing customer looking for information about these models, see [
 
 | Model | Deprecation date | Retirement date | Suggested replacement |
 | --------- | --------------------- | ------------------- | -------------------- |
+| `gpt-4o-realtime-preview` - 2024-10-01 | February 25, 2025 | March 26, 2025 | `gpt-4o-realtime-preview` (version 2024-12-17) or `gpt-4o-mini-realtime-preview` (version 2024-12-17) |
 | `gpt-35-turbo` - 0301 | | February 13, 2025   | `gpt-35-turbo` (0125) <br><br> `gpt-4o-mini`  |
 | `gpt-35-turbo` - 0613 | | February 13, 2025 | `gpt-35-turbo` (0125) <br><br> `gpt-4o-mini`  |
 | babbage-002 | | January 27, 2025 |  |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "模型退役日期的更新"
}
```

### Explanation
此次修改涉及《模型退役》文档中的数个信息更新，主要是关于模型的更新和退役日期的调整。具体而言，更改了多个模型的退役日期，部分模型如`gpt-4`和`gpt-4-32k`的最新版本被更新为新的日期。此外，文档还修正了多个模型的回退及替代建议，对未来的版本升级进行了补充说明。这些更改旨在确保用户获得最新、最准确的信息，帮助他们更好地理解Azure OpenAI服务中各模型的状态和生命周期。

## articles/ai-services/openai/concepts/models.md{#item-db2c37}

<details>
<summary>Diff</summary>
````diff
@@ -4,7 +4,7 @@ titleSuffix: Azure OpenAI
 description: Learn about the different model capabilities that are available with Azure OpenAI.
 ms.service: azure-ai-openai
 ms.topic: conceptual
-ms.date: 04/16/2025
+ms.date: 04/23/2025
 ms.custom: references_regions, build-2023, build-2023-dataai, refefences_regions
 manager: nitinme
 author: mrbullwinkle #ChrisHMSFT
@@ -26,7 +26,7 @@ Azure OpenAI Service is powered by a diverse set of models with different capabi
 | [GPT-4](#gpt-4) | A set of models that improve on GPT-3.5 and can understand and generate natural language and code. |
 | [GPT-3.5](#gpt-35) | A set of models that improve on GPT-3 and can understand and generate natural language and code. |
 | [Embeddings](#embeddings-models) | A set of models that can convert text into numerical vector form to facilitate text similarity. |
-| [DALL-E](#dall-e-models) | A series of models that can generate original images from natural language. |
+| [Image generation](#image-generation-models) | A series of models that can generate original images from natural language. |
 | [Audio](#audio-models) | A series of models for speech to text, translation, and text to speech. GPT-4o audio models support either low-latency, "speech in, speech out" conversational interactions or audio generation. |
 
 ## GPT 4.1 series
@@ -220,9 +220,24 @@ The third generation embeddings models support reducing the size of the embeddin
 
 OpenAI's MTEB benchmark testing found that even when the third generation model's dimensions are reduced to less than `text-embeddings-ada-002` 1,536 dimensions performance remains slightly better.
 
-## DALL-E
+## Image generation models
 
-The DALL-E models generate images from text prompts that the user provides. DALL-E 3 is generally available for use with the REST APIs. DALL-E 2 and DALL-E 3 with client SDKs are in preview.
+The image generation models generate images from text prompts that the user provides. GPT-image-1 is in limited access public preview. DALL-E 3 is generally available for use with the REST APIs. DALL-E 2 and DALL-E 3 with client SDKs are in preview.
+
+### Availability
+
+**For access to `gpt-image-1` registration is required, and access will be granted based on Microsoft's eligibility criteria**. Customers who have access to other limited access models will still need to request access for this model.
+
+Request access: [`computer-use-preview` limited access model application](https://aka.ms/oai/gptimage1access)
+
+Once access has been granted, you will need to create a deployment for the model.
+
+### Region availability
+
+| Model | Region |
+|---|---|
+|`dall-e-3` | East US<br>Australia East<br>Sweden Central|
+|`gpt-image-1` | West US 2 (Global Standard) <br> UAE North (Global Standard) |
 
 ## Audio models
 
@@ -414,10 +429,11 @@ These models can only be used with Embedding API requests.
 
 [!INCLUDE [Image Generation](../includes/model-matrix/standard-image-generation.md)]
 
-### DALL-E models
+### Image generation models
 
 |  Model ID  | Max Request (characters) |
 |  --- | :---: |
+| gpt-image-1 | 4,000 |
 | dall-e-3  | 4,000 |
 
 # [Audio](#tab/standard-audio)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "模型文档更新"
}
```

### Explanation
此次修改对《模型》文档进行了小幅更新，主要变动包括对模型类别和描述的调整。具体而言，将原本的“DALL-E”模型改为“图像生成模型”，以便更好地概括此类模型的功能。此外，增加了有关`gpt-image-1`模型的访问要求和区域可用性的新信息，比如用户需要注册申请接入，并且在特定地区提供相关服务。更新还对现有模型的信息进行了梳理，确保用户能够更清晰地了解不同模型的能力和使用条件。这些更改旨在提升文档的准确性和实用性，帮助用户更有效地利用Azure OpenAI平台。

## articles/ai-services/openai/concepts/prompt-transformation.md{#item-21e047}

<details>
<summary>Diff</summary>
````diff
@@ -12,12 +12,12 @@ manager: nitinme
 
 # What is prompt transformation?
 
-Prompt transformation is a process included in DALL-E 3 image generation that applies a safety and quality system message to your original prompt. It uses a large language model (LLM) call to add the message before sending your prompt to the model for image generation. This system message enriches your original prompt with the goal of generating more diverse and higher-quality images while maintaining intent. 
+Prompt transformation is a process included in the DALL-E 3 and GPT-image-1 (preview) models that applies a safety and quality system message to your original prompt. It uses a large language model (LLM) call to add the message before sending your prompt to the model for image generation. This system message enriches your original prompt with the goal of generating more diverse and higher-quality images while maintaining intent. 
 
 After prompt transformation is applied to the original prompt, content filtering is applied as a secondary step before image generation; for more information, see [Content filtering](./content-filter.md).
 
 > [!TIP]
-> Learn more about image generation prompting in OpenAI's [DALL·E documentation](https://platform.openai.com/docs/guides/images/language-specific-tips).
+> Learn more about image generation prompting in OpenAI's [Image generation documentation](https://platform.openai.com/docs/guides/images/language-specific-tips).
 
 ## Prompt transformation example
 
@@ -30,11 +30,11 @@ After prompt transformation is applied to the original prompt, content filtering
 
 Prompt transformation is essential for responsible and high-quality generations. Not only does prompt transformation improve the safety of your generated image, but it also enriches your prompt in a more descriptive manner, leading to higher quality and descriptive imagery.
 
-Default prompt transformation in Azure OpenAI DALL-E 3 contains safety enhancements that steer the model away from generating images of Copyright Studio characters and artwork, public figures, and other harmful content such as sexual, hate and unfairness, violence, and self-harm content.
+Default prompt transformation contains safety enhancements that steer the model away from generating images of Copyright Studio characters and artwork, public figures, and other harmful content such as sexual, hate and unfairness, violence, and self-harm content.
 
 ## How do I use prompt transformation?
 
-Prompt transformation is applied by default to all Azure OpenAI DALL-E 3 requests. No extra setup is required to benefit from prompt transformation enhancements.
+Prompt transformation is applied by default to all Azure OpenAI DALL-E 3 and GPT-image-1 requests. No extra setup is required to benefit from prompt transformation enhancements.
 
 Like image generation, prompt transformation is non-deterministic due to the nature of large language models. A single original prompt may lead to many image variants.
 
@@ -69,4 +69,4 @@ Output Content:
 ## Next step
 
 > [!div class="nextstepaction"]
-> [DALL-E quickstart](/azure/ai-services/openai/dall-e-quickstart)
+> [Image generation quickstart](/azure/ai-services/openai/dall-e-quickstart)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "提示转化文档的更新"
}
```

### Explanation
此次修改对《提示转化》文档进行了小幅更新，主要集中在增强针对DALL-E 3和GPT-image-1模型的描述。更新内容包括提示转化过程的定义，说明其适用于DALL-E 3和GPT-image-1（预览）模型，并将在生成图像前应用安全和质量系统消息。同样，文中的链接已被更新为指向更全面的图像生成文档。此外，文档进一步突出了提示转化如何增强生成内容的安全性和多样性，同时去除了DALL-E 3特有的描述，使其更具通用性。这些更新旨在使用户更好地理解提示转化的流程以及其在生成高质量图像方面的作用。

## articles/ai-services/openai/faq.yml{#item-6deb71}

<details>
<summary>Diff</summary>
````diff
@@ -41,7 +41,7 @@ sections:
       - question: |
           How do the capabilities of Azure OpenAI compare to OpenAI?
         answer: | 
-          Azure OpenAI Service gives customers advanced language AI with OpenAI GPT-3, Codex, and DALL-E models with the security and enterprise promise of Azure. Azure OpenAI codevelops the APIs with OpenAI, ensuring compatibility and a smooth transition from one to the other.
+          Azure OpenAI Service gives customers advanced language AI with the latest OpenAI models with the security and enterprise promise of Azure. Azure OpenAI codevelops the APIs with OpenAI, ensuring compatibility and a smooth transition from one to the other.
           
           With Azure OpenAI, customers get the security capabilities of Microsoft Azure while running the same models as OpenAI. 
       - question: |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "常见问题更新"
}
```

### Explanation
此次修改对《常见问题》文档进行了小幅更新，主要是对有关 Azure OpenAI Service 功能描述的微调。原文中提到的具体模型（如GPT-3、Codex和DALL-E）已被更新为“最新的OpenAI模型”，以便涵盖可能的模型更新和演进。此变化的目的是强调Azure OpenAI服务为客户提供最新的语言AI能力，同时保持Azure平台的安全性和企业承诺。这使得用户能够更清晰地理解Azure OpenAI的全球适用性和持续改进。

## articles/ai-services/openai/how-to/content-filters.md{#item-6f0627}

<details>
<summary>Diff</summary>
````diff
@@ -15,7 +15,7 @@ ms.custom: FY25Q1-Linter
 
 # How to configure content filters
 
-The content filtering system integrated into Azure AI Foundry runs alongside the core models, including DALL-E image generation models. It uses an ensemble of multi-class classification models to detect four categories of harmful content (violence, hate, sexual, and self-harm) at four severity levels respectively (safe, low, medium, and high), and optional binary classifiers for detecting jailbreak risk, existing text, and code in public repositories. 
+The content filtering system integrated into Azure AI Foundry runs alongside the core models, including image generation models. It uses an ensemble of multi-class classification models to detect four categories of harmful content (violence, hate, sexual, and self-harm) at four severity levels respectively (safe, low, medium, and high), and optional binary classifiers for detecting jailbreak risk, existing text, and code in public repositories. 
 
 The default content filtering configuration is set to filter at the medium severity threshold for all four content harms categories for both prompts and completions. That means that content that is detected at severity level medium or high is filtered, while content detected at severity level low or safe is not filtered by the content filters. Learn more about content categories, severity levels, and the behavior of the content filtering system [here](../concepts/content-filter.md). 
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "内容过滤系统描述更新"
}
```

### Explanation
此次修改对《如何配置内容过滤器》文档进行了小幅更新，主要是将“DALL-E图像生成模型”更改为更广泛的“图像生成模型”。这一变化的目的是为了更加包容并涵盖其他可能的图像生成模型，从而提升描述的通用性。内容过滤系统的核心功能保持不变，依然使用多类别分类模型检测四种类型的有害内容（暴力、仇恨、色情和自残），并在不同的严重性等级上进行评估。这一更新使得文档更具适用性，也增强了用户对系统能力的理解。

## articles/ai-services/openai/how-to/dall-e.md{#item-ac9616}

<details>
<summary>Diff</summary>
````diff
@@ -1,43 +1,84 @@
 ---
-title: How to use DALL-E models 
+title: How to use image generation models 
 titleSuffix: Azure OpenAI Service
-description: Learn how to generate images with the DALL-E models, and learn about the configuration options that are available.
+description: Learn how to generate and edit images with image models, and learn about the configuration options that are available.
 author: PatrickFarley
 ms.author: pafarley 
 ms.service: azure-ai-openai
 ms.custom: 
 ms.topic: how-to
-ms.date: 02/20/2025
+ms.date: 04/23/2025
 manager: nitinme
 keywords: 
 zone_pivot_groups: 
 # Customer intent: as an engineer or hobbyist, I want to know how to use DALL-E image generation models to their full capability.
 ---
 
-# How to use the DALL-E models
+# How to use Azure OpenAI image generation models
 
-OpenAI's DALL-E models generate images based on user-provided text prompts. This guide demonstrates how to use the DALL-E models and configure their options through REST API calls.
+OpenAI's image generation models render images based on user-provided text prompts and optionally provided images. This guide demonstrates how to use the image generation models and configure their options through REST API calls.
 
 
 ## Prerequisites
 
 - An Azure subscription. You can [create one for free](https://azure.microsoft.com/pricing/purchase-options/azure-account?icid=ai-services).
 - An Azure OpenAI resource created in a supported region. See [Region availability](/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability).
-- - Deploy a *dall-e-3* model with your Azure OpenAI resource.
+- Deploy a `dall-e-3` or `gpt-image-1` model with your Azure OpenAI resource. For more information on deployments, see [Create a resource and deploy a model with Azure OpenAI](/azure/ai-services/openai/how-to/create-resource).
+    - GPT-image-1 is the newer model and features a number of improvements over DALL-E 3. It's available in limited access: apply for access with [this form](https://aka.ms/oai/gptimage1access).
 
-## Call the Image Generation APIs
+## Call the Image Generation API
 
-The following command shows the most basic way to use DALL-E with code. If this is your first time using these models programmatically, we recommend starting with the [DALL-E quickstart](/azure/ai-services/openai/dall-e-quickstart).
+The following command shows the most basic way to use an image model with code. If this is your first time using these models programmatically, we recommend starting with the [quickstart](/azure/ai-services/openai/dall-e-quickstart).
 
+
+#### [GPT-image-1](#tab/gpt-image-1)
 Send a POST request to:
 
 ```
 https://<your_resource_name>.openai.azure.com/openai/deployments/<your_deployment_name>/images/generations?api-version=<api_version>
 ```
 
-**Replace the following placeholders**:
+
+**URL**:
+
+Replace the following values:
 - `<your_resource_name>` is the name of your Azure OpenAI resource.
-- `<your_deployment_name>` is the name of your DALL-E 3 model deployment.
+- `<your_deployment_name>` is the name of your DALL-E 3 or GPT-image-1 model deployment.
+- `<api_version>` is the version of the API you want to use. For example, `2025-04-01-preview`.
+
+**Required headers**:
+- `Content-Type`: `application/json`
+- `api-key`: `<your_API_key>`
+
+**Body**:
+
+The following is a sample request body. You specify a number of options, defined in later sections.
+
+```json
+{
+    "prompt": "A multi-colored umbrella on the beach, disposable camera",
+    "model": "gpt-image-1",
+    "size": "1024x1024", 
+    "n": 1,
+    "quality": "high"
+}
+```
+
+
+
+#### [DALL-E 3](#tab/dalle-3)
+
+Send a POST request to:
+
+```
+https://<your_resource_name>.openai.azure.com/openai/deployments/<your_deployment_name>/images/generations?api-version=<api_version>
+```
+
+**URL**:
+
+Replace the following values:
+- `<your_resource_name>` is the name of your Azure OpenAI resource.
+- `<your_deployment_name>` is the name of your DALL-E 3 or GPT-image-1 model deployment.
 - `<api_version>` is the version of the API you want to use. For example, `2024-02-01`.
 
 **Required headers**:
@@ -58,9 +99,11 @@ The following is a sample request body. You specify a number of options, defined
 }
 ```
 
-## Output
+---
+
+### Output
 
-The output from a successful image generation API call looks like the following example. The `url` field contains a URL where you can download the generated image. The URL stays active for 24 hours.
+The response from a successful image generation API call looks like the following example. The `url` field contains a URL where you can download the generated image. The URL stays active for 24 hours.
 
 ```json
 { 
@@ -104,51 +147,182 @@ It's also possible that the generated image itself is filtered. In this case, th
 }
 ```
 
-## Write image prompts
+### Write text-to-image prompts
 
-Your image prompts should describe the content you want to see in the image, and the visual style of image.
+Your prompts should describe the content you want to see in the image, and the visual style of image.
 
-When writing prompts, consider that the image generation APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it doesn't generate an image. For more information, see [Content filtering](../concepts/content-filter.md).
+When you write prompts, consider that the Image APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it doesn't generate an image. For more information, see [Content filtering](../concepts/content-filter.md).
 
 > [!TIP]
 > For a thorough look at how you can tweak your text prompts to generate different kinds of images, see the [Image prompt engineering guide](/azure/ai-services/openai/concepts/gpt-4-v-prompt-engineering).
 
 
-## Specify API options
+### Specify API options
+
+The following API body parameters are available for image generation models.
+
+
+#### [GPT-image-1](#tab/gpt-image-1)
+
+
+#### Size
+
+Specify the size of the generated images. Must be one of `1024x1024`, `1024x1536`, or `1536x1024` for GPT-image-1 models. Square images are faster to generate.
+
+
+#### Quality
+
+There are three options for image quality: `low`, `medium`, and `high`.Lower quality images can be generated faster.
+
+The default value is `high`.
 
-The following API body parameters are available for DALL-E image generation.
+#### Number
 
-### Size
+You can generate between one and 10 images in a single API call. The default value is `1`.
+
+#### Response format
+
+The format in which the generated images are returned. Must be either `url` (a URL pointing to the image) or `b64_json` (the base 64-byte code in JSON format). The default is `url`.
+
+#### User ID
+
+Use the *user* parameter to specify a unique identifier for the user making the request. This is useful for tracking and monitoring usage patterns. The value can be any string, such as a user ID or email address.
+
+#### Output format
+
+Use the *output_format* parameter to specify the format of the generated image. Supported formats are `PNG` and `JPEG`. The default is `PNG`.
+
+> [!NOTE]
+> WEBP images are not supported in the Azure OpenAI Service.
+
+#### Compression
+
+Use the *output_compression* parameter to specify the compression level for the generated image. Input an integer between `0` and `100`, where `0` is no compression and `100` is maximum compression. The default is `100`.
+
+
+#### [DALL-E 3](#tab/dalle-3)
+
+<!--
+| Parameter Name   | Description       | Values         |
+|------------------|-------------|--------------------------|
+| Size             | Specifies the size of generated images. Square images generate faster.    | `1024x1024` (default), `1792x1024`, `1024x1792`           |
+| Style            | DALL-E 3 offers two style options. The natural style is more similar to the default style of older models, while the vivid style generates more hyper-real and cinematic images. </br></br>The natural style is useful in cases where DALL-E 3 over-exaggerates or confuses a subject that's meant to be more simple, subdued, or realistic.     | `natural`, `vivid` (default)           |
+| Quality          | Controls image quality. `hd` has finer details and better consistency; `standard` is faster.    | `hd`, `standard` (default) |
+| Number (`n`)     | Must be set to 1 for DALL-E 3. To get multiple images, make parallel requests.        | `1`              |
+| Response format  | Format for the returned images. Default is `url`.   | `url`, `b64_json`|
+-->
+
+#### Size
 
 Specify the size of the generated images. Must be one of `1024x1024`, `1792x1024`, or `1024x1792` for DALL-E 3 models. Square images are faster to generate.
 
-### Style
+#### Style
 
 DALL-E 3 offers two style options: `natural` and `vivid`. The natural style is more similar to the default style of older models, while the vivid style generates more hyper-real and cinematic images.
 
 The natural style is useful in cases where DALL-E 3 over-exaggerates or confuses a subject that's meant to be more simple, subdued, or realistic.
 
 The default value is `vivid`.
 
-### Quality
+#### Quality
 
 There are two options for image quality: `hd` and `standard`. The hd option creates images with finer details and greater consistency across the image. Standard images can be generated faster.
 
 The default value is `standard`.
 
-### Number
+#### Number
 
 With DALL-E 3, you can't generate more than one image in a single API call: the `n` parameter must be set to *1*. If you need to generate multiple images at once, make parallel requests.
 
-### Response format
+#### Response format
 
 The format in which the generated images are returned. Must be one of `url` (a URL pointing to the image) or `b64_json` (the base 64-byte code in JSON format). The default is `url`.
 
+---
+
+## Call the Image Edit API
+
+The Image Edit API allows you to modify existing images based on text prompts you provide. The API call is similar to the image generation API call, but you also need to provide an image URL or base 64-encoded image data.
+
+
+
+#### [GPT-image-1](#tab/gpt-image-1)
+
+Send a POST request to:
+
+```
+https://<your_resource_name>.openai.azure.com/openai/deployments/<your_deployment_name>/images/edits?api-version=<api_version>
+```
+
+
+**URL**:
+
+Replace the following values:
+- `<your_resource_name>` is the name of your Azure OpenAI resource.
+- `<your_deployment_name>` is the name of your DALL-E 3 or GPT-image-1 model deployment.
+- `<api_version>` is the version of the API you want to use. For example, `2025-04-01-preview`.
+
+**Required headers**:
+- `Content-Type`: `application/json`
+- `api-key`: `<your_API_key>`
+
+**Body**:
+
+The following is a sample request body. You specify a number of options, defined in later sections.
+
+```json
+{
+    "image": "<base64_encoded_image>",
+    "prompt": "Add a beach ball in the center.",
+    "model": "gpt-image-1",
+    "size": "1024x1024", 
+    "n": 1,
+    "quality": "high"
+}
+```
+
+### Output
+
+The response from a successful image editing API call looks like the following example. The `url` field contains a URL where you can download the generated image. The URL stays active for 24 hours.
+
+```json
+{ 
+    "created": 1698116662, 
+    "data": [ 
+        { 
+            "url": "<URL_to_generated_image>",
+            "revised_prompt": "<prompt_that_was_used>" 
+        }
+    ]
+} 
+```
+
+### Specify API options
+
+The following API body parameters are available for image editing models, in addition to the ones available for image generation models.
+
+### Image
+
+The *image* value indicates the image file you want to edit. It can be either a URL string to an image file, or base 64-encoded image data.
+
+
+#### Mask
+
+The *mask* parameter is the same type as the main *image* input parameter. It defines the area of the image that you want the model to change, using fully transparent pixels (alpha of zero) in those areas. The mask can be a URL or base 64-encoded image data. It must be a PNG file and have the same dimensions as the image.
+
+
+#### [DALL-E 3](#tab/dalle-3)
+
+DALL-E models don't support the Image Edit API.
+
+---
+
 ## Related content
 
 * [What is Azure OpenAI Service?](../overview.md)
 * [Quickstart: Generate images with Azure OpenAI Service](../dall-e-quickstart.md)
-* [Image generation API reference](/azure/ai-services/openai/reference#image-generation)
+* [Image API reference](/azure/ai-services/openai/reference#image-generation)
+* [Image API (preview) reference](/azure/ai-services/openai/reference-preview)
 
 
 <!-- OAI HT guide https://platform.openai.com/docs/guides/images/usage
````
</details>

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "新增图像生成模型使用指南"
}
```

### Explanation
此次修改显著扩展了《如何使用DALL-E模型》的文档内容，将其更新为《如何使用Azure OpenAI图像生成模型》。文档的标题和描述进行了重新编写，以包含最新的图像生成模型，同时强调了图像生成与编辑的功能。具体更改包括对模型名称的更新、增加了对于新模型GPT-image-1的介绍以及其改进特性。文中详细说明了如何通过API使用图像生成和编辑功能，提供了示例请求体、API选项以及响应结构等信息，确保用户能够快速上手。

此外，文档也更新了与API相关的参数，增加了有关图像编辑的细节，以及根据特定需求提供的更多选项，如响应格式和压缩级别。这些改动不仅提升了文档的实用性，也增强了用户对Azure OpenAI图像生成能力的理解，帮助用户找到最适合其需求的使用方法。

## articles/ai-services/openai/how-to/evaluations.md{#item-dfaa1c}

<details>
<summary>Diff</summary>
````diff
@@ -305,12 +305,14 @@ BLEU (BiLingual Evaluation Understudy) score is commonly used in natural languag
 
 ROUGE (Recall-Oriented Understudy for Gisting Evaluation) is a set of metrics used to evaluate automatic summarization and machine translation. It measures the overlap between generated text and reference summaries. ROUGE focuses on recall-oriented measures to assess how well the generated text covers the reference text.
 The ROUGE score provides various metrics, including:
-•	ROUGE-1: Overlap of unigrams (single words) between generated and reference text.
-•	ROUGE-2: Overlap of bigrams (two consecutive words) between generated and reference text.
-•	ROUGE-3: Overlap of trigrams (three consecutive words) between generated and reference text.
-•	ROUGE-4: Overlap of four-grams (four consecutive words) between generated and reference text.
-•	ROUGE-5: Overlap of five-grams (five consecutive words) between generated and reference text.
-•	ROUGE-L: Overlap of L-grams (L consecutive words) between generated and reference text.
+
+- ROUGE-1: Overlap of unigrams (single words) between generated and reference text.
+- ROUGE-2: Overlap of bigrams (two consecutive words) between generated and reference text.
+- ROUGE-3: Overlap of trigrams (three consecutive words) between generated and reference text.
+- ROUGE-4: Overlap of four-grams (four consecutive words) between generated and reference text.
+- ROUGE-5: Overlap of five-grams (five consecutive words) between generated and reference text.
+- ROUGE-L: Overlap of L-grams (L consecutive words) between generated and reference text.
+
 Text summarization and document comparison are among optimal use cases for ROUGE, particularly in scenarios where text coherence and relevance are critical.
 
 Cosine similarity measures how closely two text embeddings—such as model outputs and reference texts—align in meaning, helping assess the semantic similarity between them. Same as other model-based evaluators, you need to provide a model deployment using for evaluation. 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "ROUGE指标描述格式化更新"
}
```

### Explanation
此次修改对《评估》文档中的ROUGE指标进行了格式上的更新，以增强可读性。具体变化在于重新调整了ROUGE指标列表的格式，将其从一个紧凑的列表变为更易于阅读的分行方式。更新后的文本清晰地列出各个ROUGE指标，包括ROUGE-1、ROUGE-2、ROUGE-3、ROUGE-4、ROUGE-5和ROUGE-L，并解释了它们如何衡量生成文本与参考文本之间的重叠。这种格式的改动使得用户更容易理解每个指标的意义，同时提供了关于ROUGE在文本摘要和文档比较中的应用场景的补充信息。

这项更新并未改变内容的实质性信息，而是通过优化文本结构来提升了用户的阅读体验，更好地支持用户在评估模型表现时的理解。

## articles/ai-services/openai/how-to/reasoning.md{#item-a54b2f}

<details>
<summary>Diff</summary>
````diff
@@ -49,16 +49,18 @@ Azure OpenAI `o-series` models are designed to tackle reasoning and problem-solv
 | Responses API | ✅ | ✅  | - | - | - | - |
 | Functions/Tools | ✅ | ✅ | ✅  | ✅  |  - | - |
 | Parallel Tool Calls | - | - | -  | -  |  - | - |
-| `max_completion_tokens`<sup>*</sup> | ✅ | ✅ |✅ |✅ |✅ | ✅ |
-| System Messages<sup>**</sup> | ✅ | ✅ | ✅ | ✅ | - | - |
-| [Reasoning summary](#reasoning-summary) <sup>***</sup> | ✅ | ✅ | -  | -  |  - | - |
-| Streaming | ✅ | ✅ | ✅ | - | - | - |
+| `max_completion_tokens` <sup>1</sup> | ✅ | ✅ |✅ |✅ |✅ | ✅ |
+| System Messages <sup>2</sup> | ✅ | ✅ | ✅ | ✅ | - | - |
+| [Reasoning summary](#reasoning-summary) <sup>3</sup> | ✅ | ✅ | -  | -  |  - | - |
+| Streaming <sup>4</sup>  | ✅ | ✅| ✅ | - | - | - |
 
-<sup>*</sup> Reasoning models will only work with the `max_completion_tokens` parameter. <br><br>
+<sup>1</sup> Reasoning models will only work with the `max_completion_tokens` parameter. <br><br>
 
-<sup>**</sup>The latest o<sup>&#42;</sup> series model support system messages to make migration easier. When you use a system message with `o4-mini`, `o3`, `o3-mini`, and `o1` it will be treated as a developer message. You should not use both a developer message and a system message in the same API request.
+<sup>2</sup> The latest o<sup>&#42;</sup> series model support system messages to make migration easier. When you use a system message with `o4-mini`, `o3`, `o3-mini`, and `o1` it will be treated as a developer message. You should not use both a developer message and a system message in the same API request.
 
-<sup>***</sup> Access to the chain-of-thought reasoning summary is limited access only for `o4-mini`. 
+<sup>3</sup> Access to the chain-of-thought reasoning summary is limited access only for `o4-mini`.
+
+<sup>4</sup> Streaming for `o3` is currently only supported for Enterprise subscriptions.
 
 ### Not Supported
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新推理模型支持文档"
}
```

### Explanation
此次修改对《推理》文档中的支持信息进行了小幅更新，主要体现在备注符号的编号变化上。具体而言，文中牛头标记的编号从原来的符号变为数字格式，如`<sup>1</sup>`、`<sup>2</sup>`等，从而使得文档中的注释更加一致且清晰。除了格式的变化外，文本中的内容保持不变，依然详细描述了Azure OpenAI `o-series`模型对不同功能的支持情况，包括最大完成令牌数、系统消息、推理总结和流式输出等。

格式更新的目的是为了提高用户的阅读体验，确保链接和内容的对应关系更为直观。这种细微的改动虽然不是功能性的更新，却能增加文档的整洁性和专业性，有助于用户更快地查找到相关的信息。

## articles/ai-services/openai/how-to/responses.md{#item-b9757d}

<details>
<summary>Diff</summary>
````diff
@@ -46,6 +46,7 @@ The responses API is currently available in the following regions:
 - `gpt-4.1` (Version: `2025-04-14`)
 - `gpt-4.1-nano` (Version: `2025-04-14`)
 - `gpt-4.1-mini` (Version: `2025-04-14`)
+- `gpt-image-1` (Version: `2025-04-15`)
 - `o3` (Version: `2025-04-16`)
 - `o4-mini` (Version: `2025-04-16`)
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "新增图像生成模型支持信息"
}
```

### Explanation
此次修改对《响应》文档进行了小幅更新，新增了对`gpt-image-1`模型的支持信息。该模型的版本为`2025-04-15`，与其他GPT-4.1版本的支持列表一同列出。此项更新明确了该图像生成模型的可用性，方便用户了解支持的模型类型及其版本信息。

通过将`gpt-image-1`模型的详细信息添加到列表中，文档变得更加全面，有助于用户在使用API时清晰识别各个可用模型及其版本。这种细微更新不仅增强了文档的准确性，也提升了用户体验，使得用户能够更方便地获取相关资源和支持信息。

## articles/ai-services/openai/includes/api-versions/latest-inference-preview.md{#item-24bf0f}

<details>
<summary>Diff</summary>
````diff
@@ -5,7 +5,7 @@ description: Latest preview data plane inference documentation generated from Op
 manager: nitinme
 ms.service: azure-ai-openai
 ms.topic: include
-ms.date: 03/24/2025
+ms.date: 04/23/2025
 ---
 
 ## Completions - Create
@@ -1192,7 +1192,7 @@ Status Code: 200
 POST https://{endpoint}/openai/deployments/{deployment-id}/images/generations?api-version=2025-03-01-preview
 ```
 
-Generates a batch of images from a text caption on a given DALLE model deployment
+Generates a batch of images from a text caption on a given DALL-E or GPT-image-1 model deployment
 
 ### URI Parameters
 
@@ -1219,11 +1219,13 @@ Generates a batch of images from a text caption on a given DALLE model deploymen
 |------|------|-------------|----------|---------|
 | n | integer | The number of images to generate. | No | 1 |
 | prompt | string | A text description of the desired image(s). The maximum length is 4000 characters. | Yes |  |
-| quality | [imageQuality](#imagequality) | The quality of the image that will be generated. | No | standard |
+| quality | [imageQuality](#imagequality) | The quality of the image that will be generated. | No | standard (for DALL-E)</br>high (for GPT-image-1) |
 | response_format | [imagesResponseFormat](#imagesresponseformat) | The format in which the generated images are returned. | No | url |
 | size | [imageSize](#imagesize) | The size of the generated images. | No | 1024x1024 |
 | style | [imageStyle](#imagestyle) | The style of the generated images. | No | vivid |
 | user | string | A unique identifier representing your end-user, which can help to monitor and detect abuse. | No |  |
+| output_format | string | The format in which the generated images are returned. GPT-image-1 models only. | No | PNG |
+| output_compression | integer | The compression level (on a scale of 0-100) of the generated images. GPT-image-1 | No | 0 |
 
 ### Responses
 
@@ -1243,14 +1245,12 @@ Generates a batch of images from a text caption on a given DALLE model deploymen
 |:---|:---|:---|
 |application/json | [dalleErrorResponse](#dalleerrorresponse) | |
 
-### Examples
-
 ### Example
 
 Creates images given a prompt.
 
 ```HTTP
-POST https://{endpoint}/openai/deployments/{deployment-id}/images/generations?api-version=2025-03-01-preview
+POST https://{endpoint}/openai/deployments/{deployment-id}/images/generations?api-version=2025-04-01-preview
 
 {
  "prompt": "In the style of WordArt, Microsoft Clippy wearing a cowboy hat.",
@@ -1264,6 +1264,9 @@ POST https://{endpoint}/openai/deployments/{deployment-id}/images/generations?ap
 **Responses**:
 Status Code: 200
 
+> [!NOTE]
+> The GPT-image-1 model doesn't return content filtering annotations.
+
 ```json
 {
   "body": {
@@ -1322,6 +1325,112 @@ Status Code: 200
 }
 ```
 
+
+## Image generations - Edit
+
+```HTTP
+POST https://{endpoint}/openai/deployments/{deployment-id}/images/edits?api-version=2025-04-01-preview
+```
+
+Generates an image based on an input image and text prompt instructions. Requires a GPT-image-1 model deployment
+
+### URI Parameters
+
+| Name | In | Required | Type | Description |
+|------|------|----------|------|-----------|
+| endpoint | path | Yes | string<br>url | Supported Azure OpenAI endpoints (protocol and hostname, for example: `https://aoairesource.openai.azure.com`. Replace "aoairesource" with your Azure OpenAI resource name). https://{your-resource-name}.openai.azure.com |
+| deployment-id | path | Yes | string |  |
+| api-version | query | Yes | string |  |
+
+### Request Header
+
+**Use either token based authentication or API key. Authenticating with token based authentication is recommended and more secure.**
+
+| Name | Required | Type | Description |
+| --- | --- | --- | --- |
+| Authorization | True | string | **Example:** `Authorization: Bearer {Azure_OpenAI_Auth_Token}`<br><br>**To generate an auth token using Azure CLI: `az account get-access-token --resource https://cognitiveservices.azure.com`**<br><br>Type: oauth2<br>Authorization Url: `https://login.microsoftonline.com/common/oauth2/v2.0/authorize`<br>scope: `https://cognitiveservices.azure.com/.default`|
+| api-key | True | string | Provide Azure OpenAI API key here |
+
+### Request Body
+
+**Content-Type**: application/json
+
+| Name | Type | Description | Required | Default |
+|------|------|-------------|----------|---------|
+| image | file | The input image to edit. Must be a valid image URL or base64-encoded image. tbd | Yes |  |
+| n | integer | The number of images to generate. | No | 1 |
+| prompt | string | A text description of how the input image should be edited. The maximum length is 4000 characters. | Yes |  |
+| mask | file | A mask image to define the area of the input image that the model should edit, using fully transparent pixels (alpha of zero) in those areas. Must be a valid image URL or base64-encoded image. | No |  |
+| quality | string | The quality of the image that will be generated. Values are 'low', 'medium', 'high' | No | high |
+| response_format | [imagesResponseFormat](#imagesresponseformat) | The format in which the generated images are returned. | No | url |
+| size | [imageSize](#imagesize) | The size of the generated images. | No | 1024x1024 |
+| style | [imageStyle](#imagestyle) | The style of the generated images. | No | vivid |
+| user | string | A unique identifier representing your end-user, which can help to monitor and detect abuse. | No |  |
+| output_format | [imageOutputFormat](#imageoutputformat) | The format in which the generated images are returned. | No | PNG |
+| output_compression | integer | The compression level (on a scale of 0-100) of the generated images. GPT-image-1 | No | 0 |
+
+
+### Responses
+
+**Status Code:** 200
+
+**Description**: Ok 
+
+|**Content-Type**|**Type**|**Description**|
+|:---|:---|:---|
+|application/json | [generateImagesResponse](#generateimagesresponse) | |
+
+**Status Code:** default
+
+**Description**: An error occurred. 
+
+|**Content-Type**|**Type**|**Description**|
+|:---|:---|:---|
+|application/json | [dalleErrorResponse](#dalleerrorresponse) | |
+
+### Example
+
+Creates images given an input image and text instructions.
+
+```HTTP
+POST https://{endpoint}/openai/deployments/{deployment-id}/images/edits?api-version=2025-04-01-preview
+
+{
+  "image": "<base64_encoded_image>",
+  "prompt": "Add a beach ball in the center.",
+  "model": "gpt-image-1",
+  "size": "1024x1024", 
+  "n": 1,
+  "quality": "high"
+}
+
+```
+
+**Responses**:
+Status Code: 200
+
+> [!NOTE]
+> The GPT-image-1 model doesn't return content filtering annotations.
+
+```json
+{
+  "body": {
+    "created": 1698342300,
+    "data": [
+      {
+        "b64_json": "<base64_encoded_image>",
+        "revised_prompt": "A vivid, natural representation of Microsoft Clippy wearing a cowboy hat.",
+      }],
+    "usage": 
+      {
+        "input_tokens": 557,
+        "output_tokens": 1000,
+      }
+    
+  }
+}
+```
+
 ## List - Assistants
 
 ```HTTP
@@ -6012,6 +6121,17 @@ Speech request.
 | speed | number | The speed of the synthesized audio. Select a value from `0.25` to `4.0`. `1.0` is the default. | No | 1.0 |
 | voice | enum | The voice to use for speech synthesis.<br>Possible values: `alloy`, `echo`, `fable`, `onyx`, `nova`, `shimmer` | Yes |  |
 
+### imageOutputFormat
+
+The requested output format for the generated image.
+
+| Property | Value |
+|----------|-------|
+| **Description** | The requested output format for the generated image. |
+| **Type** | string |
+| **Default** | PNG |
+| **Values** | `PNG`<br>`JPEG` |
+
 ### imageQuality
 
 The quality of the image that will be generated.
@@ -6020,8 +6140,8 @@ The quality of the image that will be generated.
 |----------|-------|
 | **Description** | The quality of the image that will be generated. |
 | **Type** | string |
-| **Default** | standard |
-| **Values** | `standard`<br>`hd` |
+| **Default** | standard (for DALL-E)<br>high (for GPT-image-1) |
+| **Values** | `standard`, `hd` (for DALL-E)<br>`low`, `medium`, `high` (for GPT-image-1) |
 
 ### imagesResponseFormat
 
@@ -6062,11 +6182,32 @@ The style of the generated images.
 |------|------|-------------|----------|---------|
 | n | integer | The number of images to generate. | No | 1 |
 | prompt | string | A text description of the desired image(s). The maximum length is 4000 characters. | Yes |  |
-| quality | [imageQuality](#imagequality) | The quality of the image that will be generated. | No | standard |
+| quality | [imageQuality](#imagequality) | The quality of the image that will be generated. | No | standard (for DALL-E)</br>high (for GPT-image-1) |
 | response_format | [imagesResponseFormat](#imagesresponseformat) | The format in which the generated images are returned. | No | url |
 | size | [imageSize](#imagesize) | The size of the generated images. | No | 1024x1024 |
 | style | [imageStyle](#imagestyle) | The style of the generated images. | No | vivid |
 | user | string | A unique identifier representing your end-user, which can help to monitor and detect abuse. | No |  |
+| output_format | string | The format in which the generated images are returned. GPT-image-1 models only. | No | PNG |
+| output_compression | integer | The compression level (on a scale of 0-100) of the generated images. GPT-image-1 | No | 0 |
+
+### imageEditsRequest
+
+
+| Name | Type | Description | Required | Default |
+|------|------|-------------|----------|---------|
+| image | file | The input image to edit. Must be a valid image URL or base64-encoded image. tbd | Yes |  |
+| n | integer | The number of images to generate. | No | 1 |
+| prompt | string | A text description of how the input image should be edited. The maximum length is 4000 characters. | Yes |  |
+| mask | file | A mask image to define the area of the input image that the model should edit, using fully transparent pixels (alpha of zero) in those areas. Must be a valid image URL or base64-encoded image. | No |  |
+| quality | string | The quality of the image that will be generated. Values are 'low', 'medium', 'high' | No | high |
+| response_format | [imagesResponseFormat](#imagesresponseformat) | The format in which the generated images are returned. | No | url |
+| size | [imageSize](#imagesize) | The size of the generated images. | No | 1024x1024 |
+| style | [imageStyle](#imagestyle) | The style of the generated images. | No | vivid |
+| user | string | A unique identifier representing your end-user, which can help to monitor and detect abuse. | No |  |
+| output_format | [imageOutputFormat](#imageoutputformat) | The format in which the generated images are returned. | No | PNG |
+| output_compression | integer | The compression level (on a scale of 0-100) of the generated images. GPT-image-1 | No | 0 |
+
+
 
 ### generateImagesResponse
 
````
</details>

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "引入图像生成和编辑功能"
}
```

### Explanation
此次修改显著更新了《最新推理预览》文档，增加了对图像生成和编辑功能的详细描述。主要改变包括：

1. **新增模型支持**：引入了`GPT-image-1`模型，并更新了关于指定图像生成和编辑功能的API端点。
  
2. **API版本更新**：更改了API版本为`2025-04-01-preview`，与新功能相匹配。
  
3. **详细的URI参数和请求体**：为图像生成和编辑操作提供了完整的URI参数及请求体的说明，包括新增的`output_format`和`output_compression`字段，这些字段使得用户可以更灵活地控制输出图像的格式和压缩级别。

4. **响应示例**：提供了更新的HTTP响应示例，包括对成功生成图像的JSON结构描述，确保用户可以清晰地了解所需和返回的内容。

5. **错误响应处理**：更新了错误处理的信息，以便用户可以更容易地识别与处理潜在的问题。

6. **编辑功能说明**：明确新增的图像编辑功能，使用户能够基于输入图像和文本说明进行修改，同时有效利用GPT-image-1模型的特性。

通过这些更新，文档提供了更为完整的API使用指南，帮助开发者更好地理解和使用图像生成与编辑功能，提升了整体用户体验。

## articles/ai-services/openai/includes/dall-e-dotnet.md{#item-755f0a}

<details>
<summary>Diff</summary>
````diff
@@ -125,7 +125,7 @@ The URL of the generated image is printed to the console.
 ```
 
 > [!NOTE]
-> The image generation APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it won't return a generated image. For more information, see the [content filter](../concepts/content-filter.md) article.
+> The Image APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it won't return a generated image. For more information, see the [content filter](../concepts/content-filter.md) article.
 
 ## Clean up resources
 
@@ -136,5 +136,5 @@ If you want to clean up and remove an Azure OpenAI resource, you can delete the
 
 ## Next steps
 
-* Explore the image generation APIs in more depth with the [DALL-E how-to guide](../how-to/dall-e.md).
+* Explore the Image APIs in more depth with the [Image API how-to guide](../how-to/dall-e.md).
 * For more examples check out the [Azure OpenAI Samples GitHub repository](https://github.com/Azure/openai-samples).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新图像API相关描述"
}
```

### Explanation
此次修改对《DALL-E .NET 文档》进行了细微更新，主要改善了对图像生成API的描述。具体更改包括：

1. **内容过滤说明调整**：将“image generation APIs”修改为“Image APIs”，使其语法更为一致，同时增加了对API的专业性描述。这一调整有助于用户更清晰地理解这些API的安全性功能。

2. **后续步骤更新**：将“image generation APIs”改为“Image APIs”的描述，统一了文档的术语。这种统一性不仅帮助用户在查找信息时减少混淆，还有助于提高整个文档的可读性。

这些小幅修改的目的是为了提升文档的准确性和一致性，使用户在使用API时能够更顺利地获取所需的信息。通过对描述的明确化，用户能够更好地理解图像生成服务的功能和使用规范。

## articles/ai-services/openai/includes/dall-e-go.md{#item-132707}

<details>
<summary>Diff</summary>
````diff
@@ -248,7 +248,7 @@ Image generated, HEAD request on URL returned 200
 Image URL: <SAS URL>
 ```
 > [!NOTE]
-> The image generation APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it won't return a generated image. For more information, see the [content filter](../concepts/content-filter.md) article.
+> The Image APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it won't return a generated image. For more information, see the [content filter](../concepts/content-filter.md) article.
 
 ## Clean up resources
 
@@ -259,5 +259,5 @@ If you want to clean up and remove an Azure OpenAI resource, you can delete the
 
 ## Next steps
 
-* Explore the image generation APIs in more depth with the [DALL-E how-to guide](../how-to/dall-e.md).
+* Explore the Image APIs in more depth with the [Image API how-to guide](../how-to/dall-e.md).
 * For more examples check out the [Azure OpenAI Samples GitHub repository](https://github.com/Azure/openai-samples).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新图像API相关说明"
}
```

### Explanation
此次修改对《DALL-E Go 文档》进行了小幅更新，主要是增强了对图像API的描述。具体的变更包括：

1. **内容过滤说明的统一**：将“image generation APIs”更新为“Image APIs”，确保文档中的术语一致性。这一修改帮助用户更清晰地理解文中所涉及的API服务。

2. **后续步骤的描述调整**：在后续步骤部分，同样将“image generation APIs”表达更改为“Image APIs”，有助于提升文档的整体可读性与专业性。

这些小更改旨在提高文档的一致性和清晰度，使用户在使用相关API时能够更加顺畅，减少了潜在的混淆，同时确保了技术术语的准确使用。

## articles/ai-services/openai/includes/dall-e-java.md{#item-373f89}

<details>
<summary>Diff</summary>
````diff
@@ -263,7 +263,7 @@ Completed getImages.
 ```
 
 > [!NOTE]
-> The image generation APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it won't return a generated image. For more information, see the [content filter](../concepts/content-filter.md) article.
+> The Image APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it won't return a generated image. For more information, see the [content filter](../concepts/content-filter.md) article.
 
 
 ## Clean up resources
@@ -275,5 +275,5 @@ If you want to clean up and remove an Azure OpenAI resource, you can delete the
 
 ## Next steps
 
-* Explore the image generation APIs in more depth with the [DALL-E how-to guide](../how-to/dall-e.md).
+* Explore the Image APIs in more depth with the [Image API how-to guide](../how-to/dall-e.md).
 * For more examples, check out the [Azure OpenAI Samples GitHub repository](https://github.com/Azure-Samples/openai)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新图像API的相关说明"
}
```

### Explanation
此次修改对《DALL-E Java 文档》进行了小幅更新，主要集中在对图像API术语的统一和明确。具体包括以下几个方面：

1. **内容过滤说明调整**：将“image generation APIs”更改为“Image APIs”，增强了术语的一致性和清晰度。这种修改旨在使用户能够更好地理解所涉及的服务功能。

2. **后续步骤的术语统一**：在后续步骤部分，将“image generation APIs”相应地修改为“Image APIs”，这提升了文档的专业性和易读性。

这些细微的修改意在提高整份文档的准确性和专业性，为用户提供更加清晰的一致性，使他们在使用API时可以更容易地获取必要的信息。通过这样的更新，文档的整体流畅性也得到了增强。

## articles/ai-services/openai/includes/dall-e-javascript.md{#item-6cffcf}

<details>
<summary>Diff</summary>
````diff
@@ -202,7 +202,7 @@ Image generation result URL: <SAS URL>
 ```
 
 > [!NOTE]
-> The image generation APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it won't return a generated image. For more information, see the [content filter](../concepts/content-filter.md) article.
+> The Image APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it won't return a generated image. For more information, see the [content filter](../concepts/content-filter.md) article.
 
 ## Clean up resources
 
@@ -213,5 +213,5 @@ If you want to clean up and remove an Azure OpenAI resource, you can delete the
 
 ## Next steps
 
-* Explore the image generation APIs in more depth with the [DALL-E how-to guide](../how-to/dall-e.md).
+* Explore the Image APIs in more depth with the [Image API how-to guide](../how-to/dall-e.md).
 * For more examples check out the [Azure OpenAI Samples GitHub repository](https://github.com/Azure/openai-samples).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新图像API的相关表述"
}
```

### Explanation
此次修改对《DALL-E JavaScript 文档》进行了小幅调整，主要聚焦于术语的统一和澄清。具体变更包括：

1. **内容过滤说明的术语优化**：将“image generation APIs”修改为“Image APIs”，以确保文档中的术语一致性和明确性。这一变更能够帮助用户准确理解相关API的功能。

2. **后续步骤描述的更新**：在后续步骤中，同样将“image generation APIs”更改为“Image APIs”。这一改动提升了文档的专业性，同时也避免了不同术语可能导致的混淆。

这些小幅度的更新旨在增强文档内容的一致性和流畅度，从而为用户提供更加清晰易懂的指导，提升他们在使用API时的体验与理解。

## articles/ai-services/openai/includes/dall-e-powershell.md{#item-97878b}

<details>
<summary>Diff</summary>
````diff
@@ -106,7 +106,7 @@ For the recommended keyless authentication with Microsoft Entra ID, you need to:
 
 PowerShell requests the image from Azure OpenAI and stores the output image in the _generated_image.png_ file in your specified directory. For convenience, the full path for the file is returned at the end of the script.
 
-The image generation APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it doesn't generate an image. For more information, see [Content filtering](../concepts/content-filter.md).
+The Image APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it doesn't generate an image. For more information, see [Content filtering](../concepts/content-filter.md).
 
 ## Clean up resources
 
@@ -117,5 +117,5 @@ If you want to clean up and remove an Azure OpenAI resource, you can delete the
 
 ## Next steps
 
-* Explore the image generation APIs in more depth with the [DALL-E how-to guide](../how-to/dall-e.md).
+* Explore the Image APIs in more depth with the [Image API how-to guide](../how-to/dall-e.md).
 - Try examples in the [Azure OpenAI Samples GitHub repository](https://github.com/Azure/openai-samples).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新图像API的描述内容"
}
```

### Explanation
此次修改对《DALL-E PowerShell 文档》进行了小幅更新，主要涉及术语的统一。具体修改包括：

1. **内容过滤的说明修改**：将“image generation APIs”调整为“Image APIs”，以增强术语的一致性。这一改变可以帮助用户在理解API功能时更加清晰，避免了不同术语带来的混淆。

2. **后续步骤的描述调整**：在后续步骤部分，类似地将“image generation APIs”更改为“Image APIs”。此更改不仅提升了文档的专业性，还确保用户能一目了然地获取关键信息。

这些细微的修改旨在提升文档的整体一致性和可读性，以便用户在使用API的过程中能够获得更加准确、清晰的指导，从而改善用户体验。

## articles/ai-services/openai/includes/dall-e-python.md{#item-c91824}

<details>
<summary>Diff</summary>
````diff
@@ -120,7 +120,7 @@ Wait a few moments to get the response.
 
 Azure OpenAI stores the output image in the _generated_image.png_ file in your specified directory. The script also displays the image in your default image viewer.
 
-The image generation APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it doesn't generate an image. For more information, see [Content filtering](../concepts/content-filter.md).
+The Image APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it doesn't generate an image. For more information, see [Content filtering](../concepts/content-filter.md).
 
 ## Clean up resources
 
@@ -131,6 +131,6 @@ If you want to clean up and remove an Azure OpenAI resource, you can delete the
 
 ## Next steps
 
-* Explore the image generation APIs in more depth with the [DALL-E how-to guide](../how-to/dall-e.md).
+* Explore the Image APIs in more depth with the [Image API how-to guide](../how-to/dall-e.md).
 * Try examples in the [Azure OpenAI Samples GitHub repository](https://github.com/Azure/openai-samples).
 * See the [API reference](../reference.md#image-generation)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新图像API的相关术语"
}
```

### Explanation
此次修改针对《DALL-E Python 文档》进行了小幅度的调整，主要集中在术语的一致性上。具体的变更包括：

1. **内容过滤说明的术语更新**：将“image generation APIs”改为“Image APIs”，以保持术语的一致性。这样的调整能够帮助用户更好地理解API的功能，避免不同术语可能引起的混淆。

2. **后续步骤的描述修改**：在后续步骤部分，类似地将“image generation APIs”更换为“Image APIs”。这一更改意在确保文档中对API的描述更加专业和统一。

这些小修改旨在提升文档的整体一致性和可读性，以便用户在使用API时能更清晰地获取信息，并改善用户的使用体验。

## articles/ai-services/openai/includes/dall-e-rest.md{#item-4bac64}

<details>
<summary>Diff</summary>
````diff
@@ -99,7 +99,7 @@ The output from a successful image generation API call looks like the following
 } 
 ```
 
-The image generation APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it doesn't generate an image. For more information, see [Content filtering](../concepts/content-filter.md). For examples of error responses, see the [DALL-E how-to guide](../how-to/dall-e.md).
+The Image APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it doesn't generate an image. For more information, see [Content filtering](../concepts/content-filter.md). For examples of error responses, see the [DALL-E how-to guide](../how-to/dall-e.md).
 
 The system returns an operation status of `Failed` and the `error.code` value in the message is set to `contentFilter`. Here's an example:
 
@@ -137,6 +137,6 @@ If you want to clean up and remove an Azure OpenAI resource, you can delete the
 
 ## Next steps
 
-* Explore the image generation APIs in more depth with the [DALL-E how-to guide](../how-to/dall-e.md).
+* Explore the Image APIs in more depth with the [Image API how-to guide](../how-to/dall-e.md).
 * Try examples in the [Azure OpenAI Samples GitHub repository](https://github.com/Azure/openai-samples).
 * See the [API reference](../reference.md#image-generation)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新API相关术语以确保一致性"
}
```

### Explanation
此次对《DALL-E REST 文档》的修改涉及术语的一致性，具体的调整如下：

1. **内容过滤说明调整**：文中将“image generation APIs”更改为“Image APIs”，旨在统一术语，避免用户在理解API功能时的困惑。通过使用一致的术语，文档的专业性得到了提升。

2. **后续步骤修改**：在后续步骤部分，同样将“image generation APIs”替换为“Image APIs”。这样的修改确保了文档中的术语在不同部分保持一致，进一步增强了可读性。

整体来看，这些小的修改旨在提高文档的一致性和清晰度，从而改善用户的文档阅读体验，使他们在使用API时更容易获取和理解重要信息。

## articles/ai-services/openai/includes/dall-e-studio.md{#item-439729}

<details>
<summary>Diff</summary>
````diff
@@ -31,7 +31,7 @@ On the model's page, select **Open in playground**.
 Start exploring Azure OpenAI capabilities with a no-code approach through the **Images playground**. Enter your image prompt into the text box and select **Generate**. When the AI-generated image is ready, it appears on the page.
 
 > [!NOTE]
-> The image generation APIs come with a content moderation filter. If Azure OpenAI recognizes your prompt as harmful content, it doesn't return a generated image. For more information, see [Content filtering](../concepts/content-filter.md).
+> The Image APIs come with a content moderation filter. If Azure OpenAI recognizes your prompt as harmful content, it doesn't return a generated image. For more information, see [Content filtering](../concepts/content-filter.md).
 
 In the **Images playground**, you can also view Python and cURL code samples, which are prefilled according to your settings. Select **View code** near the top of the page. You can use this code to write an application that completes the same task.
 
@@ -44,6 +44,6 @@ If you want to clean up and remove an Azure OpenAI resource, you can delete the
 
 ## Next steps
 
-* Explore the image generation APIs in more depth with the [DALL-E how-to guide](../how-to/dall-e.md).
+* Explore the Image APIs in more depth with the [Image API how-to guide](../how-to/dall-e.md).
 * Try examples in the [Azure OpenAI Samples GitHub repository](https://github.com/Azure/openai-samples).
 * See the [API reference](../reference.md#image-generation)
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新术语以提升一致性"
}
```

### Explanation
此次对《DALL-E Studio 文档》的修改主要是围绕术语的一致性进行的调整，具体包括：

1. **内容过滤说明的术语更正**：将文中提到的“image generation APIs”替换为“Image APIs”，这一更改是为了确保术语的一致性，使得描述更加精准，减少用户在理解上可能产生的混淆。

2. **后续步骤部分的更新**：在后续步骤中，同样将“image generation APIs”更新为“Image APIs”，以保持整个文档在术语使用上的统一性。

总体来看，这些变化旨在增强文档的清晰度和一致性，从而帮助用户更轻松地理解和使用相关的API功能。此类细微的调整能够提升用户体验，使得文档在专业性和可读性上都有所提高。

## articles/ai-services/openai/includes/dall-e-typescript.md{#item-57b205}

<details>
<summary>Diff</summary>
````diff
@@ -248,7 +248,7 @@ Image generation result URL: <SAS URL>
 ```
 
 > [!NOTE]
-> The image generation APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it won't return a generated image. For more information, see the [content filter](../concepts/content-filter.md) article.
+> The Image APIs come with a content moderation filter. If the service recognizes your prompt as harmful content, it won't return a generated image. For more information, see the [content filter](../concepts/content-filter.md) article.
 
 ## Clean up resources
 
@@ -259,5 +259,5 @@ If you want to clean up and remove an Azure OpenAI resource, you can delete the
 
 ## Next steps
 
-* Explore the image generation APIs in more depth with the [DALL-E how-to guide](../how-to/dall-e.md).
+* Explore the Image APIs in more depth with the [Image API how-to guide](../how-to/dall-e.md).
 * For more examples check out the [Azure OpenAI Samples GitHub repository](https://github.com/Azure/openai-samples).
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "修正术语以提高文档一致性"
}
```

### Explanation
此次对《DALL-E TypeScript 文档》的修改主要集中在术语的统一性和准确性上，具体的改动如下：

1. **内容过滤部分的更新**：文中将“image generation APIs”替换为“Image APIs”，这一更改意在确保文档术语的一致性，使用户在阅读时不会产生混淆，能够更清晰地理解API的功能。

2. **后续步骤的术语更改**：在后续步骤说明中，类似地将“image generation APIs”改为“Image APIs”，以保持整个文档中对术语的统一使用，提高文档的专业性和可读性。

通过这些小的修改，文档在内容一致性方面得到了提升，从而帮助用户更准确地理解和使用相关的API，改善整体的用户体验。

## articles/ai-services/openai/includes/language-overview/dotnet.md{#item-46e881}

<details>
<summary>Diff</summary>
````diff
@@ -264,7 +264,7 @@ bytes.ToStream().CopyTo(stream);
 
 ```
 
-- [C# DALL-E quickstart guide](/azure/ai-services/openai/dall-e-quickstart?tabs=dalle3%2Ccommand-line%2Ckeyless%2Ctypescript-keyless&pivots=programming-language-csharp)
+- [C# Image generation quickstart guide](/azure/ai-services/openai/dall-e-quickstart?tabs=dalle3%2Ccommand-line%2Ckeyless%2Ctypescript-keyless&pivots=programming-language-csharp)
 
 ## Reasoning models
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新快速入门指南的标题"
}
```

### Explanation
此次对《.NET 语言概述文档》的修改主要是对文中快速入门指南的标题进行了更新：

1. **标题更改**：将原来的“C# DALL-E quickstart guide”更新为“C# Image generation quickstart guide”。这一修改旨在让标题更准确地反映指南的内容，强调该指南是关于图像生成的，而不仅仅是DALL-E。

这种小的调整有助于提升文档的准确性和清晰度，使得用户能够更快地找到所需的信息，同时也增强了文档整体的一致性。

## articles/ai-services/openai/includes/model-matrix/global-batch.md{#item-929e6a}

<details>
<summary>Diff</summary>
````diff
@@ -19,7 +19,6 @@ ms.date: 04/21/2025
 | eastus2            | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | -                      | ✅                       | ✅                       |
 | francecentral      | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | -                      | ✅                       | ✅                       |
 | germanywestcentral | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | ✅                       | ✅                       | ✅                       |
-| italynorth         | ✅                        | -                      | -                      | -                      | -                           | -               | -                           | -                      | -                      | -                      |
 | japaneast          | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | -                      | ✅                       | ✅                       |
 | koreacentral       | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | ✅                       | ✅                       | ✅                       |
 | northcentralus     | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | -                      | ✅                       | ✅                       |
@@ -31,7 +30,6 @@ ms.date: 04/21/2025
 | spaincentral       | ✅                        | -                      | -                      | -                      | -                           | -               | -                           | -                      | -                      | -                      |
 | swedencentral      | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | -                      | ✅                       | ✅                       |
 | switzerlandnorth   | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | -                      | ✅                       | ✅                       |
-| uaenorth           | ✅                        | -                      | -                      | -                      | -                           | -               | -                           | -                      | -                      | -                      |
 | uksouth            | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | -                      | ✅                       | ✅                       |
 | westeurope         | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | ✅                       | ✅                       | ✅                       |
 | westus             | ✅                        | ✅                       | ✅                       | ✅                       | ✅                            | ✅                | ✅                            | ✅                       | ✅                       | ✅                       |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "删除部分区域的支持信息"
}
```

### Explanation
本次对《全局批处理文档》的修改涉及到从支持区域的表格中删除了一些信息。具体而言：

1. **区域支持信息的删除**：文中删除了两个地区的相关支持信息，即"Italynorth"和"UAE North"。这可能是因为这些区域的支持已不再可用或者相关功能的实现有所调整。这一修改帮助确保文档中提供的信息的准确性和最新性。

2. **影响表格结构**：由于对支持信息的删除，表格的结构有所变化，更新后的表格能更清晰地反映当前可用支持的区域。这提升了文档的清晰度，确保用户获取的信息真实可靠。

这样的调整有助于避免用户对已删除区域的误解，确保他们在使用相关服务时有一个更明确的指引。

## articles/ai-services/openai/includes/structured-outputs-python.md{#item-2734f0}

<details>
<summary>Diff</summary>
````diff
@@ -20,6 +20,7 @@ pip install openai pydantic --upgrade
 If you are new to using Microsoft Entra ID for authentication see [How to configure Azure OpenAI Service with Microsoft Entra ID authentication](../how-to/managed-identity.md).
 
 ```python
+import os
 from pydantic import BaseModel
 from openai import AzureOpenAI
 from azure.identity import DefaultAzureCredential, get_bearer_token_provider
@@ -105,6 +106,7 @@ pip install openai pydantic --upgrade
 ```
 
 ```python
+import os
 from pydantic import BaseModel
 from openai import AzureOpenAI
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "在示例代码中添加了对os模块的导入"
}
```

### Explanation
此次对《结构化输出 Python 文档》的修改主要是在示例代码中添加了对`os`模块的导入：

1. **代码更新**：新增了`import os`这一行，以确保代码中的相关操作能够正常执行。在Python中，`os`模块提供了与操作系统交互的功能，可能是为了后续实现文件路径获取或环境变量管理等。

2. **增强代码的功能性**：通过这项修改，示例代码的功能更加完整，确保用户在实现具体功能时不会遇到因缺少模块而导致的错误。这能够提高用户体验，使其在根据文档进行开发时能够得心应手。

这个更新在整体上是轻微的，但为代码的正确性和有效性提供了必要的支持，使得文档内容更加可靠。

## articles/ai-services/openai/index.yml{#item-0adb87}

<details>
<summary>Diff</summary>
````diff
@@ -1,11 +1,11 @@
 ### YamlMime:Landing
 
 title: Azure OpenAI Service documentation # < 60 chars
-summary: Azure OpenAI Service provides access to OpenAI's models including o-series, GPT-4o, GPT-4o mini, GPT-4, GPT-4 Turbo with Vision, GPT-3.5-Turbo, DALLE-3 and Embeddings model series with the security and enterprise capabilities of Azure. 
+summary: Azure OpenAI Service provides access to OpenAI's models including o-series, GPT-4o, GPT-4o mini, GPT-4, GPT-4 Turbo with Vision, GPT-3.5-Turbo, GPT-image-1 and Embeddings model series with the security and enterprise capabilities of Azure. 
   
 metadata:
   title: Azure OpenAI Service documentation - Quickstarts, Tutorials, API Reference - Azure AI services | Microsoft Docs
-  description: Learn how to use Azure OpenAI's powerful models including o-series, GPT-4o, GPT-4o mini, GPT-4, GPT-4 Turbo with Vision, GPT-3.5-Turbo, DALL-E 3 and Embeddings model series
+  description: Learn how to use Azure OpenAI's powerful models including o-series, GPT-4o, GPT-4o mini, GPT-4, GPT-4 Turbo with Vision, GPT-3.5-Turbo, GPT-image-1, and Embeddings model series
   ms.service: azure-ai-openai
   ms.custom:
   ms.topic: landing-page
@@ -42,7 +42,7 @@ landingContent:
              url: chatgpt-quickstart.md
            - text: Vision-enabled models
              url: gpt-v-quickstart.md  
-           - text: DALL-E
+           - text: Image generation
              url: dall-e-quickstart.md
            - text: Use your data (preview)
              url: use-your-data-quickstart.md
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新模型和文档描述中的名称"
}
```

### Explanation
本次对《Azure OpenAI 服务文档》的 YML 配置文件进行了小幅修改，主要涉及模型名称和文档描述的更新：

1. **模型名称修改**：在摘要和描述中，原来的 "DALLE-3" 和 "DALL-E 3" 被替换为 "GPT-image-1"。这可能是为了适应新的命名标准或是将模型进行更新，使得用户可以获取最新的信息和功能。

2. **文档描述更新**：同时，文档的描述文本中也进行了相应的替换，以确保描述与最新的内容保持一致。这一部分更新有助于用户准确理解Azure OpenAI服务所提供的功能和服务范围。

3. **内容链接更新**：在"landingContent"部分，将“DALL-E”更改为“Image generation”，这使得标题更加通用并符合更广泛的图像生成功能，提升了对用户的引导性。

通过这些小的修改，文档的准确性和相关性得到了提升，确保用户在查阅文档时能够接触到最新的信息和服务内容。

## articles/ai-services/openai/overview.md{#item-97d507}

<details>
<summary>Diff</summary>
````diff
@@ -52,7 +52,7 @@ Start with the [Create and deploy an Azure OpenAI Service resource](./how-to/cre
 
 ## Comparing Azure OpenAI and OpenAI
 
-Azure OpenAI Service gives customers advanced language AI with OpenAI GPT-4, GPT-3, Codex, DALL-E, speech to text, and text to speech models with the security and enterprise promise of Azure. Azure OpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth transition from one to the other.
+Azure OpenAI Service gives customers advanced language AI with OpenAI GPT-4, GPT-3, Codex, GPT-image-1 (preview), DALL-E, speech to text, and text to speech models with the security and enterprise promise of Azure. Azure OpenAI co-develops the APIs with OpenAI, ensuring compatibility and a smooth transition from one to the other.
 
 With Azure OpenAI, customers get the security capabilities of Microsoft Azure while running the same models as OpenAI. Azure OpenAI offers private networking, regional availability, and responsible AI content filtering.  
 
@@ -129,7 +129,7 @@ Prompt construction can be difficult. In practice, the prompt acts to configure
 
 The service provides users access to several different models. Each model provides a different capability and price point.
 
-The DALL-E models (some in preview; see [models](./concepts/models.md#dall-e)) generate images from text prompts that the user provides.
+The image generation models (some in preview; see [models](./concepts/models.md#image-generation-models)) generate and edit images from text prompts that the user provides.
 
 The audio API models can be used to transcribe and translate speech to text. The text to speech models, currently in preview, can be used to synthesize text to speech.
 
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新文档中模型名称及描述"
}
```

### Explanation
这次对《Azure OpenAI 概述文档》进行了小幅修改，主要集中在模型名称和描述的更新，具体如下：

1. **模型名称更新**：在描述Azure OpenAI服务时，原有的"DALL-E"被更新为"GPT-image-1 (preview)"，以反映新的模型名称并确保用户接收到最新的产品信息和功能。

2. **描述调整**：文档中对图像生成模型的描述也进行了相应修改，将原先关于"DALL-E模型"的描述改为"图像生成模型"，这种调整不仅让表述更加广泛，还能够涵盖未来可能发布的其他图像生成模型。

3. **增强用户理解**：通过这些更新，文档的内容变得更加准确，能够有效引导用户理解Azure OpenAI提供的多样化模型及其对应的功能，尤其是在图像生成和处理方面。

此次修改虽然是小幅度的更新，但在提升文档清晰度和准确性方面起到了积极的作用，有助于用户更好地了解Azure OpenAI服务的能力。

## articles/ai-services/openai/quotas-limits.md{#item-06c6f9}

<details>
<summary>Diff</summary>
````diff
@@ -9,7 +9,7 @@ ms.custom:
   - ignite-2023
   - references_regions
 ms.topic: conceptual
-ms.date: 4/14/2025
+ms.date: 04/23/2025
 ms.author: mbullwin
 ---
 
@@ -26,6 +26,7 @@ The following sections provide you with a quick guide to the default quotas and
 | Azure OpenAI resources per region per Azure subscription | 30 |
 | Default DALL-E 2 quota limits | 2 concurrent requests |
 | Default DALL-E 3 quota limits| 2 capacity units (6 requests per minute)|
+| Default GPT-image-1 quota limits | 2 capacity units (6 requests per minute) |
 | Default speech to text audio API quota limits | 3 requests per minute |
 | Maximum prompt tokens per request | Varies per model. For more information, see [Azure OpenAI Service models](./concepts/models.md)|
 | Max Standard deployments per resource | 32 |
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新配额和限制文档以包含新模型"
}
```

### Explanation
此次对《Azure OpenAI 配额和限制文档》进行了小幅更新，主要内容如下：

1. **日期更新**：文档的最后修改日期已更新，从原来的“2025年4月14日”更改为“2025年4月23日”，以反映最新的修改时间。

2. **新增模型配额**：在配额限制部分，新增了关于“GPT-image-1”的配额限制条目，指出该模型的默认限制为“2个容量单位（每分钟6个请求）”。这条信息的加入确保用户能够获取到有关新模型的最新配额信息，对于开发者而言是非常重要的参考。

3. **整体清晰度**：整体来看，这些修改使得文档内容更为完整，提升了文档清晰度与实用性。通过确保所有的配额信息都包括最新的模型，用户能够更好地规划和使用Azure OpenAI的资源。

此次更新虽然是微小的修改，但对使用者了解当前可用服务模型的配额限制提供了重要支持。

## articles/ai-services/openai/toc.yml{#item-c945af}

<details>
<summary>Diff</summary>
````diff
@@ -36,7 +36,7 @@ items:
       displayName: ChatGPT, chatgpt
     - name: Vision-enabled chats
       href: gpt-v-quickstart.md
-    - name: DALL-E
+    - name: Image generation
       href: dall-e-quickstart.md
     - name: Use your data
       href: use-your-data-quickstart.md
@@ -128,7 +128,7 @@ items:
       displayName: cua, computer using model
     - name: Vision-enabled chats
       href: ./how-to/gpt-with-vision.md
-    - name: DALL-E
+    - name: Image generation
       href: ./how-to/dall-e.md
     - name: Function calling
       href: ./how-to/function-calling.md
````
</details>

### Summary

```json
{
    "modification_type": "minor update",
    "modification_title": "更新目录以反映图像生成模型的名称变更"
}
```

### Explanation
此次对《Azure OpenAI 目录文件（toc.yml）》进行了小幅修改，主要内容如下：

1. **名称更改**：在目录中，原先的“DALL-E”选项被更新为“图像生成”。这种名称的更新旨在更好地反映该功能的广泛性，涵盖DALL-E模型及其他可能的图像生成模型。

2. **更新信息一致性**：通过在多个位置（如“快速入门”指南链接和“如何使用”链接）使用统一的新名称，增强了文档的一致性和准确性，有助于用户更容易找到相关信息。

3. **用户体验提升**：这些修改虽然简单，却使得目录结构更加直观，便于用户导航，从而提高了用户体验，让用户能够更快查找到所需的内容。

此次更新对目录的调整，使得内容更加符合当前的功能说明，提高了文档的可读性和实用性。

## articles/ai-services/openai/whats-new.md{#item-53303b}

<details>
<summary>Diff</summary>
````diff
@@ -21,6 +21,17 @@ This article provides a summary of the latest releases and major documentation u
 
 ## April 2025
 
+### GPT-image-1 released (preview, limited access)
+
+GPT-image-1 (2025-04-15) is the latest image generation model from Azure OpenAI. It features major improvements over DALL-E, including:
+- Better at responding to precise instructions.
+- Reliably renders text.
+- Accepts images as input, which enables the new capabilities of image editing and inpainting.
+
+Request access: [Limited access model application](https://aka.ms/oai/gptimage1access)
+
+Follow the [image generation how-to guide](/en-us/azure/ai-services/openai/how-to/dall-e) to get started with the new model.
+
 ### o4-mini and o3 models released
 
 `o4-mini` and `o3` models are now available. These are the latest reasoning models from Azure OpenAI offering significantly enhanced reasoning, quality, and performance. For more information, see the [getting started with reasoning models page](./how-to/reasoning.md).
````
</details>

### Summary

```json
{
    "modification_type": "new feature",
    "modification_title": "新增GPT-image-1模型的介绍"
}
```

### Explanation
此次更新了《Azure OpenAI 最新动态文档（whats-new.md）》，主要内容包括：

1. **新增模型介绍**：文档新增了关于“GPT-image-1”模型的内容，说明了其发布日期为2025年4月15日，并指出该模型目前处于预览阶段，且仅限部分用户访问。

2. **功能增强**：文中详细列出了GPT-image-1相较于DALL-E的主要改进，包括：
   - 更好地响应精确指令；
   - 稳定地渲染文本；
   - 支持图像输入，使其具备图像编辑和绘制功能的新能力。

3. **访问申请**：提供了申请访问的链接，方便用户获取对该模型的有限使用权限。

4. **入门指南**：此外，文档中还引导用户参考图像生成的操作指南，以便迅速了解如何开始使用新模型。

此次更新为用户提供了关于最新图像生成技术的重要信息，反映了Azure OpenAI在模型开发方面的前沿进展，同时增强了文档的实用性和更新性。


